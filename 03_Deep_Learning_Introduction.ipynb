{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.  DeepLearning Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 기계학습 (Machine Learning) : 가설 공간을 더욱 질서있는 방향으로 표현하기 위한 자동화 과정 \n",
    "* 딥러닝 (Deep Learning) : 여러 층(Layer)으로 구성된 규칙으로, 데이터로 부터 점진적인 학습을 하여 가설공간의 표현을 하는 과정 \n",
    "* 딥러닝은 신경망 모델 (Neural Network)을 활용해 표현층 (Layer)를 학습한다.\n",
    "* 여러 층을 거치면서, 정보가 연속된 Filter를 통과, 의미있는 정보를 추출 \n",
    "* 딥러닝에서는 특성공학의 과정을 자동화한다.\n",
    "* 특성공학 (Feature Engineering) :데이터의 표현을 직접 만들어, 알고리즘에 적합하게 다루는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1 신경망 알고리즘의 발달"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1943년 부터 존재한 개념 이였으나,(생물학적 신경망 BNN에서 부터 인공뉴런에 대한 제안) 기술적인 문제와 성능의 한계로 각광받지 못함\n",
    "* 기존에는 일반 기계학습 알고리즘의 설명이 더욱 명확하고 성능이 좋음 \n",
    "* 2010 힌튼 교수의 Image Net 이미지 분류 알고리즘을 신경망 알고리즘으로 분류, 높은 성능을 발휘하며, 다시 각광받기 시작함\n",
    "* 현재 신경망을 사용하는 이유 \n",
    "    - 현재 존재하는 데이터가 매우 많아짐 (TB 단위)\n",
    "    - 비정형데이터의 처리 필요성 (이미지, 영상, 소리 등) \n",
    "    - 컴퓨터 하드웨어의 발전 (GPU 및 클라우드 컴퓨팅)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2 신경망 알고리즘 기본 작동 원리 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://miro.medium.com/max/1380/1*dnvGC-PORSoCo7VXT3PV_A.png)\n",
    "\n",
    "**네트워크(Layer)의 기능 및 역할**\n",
    "* 데이터 연산이 처리되는 각 층을 연결 함 \n",
    "* 층간 활성함수에 의한 연산으로 다양하고 복잡한 형태의 계산이 가능 \n",
    "* 점진적으로 데이터가 정제되어 처리될 수 있는 구조 형성\n",
    "\n",
    "`                 `\n",
    "\n",
    "* 층(Layer)에서 입력 데이터(Input Data)가 처리되는 정보는 Weight(해당 Layer의 Parameter)라는 Vector에 저장되어 있음 \n",
    "* 딥러닝 : 예측을 정확하게 하기 위한 Weight를 찾는 것 \n",
    "* 손실함수 (Cost Function or Objective Function) : 예측값과 실제 값의 차이를 계산한 함수. 신경망 출력제어의 지표가 됨 \n",
    "* 손실함수가 최소가 되는 방향으로 Weight를 Update \n",
    "* Backpropagation (역전파) 알고리즘을 구현한 Optimizer를 이용해 Update\n",
    "* Training Loop를 통해, 최초의 부여받은 Random weight에서 Cost Function이 가장 낮아지는 Weight를 도출 \n",
    "\n",
    "* **처리 순서**\n",
    "    - 1. 여러개의 Batch를 나눠 학습 (몇 번 반복 할 것인가 결정 Epoch)\n",
    "    - 2. 데이터가 각 층을 통과하며, Node에 있는 함수에 의해 처리 (Forward Pass)\n",
    "    - 3. 실측값과 신경망에 의한 예측값을 비교해 오차 계산 \n",
    "    - 4. Chain Rule을 통해 오차에 대한 각 Node에 있는 기여도를 계산 (Backward Pass)\n",
    "    - 5. 오차가 감소하도록 Weight를 계산 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-3 데이터와 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img1](https://miro.medium.com/max/1814/0*HLo6XxRwCzjUzXXh.)\n",
    "\n",
    "* **Perceptron Model** : Intput Layer과 하나의 Hidden Layer와 Output Layer 로 구성되어 있으며, 초기 Percetron Model은 층이 하나 뿐인 Threshold Logic Unit 으로 구성 \n",
    "\n",
    "\n",
    "* **Multi Layer Percetron** : Perceptron 구조를 여러층으로 쌓아올린 신경망 알고리즘. 하나 이상의 Hidden Layer로 구성. 기존의 Perceptron가 가지고 있는 한계를 개선 (단순한 문제에서 발생하는 오류)\n",
    "\n",
    "\n",
    "* **Deep Neural Network** : Hidden Layer를 여러 겹 쌓아올린 신경망. 역전파(BackPropagation)알고리즘을 통해 훈련방법을 개선. 네트워크를 데이터가 통과하면서, 각 층에 있는 HyperParameter를 계산 \n",
    "\n",
    "\n",
    "* **Convolutional Neural Network, CNN**: 합성곱신경망, 사람의 시신경구조를 모방한 알고리즘. 데이터를 특정 차원으로 추출하여, 해당 차원의 패턴을 파악하는 구조. Convolution과정과 Pooling 과정을 통해 진행. 이미지처리에 주로 사용되다가 자연어 처리에도 사용 하기도 함 \n",
    "    - Convolution 과정 : 데이터의 특징을 추출하여 파악한 특징들을 하나의 차원으로 표현하는 과정. 표현된 데이터를 Convolution Layer라고 표현 \n",
    "    - Pooling 과정 : Convolution Layer의 사이즈를 줄여, 노이즈를 상쇄시키고 미세한 부분에서 일괄적 특징을 제공하는 과정 (Sub Sampling, Max-pooling/Average-pooling/L2-norm pooling 등이 존재 \n",
    "   \n",
    "    \n",
    "   \n",
    "* **Recurrent Neural Network, RNN** : 순환신경망 알고리즘, 반복적이고 순차적인 데이터를 순서대로 처리하는 형태의 알고리즘. 알고리즘 내부의 순환구조가 존재 하여, 과거의 학습을 Weight를 활용해 현재의 Node에 Weight를 반영하는 알고리즘 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obj\n",
    "\n",
    "* Target : Funded (Funding Amount Percent of Target %)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Library Import & Option**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --user catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#from sklearn.tree import export_graphviz\n",
    "#import graphviz\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T17:19:47.117723Z",
     "start_time": "2021-04-06T17:19:36.445032Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import re\n",
    "import os\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import preprocessing \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding\n",
    "from keras.layers import LSTM,RNN, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20502, 73)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Project ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>URL</th>\n",
       "      <th>Backers</th>\n",
       "      <th>Pledge</th>\n",
       "      <th>Funded</th>\n",
       "      <th>Country</th>\n",
       "      <th>CountryCode</th>\n",
       "      <th>ShortDescription</th>\n",
       "      <th>VideoCount</th>\n",
       "      <th>ImageCount</th>\n",
       "      <th>WebSiteURL</th>\n",
       "      <th>WebSiteCode</th>\n",
       "      <th>Tag</th>\n",
       "      <th>TagCode</th>\n",
       "      <th>Goal</th>\n",
       "      <th>Period</th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>Creator</th>\n",
       "      <th>Creator Ind</th>\n",
       "      <th>Location</th>\n",
       "      <th>LocationCode</th>\n",
       "      <th>ShortBio</th>\n",
       "      <th>SNS</th>\n",
       "      <th>Fiends</th>\n",
       "      <th>Created</th>\n",
       "      <th>Created Success</th>\n",
       "      <th>Backed</th>\n",
       "      <th>Backed Success</th>\n",
       "      <th>Total Rewards</th>\n",
       "      <th>Comments Creator</th>\n",
       "      <th>Comments User</th>\n",
       "      <th>Total Updates</th>\n",
       "      <th>Updates Likes</th>\n",
       "      <th>Updates Comments</th>\n",
       "      <th>Backers_Mean</th>\n",
       "      <th>DaysToGo_Mean</th>\n",
       "      <th>Funded_Mean</th>\n",
       "      <th>Pledge_Mean</th>\n",
       "      <th>Rank_Magic_Mean</th>\n",
       "      <th>Rank_Most_Funded_Mean</th>\n",
       "      <th>Rank_Popularity_Mean</th>\n",
       "      <th>Rank_S_End_Date_Mean</th>\n",
       "      <th>Rank_S_Magic_Mean</th>\n",
       "      <th>Rank_S_Most_Funded_Mean</th>\n",
       "      <th>Rank_S_Newest_Mean</th>\n",
       "      <th>Rank_S_Popularity_Mean</th>\n",
       "      <th>Backers_Median</th>\n",
       "      <th>DaysToGo_Median</th>\n",
       "      <th>Funded_Median</th>\n",
       "      <th>Pledge_Median</th>\n",
       "      <th>Rank_Magic_Median</th>\n",
       "      <th>Rank_Most_Funded_Median</th>\n",
       "      <th>Rank_Popularity_Median</th>\n",
       "      <th>Rank_S_End_Date_Median</th>\n",
       "      <th>Rank_S_Magic_Median</th>\n",
       "      <th>Rank_S_Most_Funded_Median</th>\n",
       "      <th>Rank_S_Newest_Median</th>\n",
       "      <th>Rank_S_Popularity_Median</th>\n",
       "      <th>Backers_Sum</th>\n",
       "      <th>DaysToGo_Sum</th>\n",
       "      <th>Funded_Sum</th>\n",
       "      <th>Pledge_Sum</th>\n",
       "      <th>Rank_Magic_Sum</th>\n",
       "      <th>Rank_Most_Funded_Sum</th>\n",
       "      <th>Rank_Popularity_Sum</th>\n",
       "      <th>Rank_S_End_Date_Sum</th>\n",
       "      <th>Rank_S_Magic_Sum</th>\n",
       "      <th>Rank_S_Most_Funded_Sum</th>\n",
       "      <th>Rank_S_Newest_Sum</th>\n",
       "      <th>Rank_S_Popularity_Sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>prjt1</td>\n",
       "      <td>Give Ear Gospel Songs by Michael hathaway — Ki...</td>\n",
       "      <td>https://www.kickstarter.com/projects/dancineag...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Nashville, TN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>In order to finish my album I need 4800.00 to ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No URL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Faith</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4800.00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Mon, 16 Nov 2015</td>\n",
       "      <td>Sun, 06 Dec 2015</td>\n",
       "      <td>Michael Hathaway</td>\n",
       "      <td>Michael hathaway</td>\n",
       "      <td>Camden, TN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>singer songwriter and recording artist of inst...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.277778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>prjt2</td>\n",
       "      <td>Mentally Strong Book by Michelle Jacobi — Kick...</td>\n",
       "      <td>https://www.kickstarter.com/projects/85040221/...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1140.00</td>\n",
       "      <td>11.40</td>\n",
       "      <td>Marsing, ID</td>\n",
       "      <td>1.0</td>\n",
       "      <td>After an MS diagnosis at age 29, Michelle Jaco...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>http://www.mentallystrong.life</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Mon, 16 Nov 2015</td>\n",
       "      <td>Wed, 16 Dec 2015</td>\n",
       "      <td>Michelle Lynne Jacobi</td>\n",
       "      <td>Michelle Jacobi</td>\n",
       "      <td>Marsing, ID</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Michelle Jacobi started to make a name for her...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2873.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>10.214286</td>\n",
       "      <td>1024.523810</td>\n",
       "      <td>2264.523810</td>\n",
       "      <td>1976.380952</td>\n",
       "      <td>1270.047619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1055.00</td>\n",
       "      <td>2555.0</td>\n",
       "      <td>2147.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>214.50</td>\n",
       "      <td>21515.00</td>\n",
       "      <td>47555.0</td>\n",
       "      <td>41504.0</td>\n",
       "      <td>26671.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>prjt3</td>\n",
       "      <td>High Quality Delta 3D Printer For Everybode by...</td>\n",
       "      <td>https://www.kickstarter.com/projects/107477096...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Deutsch, Germany</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Hi, my name is Jörn. I would like to create a ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No URL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3D Printing</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5361.53</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Mon, 16 Nov 2015</td>\n",
       "      <td>Wed, 16 Dec 2015</td>\n",
       "      <td>Jörn Phillipp Optatzi</td>\n",
       "      <td>Jörn Optatzi</td>\n",
       "      <td>Lohmar, Germany</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Ich bin derzeit noch Schüler eines Gymnasiums....</td>\n",
       "      <td>1.0</td>\n",
       "      <td>583.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>186.761905</td>\n",
       "      <td>2247.190476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3298.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3922.0</td>\n",
       "      <td>47191.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>prjt4</td>\n",
       "      <td>United - Helping hand by Marco Da Veiga — Kick...</td>\n",
       "      <td>https://www.kickstarter.com/projects/318423328...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.51</td>\n",
       "      <td>0.10</td>\n",
       "      <td>Oslo, Norway</td>\n",
       "      <td>9.0</td>\n",
       "      <td>I am creating my dream. My love and passion fo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>http://www.soundcloud.com/marcodaveiga</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Music</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34513.70</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Mon, 16 Nov 2015</td>\n",
       "      <td>Wed, 16 Dec 2015</td>\n",
       "      <td>Marco Da Veiga</td>\n",
       "      <td>Marco Da Veiga</td>\n",
       "      <td>Strømmen, Norway</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Marco Da Veiga, born in Norway, but from the C...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4675.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>0.061905</td>\n",
       "      <td>21.484286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1587.523810</td>\n",
       "      <td>2469.571429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>34.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2847.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>1.30</td>\n",
       "      <td>451.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33338.0</td>\n",
       "      <td>51861.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>prjt5</td>\n",
       "      <td>UNCLIP - Quick Release Carabiner/Bottle Opener...</td>\n",
       "      <td>https://www.kickstarter.com/projects/unsettle/...</td>\n",
       "      <td>1510.0</td>\n",
       "      <td>52471.00</td>\n",
       "      <td>1049.42</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Unclip is a Quick Release Carabiner/ Bottle Op...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>http://www.unsettleco.com</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Product Design</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>59.0</td>\n",
       "      <td>Mon, 16 Nov 2015</td>\n",
       "      <td>Fri, 15 Jan 2016</td>\n",
       "      <td>Charlie Yip</td>\n",
       "      <td>Unsettle &amp; Co</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Unsettle &amp; Co is an urban design company based...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>734.617021</td>\n",
       "      <td>30.255319</td>\n",
       "      <td>540.706809</td>\n",
       "      <td>27035.340426</td>\n",
       "      <td>888.978723</td>\n",
       "      <td>294.042553</td>\n",
       "      <td>117.765957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>547.3</td>\n",
       "      <td>27367.00</td>\n",
       "      <td>473.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34527.0</td>\n",
       "      <td>1422.0</td>\n",
       "      <td>25413.22</td>\n",
       "      <td>1270661.00</td>\n",
       "      <td>41782.0</td>\n",
       "      <td>13820.0</td>\n",
       "      <td>5535.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Project ID                                              Title  \\\n",
       "0           0      prjt1  Give Ear Gospel Songs by Michael hathaway — Ki...   \n",
       "1           1      prjt2  Mentally Strong Book by Michelle Jacobi — Kick...   \n",
       "2           2      prjt3  High Quality Delta 3D Printer For Everybode by...   \n",
       "3           3      prjt4  United - Helping hand by Marco Da Veiga — Kick...   \n",
       "4           4      prjt5  UNCLIP - Quick Release Carabiner/Bottle Opener...   \n",
       "\n",
       "                                                 URL  Backers    Pledge  \\\n",
       "0  https://www.kickstarter.com/projects/dancineag...      0.0      0.00   \n",
       "1  https://www.kickstarter.com/projects/85040221/...      4.0   1140.00   \n",
       "2  https://www.kickstarter.com/projects/107477096...      0.0      0.00   \n",
       "3  https://www.kickstarter.com/projects/318423328...      1.0     34.51   \n",
       "4  https://www.kickstarter.com/projects/unsettle/...   1510.0  52471.00   \n",
       "\n",
       "    Funded           Country  CountryCode  \\\n",
       "0     0.00     Nashville, TN          1.0   \n",
       "1    11.40       Marsing, ID          1.0   \n",
       "2     0.00  Deutsch, Germany          6.0   \n",
       "3     0.10      Oslo, Norway          9.0   \n",
       "4  1049.42     San Diego, CA          1.0   \n",
       "\n",
       "                                    ShortDescription  VideoCount  ImageCount  \\\n",
       "0  In order to finish my album I need 4800.00 to ...         0.0         0.0   \n",
       "1  After an MS diagnosis at age 29, Michelle Jaco...         0.0         0.0   \n",
       "2  Hi, my name is Jörn. I would like to create a ...         0.0         0.0   \n",
       "3  I am creating my dream. My love and passion fo...         0.0         3.0   \n",
       "4  Unclip is a Quick Release Carabiner/ Bottle Op...         0.0        39.0   \n",
       "\n",
       "                               WebSiteURL  WebSiteCode             Tag  \\\n",
       "0                                  No URL          0.0           Faith   \n",
       "1          http://www.mentallystrong.life          1.0      Publishing   \n",
       "2                                  No URL          0.0     3D Printing   \n",
       "3  http://www.soundcloud.com/marcodaveiga          1.0           Music   \n",
       "4               http://www.unsettleco.com          1.0  Product Design   \n",
       "\n",
       "   TagCode      Goal  Period         StartDate           EndDate  \\\n",
       "0     13.0   4800.00    19.0  Mon, 16 Nov 2015  Sun, 06 Dec 2015   \n",
       "1     13.0  10000.00    30.0  Mon, 16 Nov 2015  Wed, 16 Dec 2015   \n",
       "2      1.0   5361.53    30.0  Mon, 16 Nov 2015  Wed, 16 Dec 2015   \n",
       "3     11.0  34513.70    30.0  Mon, 16 Nov 2015  Wed, 16 Dec 2015   \n",
       "4      5.0   5000.00    59.0  Mon, 16 Nov 2015  Fri, 15 Jan 2016   \n",
       "\n",
       "                 Creator       Creator Ind          Location  LocationCode  \\\n",
       "0       Michael Hathaway  Michael hathaway        Camden, TN           1.0   \n",
       "1  Michelle Lynne Jacobi   Michelle Jacobi       Marsing, ID           1.0   \n",
       "2  Jörn Phillipp Optatzi      Jörn Optatzi   Lohmar, Germany           6.0   \n",
       "3         Marco Da Veiga    Marco Da Veiga  Strømmen, Norway           9.0   \n",
       "4            Charlie Yip     Unsettle & Co     San Diego, CA           1.0   \n",
       "\n",
       "                                            ShortBio  SNS  Fiends  Created  \\\n",
       "0  singer songwriter and recording artist of inst...  1.0    26.0      1.0   \n",
       "1  Michelle Jacobi started to make a name for her...  1.0  2873.0     11.0   \n",
       "2  Ich bin derzeit noch Schüler eines Gymnasiums....  1.0   583.0      1.0   \n",
       "3  Marco Da Veiga, born in Norway, but from the C...  1.0  4675.0      1.0   \n",
       "4  Unsettle & Co is an urban design company based...  0.0     0.0      1.0   \n",
       "\n",
       "   Created Success  Backed  Backed Success  Total Rewards  Comments Creator  \\\n",
       "0              0.0     0.0             0.0            1.0               0.0   \n",
       "1              0.0     0.0             0.0            9.0               0.0   \n",
       "2              0.0     0.0             0.0            2.0               0.0   \n",
       "3              0.0     0.0             0.0            4.0               0.0   \n",
       "4              0.0     0.0             4.0            8.0              18.0   \n",
       "\n",
       "   Comments User  Total Updates  Updates Likes  Updates Comments  \\\n",
       "0            0.0            0.0            0.0               0.0   \n",
       "1            0.0            0.0            0.0               0.0   \n",
       "2            0.0            0.0            0.0               0.0   \n",
       "3            0.0            7.0            2.0               0.0   \n",
       "4           31.0           13.0           88.0              13.0   \n",
       "\n",
       "   Backers_Mean  DaysToGo_Mean  Funded_Mean   Pledge_Mean  Rank_Magic_Mean  \\\n",
       "0      0.000000      10.277778     0.000000      0.000000         0.000000   \n",
       "1      2.285714      18.333333    10.214286   1024.523810      2264.523810   \n",
       "2      0.000000      18.333333     0.000000      0.000000         0.000000   \n",
       "3      0.619048      18.333333     0.061905     21.484286         0.000000   \n",
       "4    734.617021      30.255319   540.706809  27035.340426       888.978723   \n",
       "\n",
       "   Rank_Most_Funded_Mean  Rank_Popularity_Mean  Rank_S_End_Date_Mean  \\\n",
       "0               0.000000              0.000000                   0.0   \n",
       "1            1976.380952           1270.047619                   0.0   \n",
       "2             186.761905           2247.190476                   0.0   \n",
       "3            1587.523810           2469.571429                   0.0   \n",
       "4             294.042553            117.765957                   0.0   \n",
       "\n",
       "   Rank_S_Magic_Mean  Rank_S_Most_Funded_Mean  Rank_S_Newest_Mean  \\\n",
       "0                0.0                      0.0                 0.0   \n",
       "1                0.0                      0.0                 0.0   \n",
       "2                0.0                      0.0                 0.0   \n",
       "3                0.0                      0.0                 0.0   \n",
       "4                0.0                      0.0                 0.0   \n",
       "\n",
       "   Rank_S_Popularity_Mean  Backers_Median  DaysToGo_Median  Funded_Median  \\\n",
       "0                     0.0             0.0             10.5            0.0   \n",
       "1                     0.0             2.0             19.0           10.5   \n",
       "2                     0.0             0.0             19.0            0.0   \n",
       "3                     0.0             1.0             19.0            0.1   \n",
       "4                     0.0           720.0             28.0          547.3   \n",
       "\n",
       "   Pledge_Median  Rank_Magic_Median  Rank_Most_Funded_Median  \\\n",
       "0           0.00                0.0                      0.0   \n",
       "1        1055.00             2555.0                   2147.0   \n",
       "2           0.00                0.0                      0.0   \n",
       "3          34.34                0.0                      0.0   \n",
       "4       27367.00              473.0                    177.0   \n",
       "\n",
       "   Rank_Popularity_Median  Rank_S_End_Date_Median  Rank_S_Magic_Median  \\\n",
       "0                     0.0                     0.0                  0.0   \n",
       "1                     0.0                     0.0                  0.0   \n",
       "2                  3298.0                     0.0                  0.0   \n",
       "3                  2847.0                     0.0                  0.0   \n",
       "4                    87.0                     0.0                  0.0   \n",
       "\n",
       "   Rank_S_Most_Funded_Median  Rank_S_Newest_Median  Rank_S_Popularity_Median  \\\n",
       "0                        0.0                   0.0                       0.0   \n",
       "1                        0.0                   0.0                       0.0   \n",
       "2                        0.0                   0.0                       0.0   \n",
       "3                        0.0                   0.0                       0.0   \n",
       "4                        0.0                   0.0                       0.0   \n",
       "\n",
       "   Backers_Sum  DaysToGo_Sum  Funded_Sum  Pledge_Sum  Rank_Magic_Sum  \\\n",
       "0          0.0         185.0        0.00        0.00             0.0   \n",
       "1         48.0         385.0      214.50    21515.00         47555.0   \n",
       "2          0.0         385.0        0.00        0.00             0.0   \n",
       "3         13.0         385.0        1.30      451.17             0.0   \n",
       "4      34527.0        1422.0    25413.22  1270661.00         41782.0   \n",
       "\n",
       "   Rank_Most_Funded_Sum  Rank_Popularity_Sum  Rank_S_End_Date_Sum  \\\n",
       "0                   0.0                  0.0                  0.0   \n",
       "1               41504.0              26671.0                  0.0   \n",
       "2                3922.0              47191.0                  0.0   \n",
       "3               33338.0              51861.0                  0.0   \n",
       "4               13820.0               5535.0                  0.0   \n",
       "\n",
       "   Rank_S_Magic_Sum  Rank_S_Most_Funded_Sum  Rank_S_Newest_Sum  \\\n",
       "0               0.0                     0.0                0.0   \n",
       "1               0.0                     0.0                0.0   \n",
       "2               0.0                     0.0                0.0   \n",
       "3               0.0                     0.0                0.0   \n",
       "4               0.0                     0.0                0.0   \n",
       "\n",
       "   Rank_S_Popularity_Sum  \n",
       "0                    0.0  \n",
       "1                    0.0  \n",
       "2                    0.0  \n",
       "3                    0.0  \n",
       "4                    0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1= pd.read_csv('merge_total_data.csv')\n",
    "print(df1.shape)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = df1[['Backers', 'Pledge','Funded', 'VideoCount',\n",
    "       'ImageCount', 'Tag', 'Goal','Period',  'SNS', 'Fiends', 'Created',\n",
    "       'Created Success', 'Backed', 'Backed Success', 'Total Rewards',\n",
    "       'Comments Creator', 'Comments User', 'Total Updates', 'Updates Likes',\n",
    "       'Updates Comments']].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12624, 176)\n",
      "(3156, 176)\n",
      "(12624, 1)\n",
      "(3156, 1)\n"
     ]
    }
   ],
   "source": [
    "X = data1.drop(columns='Funded')\n",
    "Y = data1[['Funded']]\n",
    "\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2, random_state=1234)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_DT = DecisionTreeRegressor()\n",
    "model_RF = RandomForestRegressor()\n",
    "model_GB = GradientBoostingRegressor()\n",
    "model_NN = MLPRegressor()\n",
    "model_CB = CatBoostRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('model_DT', DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best'))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_model = Pipeline( [ ('scaler',StandardScaler()),\n",
    "                        ('model_DT',model_DT )] )\n",
    "pipe_model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best GridSearchCV Parameter :  {'model_DT__max_depth': 4, 'model_DT__min_samples_split': 4}\n",
      "Best GridSearchCV Accuracy :  0.675\n",
      "Test Set Accuracy :  0.669\n"
     ]
    }
   ],
   "source": [
    "parameters = {'model_DT__max_depth':[2,3,4,5,6],\n",
    "              'model_DT__min_samples_split':[2,3,4,5,6]}\n",
    "\n",
    "grid_Tree = GridSearchCV(pipe_model,param_grid=parameters,cv=5,\n",
    "                         refit=True,n_jobs= -1)\n",
    "\n",
    "grid_Tree.fit(X_train,Y_train)\n",
    "estimator = grid_Tree.best_estimator_\n",
    "pred = estimator.predict(X_test)\n",
    "\n",
    "print(\"Best GridSearchCV Parameter : \",grid_Tree.best_params_)\n",
    "print(\"Best GridSearchCV Accuracy : \", (grid_Tree.best_score_).round(3))\n",
    "print('Test Set Accuracy : ', (r2_score(Y_test,pred).round(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: Tree Pages: 1 -->\r\n",
       "<svg width=\"1153pt\" height=\"477pt\"\r\n",
       " viewBox=\"0.00 0.00 1153.00 477.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 473)\">\r\n",
       "<title>Tree</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-473 1149,-473 1149,4 -4,4\"/>\r\n",
       "<!-- 0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\r\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" points=\"722,-469 582,-469 582,-401 722,-401 722,-469\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"652\" y=\"-453.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Goal &lt;= 1.06</text>\r\n",
       "<text text-anchor=\"middle\" x=\"652\" y=\"-438.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">mse = 234443860.888</text>\r\n",
       "<text text-anchor=\"middle\" x=\"652\" y=\"-423.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 12624</text>\r\n",
       "<text text-anchor=\"middle\" x=\"652\" y=\"-408.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = 457.046</text>\r\n",
       "</g>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\r\n",
       "<polygon fill=\"#f9e3d2\" stroke=\"black\" points=\"647,-365 487,-365 487,-297 647,-297 647,-365\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"567\" y=\"-349.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Pledge &lt;= 6992.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"567\" y=\"-334.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">mse = 112177865259.516</text>\r\n",
       "<text text-anchor=\"middle\" x=\"567\" y=\"-319.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 17</text>\r\n",
       "<text text-anchor=\"middle\" x=\"567\" y=\"-304.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = 236094.118</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M624.403,-400.884C617.054,-392.065 609.025,-382.43 601.363,-373.235\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"603.84,-370.741 594.749,-365.299 598.463,-375.222 603.84,-370.741\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"592.486\" y=\"-386.497\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">True</text>\r\n",
       "</g>\r\n",
       "<!-- 10 -->\r\n",
       "<g id=\"node11\" class=\"node\"><title>10</title>\r\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" points=\"796.5,-365 677.5,-365 677.5,-297 796.5,-297 796.5,-365\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"737\" y=\"-349.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Goal &lt;= 7.39</text>\r\n",
       "<text text-anchor=\"middle\" x=\"737\" y=\"-334.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">mse = 8519128.49</text>\r\n",
       "<text text-anchor=\"middle\" x=\"737\" y=\"-319.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 12607</text>\r\n",
       "<text text-anchor=\"middle\" x=\"737\" y=\"-304.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = 139.3</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;10 -->\r\n",
       "<g id=\"edge10\" class=\"edge\"><title>0&#45;&gt;10</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M679.597,-400.884C686.946,-392.065 694.975,-382.43 702.637,-373.235\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"705.537,-375.222 709.251,-365.299 700.16,-370.741 705.537,-375.222\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"711.514\" y=\"-386.497\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">False</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\r\n",
       "<polygon fill=\"#fcf0e7\" stroke=\"black\" points=\"459.5,-261 306.5,-261 306.5,-193 459.5,-193 459.5,-261\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"383\" y=\"-245.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Pledge &lt;= 2546.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"383\" y=\"-230.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">mse = 26580807733.333</text>\r\n",
       "<text text-anchor=\"middle\" x=\"383\" y=\"-215.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 15</text>\r\n",
       "<text text-anchor=\"middle\" x=\"383\" y=\"-200.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = 128360.0</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;2 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M507.26,-296.884C489.495,-287.035 469.893,-276.169 451.61,-266.034\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"453.197,-262.912 442.754,-261.125 449.804,-269.034 453.197,-262.912\"/>\r\n",
       "</g>\r\n",
       "<!-- 9 -->\r\n",
       "<g id=\"node10\" class=\"node\"><title>9</title>\r\n",
       "<polygon fill=\"#e58139\" stroke=\"black\" points=\"637,-253.5 497,-253.5 497,-200.5 637,-200.5 637,-253.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"567\" y=\"-238.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">mse = 14232490000.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"567\" y=\"-223.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 2</text>\r\n",
       "<text text-anchor=\"middle\" x=\"567\" y=\"-208.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = 1044100.0</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;9 -->\r\n",
       "<g id=\"edge9\" class=\"edge\"><title>1&#45;&gt;9</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M567,-296.884C567,-286.326 567,-274.597 567,-263.854\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"570.5,-263.52 567,-253.52 563.5,-263.52 570.5,-263.52\"/>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\r\n",
       "<polygon fill=\"#fefaf8\" stroke=\"black\" points=\"288,-157 142,-157 142,-89 288,-89 288,-157\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"215\" y=\"-141.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Backers &lt;= 27.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"215\" y=\"-126.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">mse = 4247829256.198</text>\r\n",
       "<text text-anchor=\"middle\" x=\"215\" y=\"-111.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 11</text>\r\n",
       "<text text-anchor=\"middle\" x=\"215\" y=\"-96.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = 37672.727</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;3 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>2&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M328.455,-192.884C312.53,-183.214 294.987,-172.563 278.555,-162.587\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"279.923,-159.323 269.558,-157.125 276.29,-165.306 279.923,-159.323\"/>\r\n",
       "</g>\r\n",
       "<!-- 6 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>6</title>\r\n",
       "<polygon fill=\"#f6d1b7\" stroke=\"black\" points=\"449.5,-157 316.5,-157 316.5,-89 449.5,-89 449.5,-157\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"383\" y=\"-141.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Tag_Games &lt;= 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"383\" y=\"-126.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">mse = 3184627500.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"383\" y=\"-111.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 4</text>\r\n",
       "<text text-anchor=\"middle\" x=\"383\" y=\"-96.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = 377750.0</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;6 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>2&#45;&gt;6</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M383,-192.884C383,-184.778 383,-175.982 383,-167.472\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"386.5,-167.299 383,-157.299 379.5,-167.299 386.5,-167.299\"/>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\r\n",
       "<polygon fill=\"#fffefe\" stroke=\"black\" points=\"140,-53 0,-53 0,-0 140,-0 140,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"70\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">mse = 340770617.284</text>\r\n",
       "<text text-anchor=\"middle\" x=\"70\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 9</text>\r\n",
       "<text text-anchor=\"middle\" x=\"70\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = 7977.778</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;4 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>3&#45;&gt;4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M164.286,-88.9485C149.267,-79.1601 132.873,-68.4756 118.029,-58.8015\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"119.779,-55.7645 109.49,-53.2367 115.957,-61.629 119.779,-55.7645\"/>\r\n",
       "</g>\r\n",
       "<!-- 5 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\r\n",
       "<polygon fill=\"#fbeadf\" stroke=\"black\" points=\"271.5,-53 158.5,-53 158.5,-0 271.5,-0 271.5,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"215\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">mse = 5290000.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"215\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 2</text>\r\n",
       "<text text-anchor=\"middle\" x=\"215\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = 171300.0</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;5 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>3&#45;&gt;5</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M215,-88.9485C215,-80.7153 215,-71.848 215,-63.4814\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"218.5,-63.2367 215,-53.2367 211.5,-63.2367 218.5,-63.2367\"/>\r\n",
       "</g>\r\n",
       "<!-- 7 -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>7</title>\r\n",
       "<polygon fill=\"#f6d5bd\" stroke=\"black\" points=\"416,-53 290,-53 290,-0 416,-0 416,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"353\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">mse = 162960000.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"353\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 3</text>\r\n",
       "<text text-anchor=\"middle\" x=\"353\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = 345800.0</text>\r\n",
       "</g>\r\n",
       "<!-- 6&#45;&gt;7 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>6&#45;&gt;7</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M372.507,-88.9485C369.836,-80.5323 366.954,-71.4536 364.246,-62.9243\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"367.532,-61.7089 361.17,-53.2367 360.86,-63.827 367.532,-61.7089\"/>\r\n",
       "</g>\r\n",
       "<!-- 8 -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>8</title>\r\n",
       "<polygon fill=\"#f3c6a5\" stroke=\"black\" points=\"546,-53 434,-53 434,-0 546,-0 546,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"490\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">mse = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"490\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 1</text>\r\n",
       "<text text-anchor=\"middle\" x=\"490\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = 473600.0</text>\r\n",
       "</g>\r\n",
       "<!-- 6&#45;&gt;8 -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>6&#45;&gt;8</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M420.423,-88.9485C431.092,-79.526 442.701,-69.2731 453.325,-59.8906\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"455.681,-62.4798 460.859,-53.2367 451.047,-57.2331 455.681,-62.4798\"/>\r\n",
       "</g>\r\n",
       "<!-- 11 -->\r\n",
       "<g id=\"node12\" class=\"node\"><title>11</title>\r\n",
       "<polygon fill=\"#fefbf9\" stroke=\"black\" points=\"810,-261 664,-261 664,-193 810,-193 810,-261\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"737\" y=\"-245.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Updates Likes &lt;= 1.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"737\" y=\"-230.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">mse = 5813441996.667</text>\r\n",
       "<text text-anchor=\"middle\" x=\"737\" y=\"-215.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 15</text>\r\n",
       "<text text-anchor=\"middle\" x=\"737\" y=\"-200.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = 33455.0</text>\r\n",
       "</g>\r\n",
       "<!-- 10&#45;&gt;11 -->\r\n",
       "<g id=\"edge11\" class=\"edge\"><title>10&#45;&gt;11</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M737,-296.884C737,-288.778 737,-279.982 737,-271.472\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"740.5,-271.299 737,-261.299 733.5,-271.299 740.5,-271.299\"/>\r\n",
       "</g>\r\n",
       "<!-- 16 -->\r\n",
       "<g id=\"node17\" class=\"node\"><title>16</title>\r\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" points=\"1005,-261 869,-261 869,-193 1005,-193 1005,-261\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"937\" y=\"-245.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Pledge &lt;= 2852685.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"937\" y=\"-230.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">mse = 280348.787</text>\r\n",
       "<text text-anchor=\"middle\" x=\"937\" y=\"-215.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 12592</text>\r\n",
       "<text text-anchor=\"middle\" x=\"937\" y=\"-200.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = 99.613</text>\r\n",
       "</g>\r\n",
       "<!-- 10&#45;&gt;16 -->\r\n",
       "<g id=\"edge16\" class=\"edge\"><title>10&#45;&gt;16</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M796.736,-299.535C817.576,-288.906 841.217,-276.849 863.072,-265.703\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"864.673,-268.816 871.991,-261.154 861.493,-262.58 864.673,-268.816\"/>\r\n",
       "</g>\r\n",
       "<!-- 12 -->\r\n",
       "<g id=\"node13\" class=\"node\"><title>12</title>\r\n",
       "<polygon fill=\"#fffefe\" stroke=\"black\" points=\"690.5,-157 557.5,-157 557.5,-89 690.5,-89 690.5,-157\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"624\" y=\"-141.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Tag_Rock &lt;= 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"624\" y=\"-126.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">mse = 81679723.077</text>\r\n",
       "<text text-anchor=\"middle\" x=\"624\" y=\"-111.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 13</text>\r\n",
       "<text text-anchor=\"middle\" x=\"624\" y=\"-96.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = 4305.0</text>\r\n",
       "</g>\r\n",
       "<!-- 11&#45;&gt;12 -->\r\n",
       "<g id=\"edge12\" class=\"edge\"><title>11&#45;&gt;12</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M700.312,-192.884C690.148,-183.709 679.005,-173.65 668.45,-164.123\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"670.659,-161.402 660.89,-157.299 665.968,-166.598 670.659,-161.402\"/>\r\n",
       "</g>\r\n",
       "<!-- 15 -->\r\n",
       "<g id=\"node16\" class=\"node\"><title>15</title>\r\n",
       "<polygon fill=\"#f9e4d5\" stroke=\"black\" points=\"841.5,-149.5 708.5,-149.5 708.5,-96.5 841.5,-96.5 841.5,-149.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"775\" y=\"-134.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">mse = 1645924900.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"775\" y=\"-119.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 2</text>\r\n",
       "<text text-anchor=\"middle\" x=\"775\" y=\"-104.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = 222930.0</text>\r\n",
       "</g>\r\n",
       "<!-- 11&#45;&gt;15 -->\r\n",
       "<g id=\"edge15\" class=\"edge\"><title>11&#45;&gt;15</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M749.338,-192.884C753.353,-182.106 757.823,-170.108 761.892,-159.184\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"765.281,-160.113 765.493,-149.52 758.722,-157.669 765.281,-160.113\"/>\r\n",
       "</g>\r\n",
       "<!-- 13 -->\r\n",
       "<g id=\"node14\" class=\"node\"><title>13</title>\r\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" points=\"683.5,-53 564.5,-53 564.5,-0 683.5,-0 683.5,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"624\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">mse = 8880051.91</text>\r\n",
       "<text text-anchor=\"middle\" x=\"624\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 12</text>\r\n",
       "<text text-anchor=\"middle\" x=\"624\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = 1830.417</text>\r\n",
       "</g>\r\n",
       "<!-- 12&#45;&gt;13 -->\r\n",
       "<g id=\"edge13\" class=\"edge\"><title>12&#45;&gt;13</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M624,-88.9485C624,-80.7153 624,-71.848 624,-63.4814\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"627.5,-63.2367 624,-53.2367 620.5,-63.2367 627.5,-63.2367\"/>\r\n",
       "</g>\r\n",
       "<!-- 14 -->\r\n",
       "<g id=\"node15\" class=\"node\"><title>14</title>\r\n",
       "<polygon fill=\"#fefbf9\" stroke=\"black\" points=\"806.5,-53 701.5,-53 701.5,-0 806.5,-0 806.5,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"754\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">mse = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"754\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 1</text>\r\n",
       "<text text-anchor=\"middle\" x=\"754\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = 34000.0</text>\r\n",
       "</g>\r\n",
       "<!-- 12&#45;&gt;14 -->\r\n",
       "<g id=\"edge14\" class=\"edge\"><title>12&#45;&gt;14</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M669.468,-88.9485C682.681,-79.3431 697.082,-68.8747 710.192,-59.345\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"712.564,-61.9477 718.595,-53.2367 708.448,-56.2856 712.564,-61.9477\"/>\r\n",
       "</g>\r\n",
       "<!-- 17 -->\r\n",
       "<g id=\"node18\" class=\"node\"><title>17</title>\r\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" points=\"1014.5,-157 859.5,-157 859.5,-89 1014.5,-89 1014.5,-157\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"937\" y=\"-141.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Comments User &lt;= 61.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"937\" y=\"-126.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">mse = 205202.57</text>\r\n",
       "<text text-anchor=\"middle\" x=\"937\" y=\"-111.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 12591</text>\r\n",
       "<text text-anchor=\"middle\" x=\"937\" y=\"-96.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = 97.17</text>\r\n",
       "</g>\r\n",
       "<!-- 16&#45;&gt;17 -->\r\n",
       "<g id=\"edge17\" class=\"edge\"><title>16&#45;&gt;17</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M937,-192.884C937,-184.778 937,-175.982 937,-167.472\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"940.5,-167.299 937,-157.299 933.5,-167.299 940.5,-167.299\"/>\r\n",
       "</g>\r\n",
       "<!-- 20 -->\r\n",
       "<g id=\"node21\" class=\"node\"><title>20</title>\r\n",
       "<polygon fill=\"#fefbf9\" stroke=\"black\" points=\"1145,-149.5 1033,-149.5 1033,-96.5 1145,-96.5 1145,-149.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1089\" y=\"-134.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">mse = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1089\" y=\"-119.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 1</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1089\" y=\"-104.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = 30862.76</text>\r\n",
       "</g>\r\n",
       "<!-- 16&#45;&gt;20 -->\r\n",
       "<g id=\"edge20\" class=\"edge\"><title>16&#45;&gt;20</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M986.35,-192.884C1004.38,-180.786 1024.7,-167.151 1042.47,-155.224\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1044.62,-157.998 1050.97,-149.52 1040.72,-152.186 1044.62,-157.998\"/>\r\n",
       "</g>\r\n",
       "<!-- 18 -->\r\n",
       "<g id=\"node19\" class=\"node\"><title>18</title>\r\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" points=\"970.5,-53 851.5,-53 851.5,-0 970.5,-0 970.5,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"911\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">mse = 111378.173</text>\r\n",
       "<text text-anchor=\"middle\" x=\"911\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 12248</text>\r\n",
       "<text text-anchor=\"middle\" x=\"911\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = 74.753</text>\r\n",
       "</g>\r\n",
       "<!-- 17&#45;&gt;18 -->\r\n",
       "<g id=\"edge18\" class=\"edge\"><title>17&#45;&gt;18</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M927.906,-88.9485C925.591,-80.5323 923.093,-71.4536 920.746,-62.9243\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"924.108,-61.9499 918.081,-53.2367 917.359,-63.8069 924.108,-61.9499\"/>\r\n",
       "</g>\r\n",
       "<!-- 19 -->\r\n",
       "<g id=\"node20\" class=\"node\"><title>19</title>\r\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" points=\"1115,-53 989,-53 989,-0 1115,-0 1115,-53\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1052\" y=\"-37.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">mse = 2896804.613</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1052\" y=\"-22.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">samples = 343</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1052\" y=\"-7.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">value = 897.656</text>\r\n",
       "</g>\r\n",
       "<!-- 17&#45;&gt;19 -->\r\n",
       "<g id=\"edge19\" class=\"edge\"><title>17&#45;&gt;19</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M977.221,-88.9485C988.799,-79.4346 1001.41,-69.074 1012.92,-59.6175\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1015.18,-62.2897 1020.68,-53.2367 1010.73,-56.8814 1015.18,-62.2897\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x258b6a2b4c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "export_graphviz(estimator, out_file='tree1.dot',\n",
    "                feature_names=X.columns,impurity = True, filled = True,class_names=True)\n",
    "\n",
    "os.environ[\"PATH\"] += os.pathsep + \"C:/Program Files (x86)/Graphviz2.38/bin/\"\n",
    "\n",
    "with open(\"tree1.dot\",encoding='utf-8') as f:\n",
    "    dot_graph = f.read()\n",
    "display(graphviz.Source(dot_graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:715: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best GridSearchCV Parameter :  {'max_depth': 7, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Best GridSearchCV Accuracy :  0.794\n",
      "Test Set Accuracy :  0.45\n"
     ]
    }
   ],
   "source": [
    "model = model_RF\n",
    "parameters = {'max_depth':[2,3,4,5,6,7],'min_samples_split':[2,3],\n",
    "              'n_estimators':[10,50,100]}\n",
    "grid_Tree = GridSearchCV(model,param_grid=parameters,cv=5,\n",
    "                         refit=True)\n",
    "\n",
    "grid_Tree.fit(X_train,Y_train)\n",
    "estimator = grid_Tree.best_estimator_\n",
    "pred = estimator.predict(X_test)\n",
    "print(\"Best GridSearchCV Parameter : \",grid_Tree.best_params_)\n",
    "print(\"Best GridSearchCV Accuracy : \", (grid_Tree.best_score_).round(3))\n",
    "print('Test Set Accuracy : ', (r2_score(Y_test,pred).round(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance\n",
      "Backers  :  0.113\n",
      "Pledge  :  0.332\n",
      "Goal  :  0.361\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature Importance\")\n",
    "importance_list = []\n",
    "value_list = []\n",
    "for name,value in zip(X.columns,estimator.feature_importances_):\n",
    "    if value >=0.05:\n",
    "        print(name ,\" : \", value.round(3))\n",
    "        importance_list.append(name)\n",
    "        value_list.append(value)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x258b5b96b08>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3AAAAEvCAYAAAAErSPcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAX40lEQVR4nO3de7BuZ10f8O/XEwMqFkFOHScXEjRYg2gYDqGWiqNyCaUlOIUaptZQmUlxiNIyWsNgQxsHL9DRTm0cSGu8TWm4tfZ0Go2Uq3LznEAAg2Y4RIFjmBIIA+UaT/j1j/2GedmecN5DTrKzsj+fmT17rWc9z7N/a+bMOu/3fda73s5MAAAAuOf7mp0uAAAAgM0IcAAAAAshwAEAACyEAAcAALAQAhwAAMBCCHAAAAALcdJOF7Ddgx70oDnjjDN2ugwAAIAdce21135sZvYe7dg9LsCdccYZOXjw4E6XAQAAsCPafvCOjrmFEgAAYCEEOAAAgIUQ4AAAABZCgAMAAFgIAQ4AAGAhBDgAAICFEOAAAAAWQoADAABYCAEOAABgIQQ4AACAhRDgAAAAFuKknS4AAIDNPObXHrPTJcCu9ZaffMtOl5DEChwAAMBiCHAAAAALIcABAAAsxEYBru15bW9oe6jtJUc5/uy27217Xds/bnv2qv2Mtp9btV/X9qUn+gQAAAB2i2M+xKTtniSXJ3l8ksNJDrTdPzPvW+v28pl56ar/U5L8SpLzVsc+MDPnnNiyAQAAdp9NVuDOTXJoZm6cmVuTXJXk/PUOM/Optd1vSDInrkQAAACSzQLcKUk+vLZ/eNX2Zdo+p+0Hkrw4yU+tHTqz7bvavqnt992pagEAAHaxTQJcj9L2N1bYZubymfm2JD+b5OdWzR9JcvrMPCLJ85K8vO3f+ht/oL2o7cG2B2+++ebNqwcAANhFNglwh5OctrZ/apKbvkL/q5I8NUlm5gsz8/HV9rVJPpDkodsHzMwVM7NvZvbt3bt309oBAAB2lU0C3IEkZ7U9s+3JSS5Isn+9Q9uz1nafnOT9q/a9q4egpO1DkpyV5MYTUTgAAMBuc8ynUM7MkbYXJ7kmyZ4kV87M9W0vS3JwZvYnubjt45L8dZJPJLlwNfyxSS5reyTJbUmePTO33BUnAgAAcG93zACXJDNzdZKrt7Vdurb93DsY95okr7kzBQIAALBloy/yBgAAYOcJcAAAAAshwAEAACyEAAcAALAQAhwAAMBCCHAAAAALIcABAAAsxEbfAwfA8fnQZQ/f6RJg1zr90vfudAkAdxkrcAAAAAshwAEAACyEAAcAALAQAhwAAMBCCHAAAAALIcABAAAshAAHAACwEAIcAADAQghwAAAACyHAAQAALIQABwAAsBACHAAAwEIIcAAAAAshwAEAACyEAAcAALAQAhwAAMBCCHAAAAALIcABAAAshAAHAACwEBsFuLbntb2h7aG2lxzl+LPbvrftdW3/uO3Za8eevxp3Q9snnsjiAQAAdpNjBri2e5JcnuRJSc5O8oz1gLby8pl5+Myck+TFSX5lNfbsJBckeViS85L8+mo+AAAAjtMmK3DnJjk0MzfOzK1Jrkpy/nqHmfnU2u43JJnV9vlJrpqZL8zMXyQ5tJoPAACA43TSBn1OSfLhtf3DSR69vVPb5yR5XpKTk/zg2ti3bxt7yldVKQAAwC63yQpcj9I2f6Nh5vKZ+bYkP5vk545nbNuL2h5se/Dmm2/eoCQAAIDdZ5MAdzjJaWv7pya56Sv0vyrJU49n7MxcMTP7Zmbf3r17NygJAABg99kkwB1IclbbM9uenK2Hkuxf79D2rLXdJyd5/2p7f5IL2t6n7ZlJzkryJ3e+bAAAgN3nmJ+Bm5kjbS9Ock2SPUmunJnr216W5ODM7E9ycdvHJfnrJJ9IcuFq7PVtX5nkfUmOJHnOzNx2F50LAADAvdomDzHJzFyd5OptbZeubT/3K4x9UZIXfbUFAgAAsGWjL/IGAABg5wlwAAAACyHAAQAALIQABwAAsBACHAAAwEIIcAAAAAshwAEAACyEAAcAALAQAhwAAMBCCHAAAAALIcABAAAshAAHAACwEAIcAADAQghwAAAACyHAAQAALIQABwAAsBACHAAAwEIIcAAAAAshwAEAACyEAAcAALAQAhwAAMBCCHAAAAALIcABAAAshAAHAACwEAIcAADAQghwAAAACyHAAQAALMRGAa7teW1vaHuo7SVHOf68tu9r+562r2v74LVjt7W9bvWz/0QWDwAAsJucdKwObfckuTzJ45McTnKg7f6Zed9at3cl2Tczn237E0lenORHVsc+NzPnnOC6AQAAdp1NVuDOTXJoZm6cmVuTXJXk/PUOM/OGmfnsavftSU49sWUCAACwSYA7JcmH1/YPr9ruyLOS/P7a/n3bHmz79rZPPdqAthet+hy8+eabNygJAABg9znmLZRJepS2OWrH9keT7Evy/WvNp8/MTW0fkuT1bd87Mx/4sslmrkhyRZLs27fvqHMDAADsdpuswB1Octra/qlJbtreqe3jkrwgyVNm5gu3t8/MTavfNyZ5Y5JH3Il6AQAAdq1NAtyBJGe1PbPtyUkuSPJlT5Ns+4gkL8tWePvoWvsD2t5ntf2gJI9Jsv7wEwAAADZ0zFsoZ+ZI24uTXJNkT5IrZ+b6tpclOTgz+5O8JMn9kryqbZJ8aGaekuQ7k7ys7RezFRZ/advTKwEAANjQJp+By8xcneTqbW2Xrm0/7g7GvTXJw+9MgQAAAGzZ6Iu8AQAA2HkCHAAAwEIIcAAAAAshwAEAACyEAAcAALAQAhwAAMBCCHAAAAALIcABAAAshAAHAACwEAIcAADAQghwAAAACyHAAQAALIQABwAAsBACHAAAwEIIcAAAAAshwAEAACyEAAcAALAQAhwAAMBCCHAAAAALIcABAAAshAAHAACwEAIcAADAQghwAAAACyHAAQAALIQABwAAsBACHAAAwEJsFODantf2hraH2l5ylOPPa/u+tu9p+7q2D147dmHb969+LjyRxQMAAOwmxwxwbfckuTzJk5KcneQZbc/e1u1dSfbNzHcneXWSF6/GPjDJC5M8Osm5SV7Y9gEnrnwAAIDdY5MVuHOTHJqZG2fm1iRXJTl/vcPMvGFmPrvafXuSU1fbT0zy2pm5ZWY+keS1Sc47MaUDAADsLpsEuFOSfHht//Cq7Y48K8nvf5VjAQAAuAMnbdCnR2mbo3ZsfzTJviTffzxj216U5KIkOf300zcoCQAAYPfZZAXucJLT1vZPTXLT9k5tH5fkBUmeMjNfOJ6xM3PFzOybmX179+7dtHYAAIBdZZMAdyDJWW3PbHtykguS7F/v0PYRSV6WrfD20bVD1yR5QtsHrB5e8oRVGwAAAMfpmLdQzsyRthdnK3jtSXLlzFzf9rIkB2dmf5KXJLlfkle1TZIPzcxTZuaWtj+frRCYJJfNzC13yZkAAADcy23yGbjMzNVJrt7Wduna9uO+wtgrk1z51RYIAADAlo2+yBsAAICdJ8ABAAAshAAHAACwEAIcAADAQghwAAAACyHAAQAALIQABwAAsBACHAAAwEIIcAAAAAshwAEAACyEAAcAALAQAhwAAMBCCHAAAAALIcABAAAshAAHAACwEAIcAADAQghwAAAACyHAAQAALIQABwAAsBACHAAAwEIIcAAAAAshwAEAACyEAAcAALAQAhwAAMBCCHAAAAALIcABAAAshAAHAACwEBsFuLbntb2h7aG2lxzl+GPbvrPtkbZP23bstrbXrX72n6jCAQAAdpuTjtWh7Z4klyd5fJLDSQ603T8z71vr9qEkz0zy00eZ4nMzc84JqBUAAGBXO2aAS3JukkMzc2OStL0qyflJvhTgZuYvV8e+eBfUCAAAQDa7hfKUJB9e2z+8atvUfdsebPv2tk89ruoAAAD4kk1W4HqUtjmOv3H6zNzU9iFJXt/2vTPzgS/7A+1FSS5KktNPP/04pgYAANg9NlmBO5zktLX9U5PctOkfmJmbVr9vTPLGJI84Sp8rZmbfzOzbu3fvplMDAADsKpsEuANJzmp7ZtuTk1yQZKOnSbZ9QNv7rLYflOQxWfvsHAAAAJs7ZoCbmSNJLk5yTZI/S/LKmbm+7WVtn5IkbR/V9nCSpyd5WdvrV8O/M8nBtu9O8oYkv7Tt6ZUAAABsaJPPwGVmrk5y9ba2S9e2D2Tr1srt496a5OF3skYAAACy4Rd5AwAAsPMEOAAAgIUQ4AAAABZCgAMAAFgIAQ4AAGAhBDgAAICFEOAAAAAWQoADAABYCAEOAABgIQQ4AACAhRDgAAAAFkKAAwAAWAgBDgAAYCEEOAAAgIUQ4AAAABZCgAMAAFgIAQ4AAGAhBDgAAICFEOAAAAAWQoADAABYCAEOAABgIQQ4AACAhThppwvYaY/8md/Z6RJg17r2JT+20yUAACyKFTgAAICFEOAAAAAWQoADAABYCAEOAABgITYKcG3Pa3tD20NtLznK8ce2fWfbI22ftu3YhW3fv/q58EQVDgAAsNscM8C13ZPk8iRPSnJ2kme0PXtbtw8leWaSl28b+8AkL0zy6CTnJnlh2wfc+bIBAAB2n01W4M5NcmhmbpyZW5NcleT89Q4z85cz854kX9w29olJXjszt8zMJ5K8Nsl5J6BuAACAXWeTAHdKkg+v7R9etW3izowFAABgzSYBrkdpmw3n32hs24vaHmx78Oabb95wagAAgN1lkwB3OMlpa/unJrlpw/k3GjszV8zMvpnZt3fv3g2nBgAA2F02CXAHkpzV9sy2Jye5IMn+Dee/JskT2j5g9fCSJ6zaAAAAOE7HDHAzcyTJxdkKXn+W5JUzc33by9o+JUnaPqrt4SRPT/Kyttevxt6S5OezFQIPJLls1QYAAMBxOmmTTjNzdZKrt7VdurZ9IFu3Rx5t7JVJrrwTNQIAAJANv8gbAACAnSfAAQAALIQABwAAsBACHAAAwEIIcAAAAAshwAEAACyEAAcAALAQAhwAAMBCCHAAAAALIcABAAAshAAHAACwEAIcAADAQghwAAAACyHAAQAALIQABwAAsBACHAAAwEIIcAAAAAshwAEAACyEAAcAALAQAhwAAMBCCHAAAAALIcABAAAshAAHAACwEAIcAADAQghwAAAACyHAAQAALIQABwAAsBAbBbi257W9oe2htpcc5fh92r5idfwdbc9YtZ/R9nNtr1v9vPTElg8AALB7nHSsDm33JLk8yeOTHE5yoO3+mXnfWrdnJfnEzHx72wuS/HKSH1kd+8DMnHOC6wYAANh1NlmBOzfJoZm5cWZuTXJVkvO39Tk/yW+vtl+d5Ifa9sSVCQAAwCYB7pQkH17bP7xqO2qfmTmS5JNJvnl17My272r7prbfdyfrBQAA2LWOeQtlkqOtpM2GfT6S5PSZ+XjbRyb5vbYPm5lPfdng9qIkFyXJ6aefvkFJAAAAu88mK3CHk5y2tn9qkpvuqE/bk5LcP8ktM/OFmfl4kszMtUk+kOSh2//AzFwxM/tmZt/evXuP/ywAAAB2gU0C3IEkZ7U9s+3JSS5Isn9bn/1JLlxtPy3J62dm2u5dPQQlbR+S5KwkN56Y0gEAAHaXY95COTNH2l6c5Joke5JcOTPXt70sycGZ2Z/kN5L8bttDSW7JVshLkscmuaztkSS3JXn2zNxyV5wIAADAvd0mn4HLzFyd5OptbZeubX8+ydOPMu41SV5zJ2sEAAAgG36RNwAAADtPgAMAAFgIAQ4AAGAhBDgAAICFEOAAAAAWQoADAABYCAEOAABgIQQ4AACAhRDgAAAAFkKAAwAAWAgBDgAAYCEEOAAAgIUQ4AAAABZCgAMAAFgIAQ4AAGAhBDgAAICFEOAAAAAWQoADAABYCAEOAABgIQQ4AACAhRDgAAAAFkKAAwAAWAgBDgAAYCEEOAAAgIUQ4AAAABZCgAMAAFgIAQ4AAGAhNgpwbc9re0PbQ20vOcrx+7R9xer4O9qesXbs+av2G9o+8cSVDgAAsLscM8C13ZPk8iRPSnJ2kme0PXtbt2cl+cTMfHuSX03yy6uxZye5IMnDkpyX5NdX8wEAAHCcNlmBOzfJoZm5cWZuTXJVkvO39Tk/yW+vtl+d5IfadtV+1cx8YWb+Ismh1XwAAAAcp00C3ClJPry2f3jVdtQ+M3MkySeTfPOGYwEAANjASRv06VHaZsM+m4xN24uSXLTa/XTbGzaoC5LkQUk+ttNF8NXpv79wp0uAO+LasmQvPNrLD7hHcG1ZsP7U3XptefAdHdgkwB1Octra/qlJbrqDPofbnpTk/klu2XBsZuaKJFdsUAt8mbYHZ2bfTtcB3Lu4tgB3BdcWToRNbqE8kOSstme2PTlbDyXZv63P/iS3v5X+tCSvn5lZtV+wekrlmUnOSvInJ6Z0AACA3eWYK3Azc6TtxUmuSbInyZUzc33by5IcnJn9SX4jye+2PZStlbcLVmOvb/vKJO9LciTJc2bmtrvoXAAAAO7VurVQBsvU9qLVLbgAJ4xrC3BXcG3hRBDgAAAAFmKTz8ABAABwDyDAcbdre1vb69q+u+072/69r3Ke32r7tBNdH7B8a9eZP237qrZfv2r/9HHO82/b/vRdUyVwb9H2W9q+vO2Nba9t+7a2P/xVzHNG2z+9K2rk3kOAYyd8bmbOmZnvSfL8JL94dxew+roL4N7r9uvMdyW5Ncmzd7og4N6pbZP8XpI3z8xDZuaR2Xqg36k7Wxn3VgIcO+1vJflEkrS9X9vXrVbl3tv2/Ns7tf2xtu9Zrdr97vZJ2v78akXua9o+su2bVu+AXdP2W1d93tj2F9q+Kclz2z599e78u9u++e46YeBu90dJvn17Y9ufaXtgdW35d2vtL2h7Q9v/k+Q71tofter7trYvuf1d8rZ7Vvu3z/Uv7o6TAu4xfjDJrTPz0tsbZuaDM/Nrbe/b9jdXr2ve1fYHki+ttP3R6jXPV303EruTVQh2wte1vS7JfZN8a7YufEny+SQ/PDOfavugJG9vuz/J2UlekOQxM/Oxtg9cn6zti7P15fH/PFv/pn8tyfkzc3PbH0nyoiQ/vur+TTPz/atx703yxJn5q7bfdFeeMLAzVqvtT0ryB9van5Ct7yY9N0mT7G/72CSfydY754/I1vXknUmuXQ37zSQXzcxb2/7S2nTPSvLJmXlU2/skeUvbP5yZv7gLTw2453hYtq4VR/OcJJmZh7f9O0n+sO1Dk3w0yeNn5vNtz0ry35L4gm82IsCxEz43M+ckSdvvTfI7bb8rWy+ifmH1IuqLSU5J8i3ZCnivnpmPJcnM3LI2179J8o6ZuWg133ck+a4kr926oyF7knxkrf8r1rbfkuS3Vt9V+N9P+FkCO+n2N4qSrRW439h2/Amrn3et9u+XrUD3jUn+x8x8NklWbyJl9SbPN87MW1f9X57kH67N9d1rn8m9/2ouAQ52obaXJ/n72bp9+3C23ljOzPx52w8meWiSDyb5T23PSXLbqg02IsCxo2bmbavVtr1J/sHq9yNn5q/b/mW2Vuma5I6+7+JAkke2feAq2DXJ9TPzvXfQ/zNrf/vZbR+d5MlJrmt7zsx8/IScGLDTvvRG0R1okl+cmZd9WWP7L3P0602PMddPzsw1x18mcC9wfZJ/fPvOzDxn9drmYJK/uoMx/yrJ/03yPdn6SNPn7+oiuffwGTh21Op2gj1JPp6td60/ugpvP5Dkwatur0vyT9p+82rM+i2Uf5Dkl5L877bfmOSGJHtXK3tp+7VtH3YHf/vbZuYdM3Npko8lOe3EnyFwD3VNkh9ve78kaXtK27+d5M1Jfrjt162uKf8oSWbmE0n+X9u/uxp/wba5fqLt167memjbb7i7TgTYca9Pct+2P7HW9vWr329O8k+TrWtDktOz9Vrl/kk+MjNfTPLPsvVaCDZiBY6dsH5rU5NcODO3tf2vSf5X24NJrkvy50kyM9e3fVGSN7W9LVu3PD3z9slm5lWrF1r7s7WK97Qk/7Ht/bP1b/w/ZOvdse1esrrvvNkKie8+8acK3BPNzB+2/c4kb1vdbv3pJD86M+9s+4psXYM+mK3bL2/3rCT/ue1nkrwxySdX7f8lyRlJ3rl6Gt3NSZ56d5wHsPNmZto+Ncmvtv3X2boGfCbJzyb5n0leuvrc/ZEkz5yZL7T99SSvafv0JG/I2h1CcCyduaM70wCA27W938x8erV9SZJvnZnn7nBZAOwyVuAAYDNPbvv8bP3f+cGs3QkAAHcXK3AAAAAL4SEmAAAACyHAAQAALIQABwAAsBACHAAAwEIIcAAAAAshwAEAACzE/wdWwow/0xEDOgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[15,5])\n",
    "sns.barplot(y=value_list, x=importance_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cat Boosting Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 11300.7870894\ttotal: 62ms\tremaining: 0us\n",
      "0:\tlearn: 15801.8525405\ttotal: 1.23ms\tremaining: 0us\n",
      "0:\tlearn: 15848.5282746\ttotal: 2.3ms\tremaining: 0us\n",
      "0:\tlearn: 13464.5716169\ttotal: 1.38ms\tremaining: 0us\n",
      "0:\tlearn: 16503.9859861\ttotal: 1.36ms\tremaining: 0us\n",
      "0:\tlearn: 10731.5008712\ttotal: 1.16ms\tremaining: 0us\n",
      "0:\tlearn: 15215.3899460\ttotal: 1.22ms\tremaining: 0us\n",
      "0:\tlearn: 15249.2563788\ttotal: 1.16ms\tremaining: 0us\n",
      "0:\tlearn: 12848.0374599\ttotal: 1.18ms\tremaining: 0us\n",
      "0:\tlearn: 15904.3661176\ttotal: 1.2ms\tremaining: 0us\n",
      "0:\tlearn: 10172.9697494\ttotal: 1.17ms\tremaining: 0us\n",
      "0:\tlearn: 14635.8879937\ttotal: 1.2ms\tremaining: 0us\n",
      "0:\tlearn: 14657.1549834\ttotal: 1.22ms\tremaining: 0us\n",
      "0:\tlearn: 12249.6349733\ttotal: 1.19ms\tremaining: 0us\n",
      "0:\tlearn: 15314.5289020\ttotal: 1.19ms\tremaining: 0us\n",
      "0:\tlearn: 9627.0659640\ttotal: 1.18ms\tremaining: 0us\n",
      "0:\tlearn: 14064.2072631\ttotal: 1.3ms\tremaining: 0us\n",
      "0:\tlearn: 14073.1293120\ttotal: 1.16ms\tremaining: 0us\n",
      "0:\tlearn: 11672.1533263\ttotal: 1.24ms\tremaining: 0us\n",
      "0:\tlearn: 14735.6492595\ttotal: 1.17ms\tremaining: 0us\n",
      "0:\tlearn: 11300.7870894\ttotal: 1.25ms\tremaining: 1.25ms\n",
      "1:\tlearn: 10766.8454870\ttotal: 2.36ms\tremaining: 0us\n",
      "0:\tlearn: 15801.8525405\ttotal: 1.21ms\tremaining: 1.21ms\n",
      "1:\tlearn: 15241.7224013\ttotal: 2.24ms\tremaining: 0us\n",
      "0:\tlearn: 15848.5282746\ttotal: 1.18ms\tremaining: 1.18ms\n",
      "1:\tlearn: 15276.5742953\ttotal: 2.26ms\tremaining: 0us\n",
      "0:\tlearn: 13464.5716169\ttotal: 1.21ms\tremaining: 1.21ms\n",
      "1:\tlearn: 12888.6725604\ttotal: 2.31ms\tremaining: 0us\n",
      "0:\tlearn: 16503.9859861\ttotal: 1.14ms\tremaining: 1.14ms\n",
      "1:\tlearn: 15673.3060628\ttotal: 2.23ms\tremaining: 0us\n",
      "0:\tlearn: 10731.5008712\ttotal: 1.17ms\tremaining: 1.17ms\n",
      "1:\tlearn: 9762.4641231\ttotal: 2.27ms\tremaining: 0us\n",
      "0:\tlearn: 15215.3899460\ttotal: 1.22ms\tremaining: 1.22ms\n",
      "1:\tlearn: 14165.5369608\ttotal: 2.24ms\tremaining: 0us\n",
      "0:\tlearn: 15249.2563788\ttotal: 1.19ms\tremaining: 1.19ms\n",
      "1:\tlearn: 14178.1737171\ttotal: 2.27ms\tremaining: 0us\n",
      "0:\tlearn: 12848.0374599\ttotal: 1.11ms\tremaining: 1.11ms\n",
      "1:\tlearn: 11824.1722047\ttotal: 2.11ms\tremaining: 0us\n",
      "0:\tlearn: 15904.3661176\ttotal: 1.14ms\tremaining: 1.14ms\n",
      "1:\tlearn: 14315.8790078\ttotal: 2.17ms\tremaining: 0us\n",
      "0:\tlearn: 10172.9697494\ttotal: 1.16ms\tremaining: 1.16ms\n",
      "1:\tlearn: 9237.6947193\ttotal: 2.21ms\tremaining: 0us\n",
      "0:\tlearn: 14635.8879937\ttotal: 1.18ms\tremaining: 1.18ms\n",
      "1:\tlearn: 13165.8826185\ttotal: 2.19ms\tremaining: 0us\n",
      "0:\tlearn: 14657.1549834\ttotal: 1.18ms\tremaining: 1.18ms\n",
      "1:\tlearn: 13158.8627401\ttotal: 2.52ms\tremaining: 0us\n",
      "0:\tlearn: 12249.6349733\ttotal: 1.19ms\tremaining: 1.19ms\n",
      "1:\tlearn: 11380.7648036\ttotal: 2.26ms\tremaining: 0us\n",
      "0:\tlearn: 15314.5289020\ttotal: 1.26ms\tremaining: 1.26ms\n",
      "1:\tlearn: 13039.3500528\ttotal: 2.4ms\tremaining: 0us\n",
      "0:\tlearn: 9627.0659640\ttotal: 1.13ms\tremaining: 1.13ms\n",
      "1:\tlearn: 8458.5394388\ttotal: 2.21ms\tremaining: 0us\n",
      "0:\tlearn: 14064.2072631\ttotal: 1.12ms\tremaining: 1.12ms\n",
      "1:\tlearn: 11552.6158485\ttotal: 2.31ms\tremaining: 0us\n",
      "0:\tlearn: 14073.1293120\ttotal: 1.2ms\tremaining: 1.2ms\n",
      "1:\tlearn: 12218.3460561\ttotal: 2.28ms\tremaining: 0us\n",
      "0:\tlearn: 11672.1533263\ttotal: 1.15ms\tremaining: 1.15ms\n",
      "1:\tlearn: 10581.6368988\ttotal: 2.33ms\tremaining: 0us\n",
      "0:\tlearn: 14735.6492595\ttotal: 1.2ms\tremaining: 1.2ms\n",
      "1:\tlearn: 11843.0826428\ttotal: 2.25ms\tremaining: 0us\n",
      "0:\tlearn: 11300.7870894\ttotal: 1.15ms\tremaining: 2.29ms\n",
      "1:\tlearn: 10766.8454870\ttotal: 2.23ms\tremaining: 1.12ms\n",
      "2:\tlearn: 10274.7977866\ttotal: 3.24ms\tremaining: 0us\n",
      "0:\tlearn: 15801.8525405\ttotal: 1.17ms\tremaining: 2.34ms\n",
      "1:\tlearn: 15241.7224013\ttotal: 2.25ms\tremaining: 1.12ms\n",
      "2:\tlearn: 14712.2057671\ttotal: 3.25ms\tremaining: 0us\n",
      "0:\tlearn: 15848.5282746\ttotal: 1.15ms\tremaining: 2.31ms\n",
      "1:\tlearn: 15276.5742953\ttotal: 2.18ms\tremaining: 1.09ms\n",
      "2:\tlearn: 14736.2726134\ttotal: 3.25ms\tremaining: 0us\n",
      "0:\tlearn: 13464.5716169\ttotal: 1.42ms\tremaining: 2.84ms\n",
      "1:\tlearn: 12888.6725604\ttotal: 2.53ms\tremaining: 1.26ms\n",
      "2:\tlearn: 12365.2902099\ttotal: 3.52ms\tremaining: 0us\n",
      "0:\tlearn: 16503.9859861\ttotal: 1.15ms\tremaining: 2.29ms\n",
      "1:\tlearn: 15673.3060628\ttotal: 2.27ms\tremaining: 1.14ms\n",
      "2:\tlearn: 15127.8358718\ttotal: 3.25ms\tremaining: 0us\n",
      "0:\tlearn: 10731.5008712\ttotal: 1.16ms\tremaining: 2.31ms\n",
      "1:\tlearn: 9762.4641231\ttotal: 2.2ms\tremaining: 1.1ms\n",
      "2:\tlearn: 9160.0541290\ttotal: 3.23ms\tremaining: 0us\n",
      "0:\tlearn: 15215.3899460\ttotal: 1.23ms\tremaining: 2.46ms\n",
      "1:\tlearn: 14165.5369608\ttotal: 2.25ms\tremaining: 1.12ms\n",
      "2:\tlearn: 13229.8781337\ttotal: 3.28ms\tremaining: 0us\n",
      "0:\tlearn: 15249.2563788\ttotal: 1.3ms\tremaining: 2.6ms\n",
      "1:\tlearn: 14178.1737171\ttotal: 2.4ms\tremaining: 1.2ms\n",
      "2:\tlearn: 13224.9849916\ttotal: 3.35ms\tremaining: 0us\n",
      "0:\tlearn: 12848.0374599\ttotal: 1.15ms\tremaining: 2.3ms\n",
      "1:\tlearn: 11824.1722047\ttotal: 2.13ms\tremaining: 1.06ms\n",
      "2:\tlearn: 11262.1710688\ttotal: 3.1ms\tremaining: 0us\n",
      "0:\tlearn: 15904.3661176\ttotal: 1.12ms\tremaining: 2.23ms\n",
      "1:\tlearn: 14315.8790078\ttotal: 2.12ms\tremaining: 1.06ms\n",
      "2:\tlearn: 13345.9173467\ttotal: 3.12ms\tremaining: 0us\n",
      "0:\tlearn: 10172.9697494\ttotal: 1.25ms\tremaining: 2.49ms\n",
      "1:\tlearn: 9237.6947193\ttotal: 2.28ms\tremaining: 1.14ms\n",
      "2:\tlearn: 8058.0979516\ttotal: 3.36ms\tremaining: 0us\n",
      "0:\tlearn: 14635.8879937\ttotal: 1.37ms\tremaining: 2.75ms\n",
      "1:\tlearn: 13165.8826185\ttotal: 2.36ms\tremaining: 1.18ms\n",
      "2:\tlearn: 11349.2849401\ttotal: 3.33ms\tremaining: 0us\n",
      "0:\tlearn: 14657.1549834\ttotal: 1.14ms\tremaining: 2.27ms\n",
      "1:\tlearn: 13158.8627401\ttotal: 2.2ms\tremaining: 1.1ms\n",
      "2:\tlearn: 11906.8331510\ttotal: 3.21ms\tremaining: 0us\n",
      "0:\tlearn: 12249.6349733\ttotal: 1.12ms\tremaining: 2.24ms\n",
      "1:\tlearn: 11380.7648036\ttotal: 2.2ms\tremaining: 1.1ms\n",
      "2:\tlearn: 10643.4778050\ttotal: 3.19ms\tremaining: 0us\n",
      "0:\tlearn: 15314.5289020\ttotal: 1.17ms\tremaining: 2.33ms\n",
      "1:\tlearn: 13039.3500528\ttotal: 2.16ms\tremaining: 1.08ms\n",
      "2:\tlearn: 11748.0580441\ttotal: 3.15ms\tremaining: 0us\n",
      "0:\tlearn: 9627.0659640\ttotal: 1.23ms\tremaining: 2.47ms\n",
      "1:\tlearn: 8458.5394388\ttotal: 2.32ms\tremaining: 1.16ms\n",
      "2:\tlearn: 7553.6217149\ttotal: 3.38ms\tremaining: 0us\n",
      "0:\tlearn: 14064.2072631\ttotal: 1.15ms\tremaining: 2.3ms\n",
      "1:\tlearn: 11552.6158485\ttotal: 2.11ms\tremaining: 1.06ms\n",
      "2:\tlearn: 9997.0105570\ttotal: 3.1ms\tremaining: 0us\n",
      "0:\tlearn: 14073.1293120\ttotal: 1.31ms\tremaining: 2.61ms\n",
      "1:\tlearn: 12218.3460561\ttotal: 2.34ms\tremaining: 1.17ms\n",
      "2:\tlearn: 9947.5569397\ttotal: 3.35ms\tremaining: 0us\n",
      "0:\tlearn: 11672.1533263\ttotal: 1.09ms\tremaining: 2.18ms\n",
      "1:\tlearn: 10581.6368988\ttotal: 2.03ms\tremaining: 1.02ms\n",
      "2:\tlearn: 9690.3610568\ttotal: 2.98ms\tremaining: 0us\n",
      "0:\tlearn: 14735.6492595\ttotal: 1.18ms\tremaining: 2.35ms\n",
      "1:\tlearn: 11843.0826428\ttotal: 2.25ms\tremaining: 1.13ms\n",
      "2:\tlearn: 10318.3864771\ttotal: 3.28ms\tremaining: 0us\n",
      "0:\tlearn: 11300.7870894\ttotal: 1.11ms\tremaining: 3.34ms\n",
      "1:\tlearn: 10766.8454870\ttotal: 2.08ms\tremaining: 2.08ms\n",
      "2:\tlearn: 10274.7977866\ttotal: 3.04ms\tremaining: 1.01ms\n",
      "3:\tlearn: 9954.9781575\ttotal: 4.02ms\tremaining: 0us\n",
      "0:\tlearn: 15801.8525405\ttotal: 1.19ms\tremaining: 3.58ms\n",
      "1:\tlearn: 15241.7224013\ttotal: 2.26ms\tremaining: 2.26ms\n",
      "2:\tlearn: 14712.2057671\ttotal: 3.25ms\tremaining: 1.08ms\n",
      "3:\tlearn: 14211.5336848\ttotal: 4.26ms\tremaining: 0us\n",
      "0:\tlearn: 15848.5282746\ttotal: 1.09ms\tremaining: 3.27ms\n",
      "1:\tlearn: 15276.5742953\ttotal: 2.13ms\tremaining: 2.13ms\n",
      "2:\tlearn: 14736.2726134\ttotal: 3.09ms\tremaining: 1.03ms\n",
      "3:\tlearn: 14225.7628967\ttotal: 4.06ms\tremaining: 0us\n",
      "0:\tlearn: 13464.5716169\ttotal: 1.22ms\tremaining: 3.67ms\n",
      "1:\tlearn: 12888.6725604\ttotal: 2.27ms\tremaining: 2.27ms\n",
      "2:\tlearn: 12365.2902099\ttotal: 3.29ms\tremaining: 1.1ms\n",
      "3:\tlearn: 12011.8729021\ttotal: 4.27ms\tremaining: 0us\n",
      "0:\tlearn: 16503.9859861\ttotal: 1.25ms\tremaining: 3.77ms\n",
      "1:\tlearn: 15673.3060628\ttotal: 2.29ms\tremaining: 2.29ms\n",
      "2:\tlearn: 15127.8358718\ttotal: 3.27ms\tremaining: 1.09ms\n",
      "3:\tlearn: 14614.4239313\ttotal: 4.26ms\tremaining: 0us\n",
      "0:\tlearn: 10731.5008712\ttotal: 1.17ms\tremaining: 3.5ms\n",
      "1:\tlearn: 9762.4641231\ttotal: 2.26ms\tremaining: 2.26ms\n",
      "2:\tlearn: 9160.0541290\ttotal: 3.27ms\tremaining: 1.09ms\n",
      "3:\tlearn: 8625.9112156\ttotal: 4.26ms\tremaining: 0us\n",
      "0:\tlearn: 15215.3899460\ttotal: 1.15ms\tremaining: 3.44ms\n",
      "1:\tlearn: 14165.5369608\ttotal: 2.15ms\tremaining: 2.15ms\n",
      "2:\tlearn: 13229.8781337\ttotal: 3.14ms\tremaining: 1.05ms\n",
      "3:\tlearn: 11997.1411905\ttotal: 4.13ms\tremaining: 0us\n",
      "0:\tlearn: 15249.2563788\ttotal: 1.27ms\tremaining: 3.82ms\n",
      "1:\tlearn: 14178.1737171\ttotal: 2.29ms\tremaining: 2.29ms\n",
      "2:\tlearn: 13224.9849916\ttotal: 3.3ms\tremaining: 1.1ms\n",
      "3:\tlearn: 12376.3664360\ttotal: 4.32ms\tremaining: 0us\n",
      "0:\tlearn: 12848.0374599\ttotal: 1.31ms\tremaining: 3.93ms\n",
      "1:\tlearn: 11824.1722047\ttotal: 2.41ms\tremaining: 2.41ms\n",
      "2:\tlearn: 11262.1710688\ttotal: 3.38ms\tremaining: 1.13ms\n",
      "3:\tlearn: 10755.1373018\ttotal: 4.33ms\tremaining: 0us\n",
      "0:\tlearn: 15904.3661176\ttotal: 1.19ms\tremaining: 3.56ms\n",
      "1:\tlearn: 14315.8790078\ttotal: 2.17ms\tremaining: 2.17ms\n",
      "2:\tlearn: 13345.9173467\ttotal: 3.15ms\tremaining: 1.05ms\n",
      "3:\tlearn: 12485.4066995\ttotal: 4.11ms\tremaining: 0us\n",
      "0:\tlearn: 10172.9697494\ttotal: 1.13ms\tremaining: 3.4ms\n",
      "1:\tlearn: 9237.6947193\ttotal: 2.14ms\tremaining: 2.14ms\n",
      "2:\tlearn: 8058.0979516\ttotal: 3.14ms\tremaining: 1.05ms\n",
      "3:\tlearn: 7387.9387756\ttotal: 4.14ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 14635.8879937\ttotal: 1.18ms\tremaining: 3.53ms\n",
      "1:\tlearn: 13165.8826185\ttotal: 2.2ms\tremaining: 2.2ms\n",
      "2:\tlearn: 11349.2849401\ttotal: 3.21ms\tremaining: 1.07ms\n",
      "3:\tlearn: 10251.1822191\ttotal: 4.21ms\tremaining: 0us\n",
      "0:\tlearn: 14657.1549834\ttotal: 1.12ms\tremaining: 3.37ms\n",
      "1:\tlearn: 13158.8627401\ttotal: 2.13ms\tremaining: 2.13ms\n",
      "2:\tlearn: 11906.8331510\ttotal: 3.13ms\tremaining: 1.04ms\n",
      "3:\tlearn: 10210.9814922\ttotal: 4.12ms\tremaining: 0us\n",
      "0:\tlearn: 12249.6349733\ttotal: 1.31ms\tremaining: 3.92ms\n",
      "1:\tlearn: 11380.7648036\ttotal: 2.33ms\tremaining: 2.33ms\n",
      "2:\tlearn: 10643.4778050\ttotal: 3.34ms\tremaining: 1.11ms\n",
      "3:\tlearn: 10005.4699549\ttotal: 4.37ms\tremaining: 0us\n",
      "0:\tlearn: 15314.5289020\ttotal: 1.12ms\tremaining: 3.35ms\n",
      "1:\tlearn: 13039.3500528\ttotal: 2.11ms\tremaining: 2.11ms\n",
      "2:\tlearn: 11748.0580441\ttotal: 3.09ms\tremaining: 1.03ms\n",
      "3:\tlearn: 10667.5680062\ttotal: 4.07ms\tremaining: 0us\n",
      "0:\tlearn: 9627.0659640\ttotal: 1.21ms\tremaining: 3.63ms\n",
      "1:\tlearn: 8458.5394388\ttotal: 2.23ms\tremaining: 2.23ms\n",
      "2:\tlearn: 7553.6217149\ttotal: 3.22ms\tremaining: 1.07ms\n",
      "3:\tlearn: 6374.7807565\ttotal: 4.21ms\tremaining: 0us\n",
      "0:\tlearn: 14064.2072631\ttotal: 1.12ms\tremaining: 3.35ms\n",
      "1:\tlearn: 11552.6158485\ttotal: 2.12ms\tremaining: 2.12ms\n",
      "2:\tlearn: 9997.0105570\ttotal: 3.13ms\tremaining: 1.04ms\n",
      "3:\tlearn: 8749.6863745\ttotal: 4.11ms\tremaining: 0us\n",
      "0:\tlearn: 14073.1293120\ttotal: 1.39ms\tremaining: 4.16ms\n",
      "1:\tlearn: 12218.3460561\ttotal: 2.47ms\tremaining: 2.47ms\n",
      "2:\tlearn: 9947.5569397\ttotal: 3.51ms\tremaining: 1.17ms\n",
      "3:\tlearn: 8709.0132362\ttotal: 4.6ms\tremaining: 0us\n",
      "0:\tlearn: 11672.1533263\ttotal: 1.2ms\tremaining: 3.59ms\n",
      "1:\tlearn: 10581.6368988\ttotal: 2.16ms\tremaining: 2.16ms\n",
      "2:\tlearn: 9690.3610568\ttotal: 3.14ms\tremaining: 1.05ms\n",
      "3:\tlearn: 8940.6243502\ttotal: 4.12ms\tremaining: 0us\n",
      "0:\tlearn: 14735.6492595\ttotal: 4.84ms\tremaining: 14.5ms\n",
      "1:\tlearn: 11843.0826428\ttotal: 5.86ms\tremaining: 5.86ms\n",
      "2:\tlearn: 10318.3864771\ttotal: 6.84ms\tremaining: 2.28ms\n",
      "3:\tlearn: 9116.2434554\ttotal: 7.82ms\tremaining: 0us\n",
      "0:\tlearn: 11300.7870894\ttotal: 1.18ms\tremaining: 4.72ms\n",
      "1:\tlearn: 10766.8454870\ttotal: 2.22ms\tremaining: 3.32ms\n",
      "2:\tlearn: 10274.7977866\ttotal: 3.23ms\tremaining: 2.16ms\n",
      "3:\tlearn: 9954.9781575\ttotal: 4.26ms\tremaining: 1.06ms\n",
      "4:\tlearn: 9516.7009993\ttotal: 5.26ms\tremaining: 0us\n",
      "0:\tlearn: 15801.8525405\ttotal: 1.17ms\tremaining: 4.69ms\n",
      "1:\tlearn: 15241.7224013\ttotal: 2.22ms\tremaining: 3.33ms\n",
      "2:\tlearn: 14712.2057671\ttotal: 3.34ms\tremaining: 2.22ms\n",
      "3:\tlearn: 14211.5336848\ttotal: 4.36ms\tremaining: 1.09ms\n",
      "4:\tlearn: 13738.0824629\ttotal: 5.37ms\tremaining: 0us\n",
      "0:\tlearn: 15848.5282746\ttotal: 1.38ms\tremaining: 5.53ms\n",
      "1:\tlearn: 15276.5742953\ttotal: 2.4ms\tremaining: 3.61ms\n",
      "2:\tlearn: 14736.2726134\ttotal: 3.48ms\tremaining: 2.32ms\n",
      "3:\tlearn: 14225.7628967\ttotal: 4.51ms\tremaining: 1.13ms\n",
      "4:\tlearn: 13743.3414833\ttotal: 5.52ms\tremaining: 0us\n",
      "0:\tlearn: 13464.5716169\ttotal: 1.2ms\tremaining: 4.82ms\n",
      "1:\tlearn: 12888.6725604\ttotal: 2.29ms\tremaining: 3.44ms\n",
      "2:\tlearn: 12365.2902099\ttotal: 3.28ms\tremaining: 2.19ms\n",
      "3:\tlearn: 12011.8729021\ttotal: 4.25ms\tremaining: 1.06ms\n",
      "4:\tlearn: 11729.0594517\ttotal: 5.42ms\tremaining: 0us\n",
      "0:\tlearn: 16503.9859861\ttotal: 1.18ms\tremaining: 4.71ms\n",
      "1:\tlearn: 15673.3060628\ttotal: 2.22ms\tremaining: 3.32ms\n",
      "2:\tlearn: 15127.8358718\ttotal: 3.29ms\tremaining: 2.19ms\n",
      "3:\tlearn: 14614.4239313\ttotal: 4.31ms\tremaining: 1.08ms\n",
      "4:\tlearn: 14131.0802253\ttotal: 5.36ms\tremaining: 0us\n",
      "0:\tlearn: 10731.5008712\ttotal: 1.13ms\tremaining: 4.52ms\n",
      "1:\tlearn: 9762.4641231\ttotal: 2.14ms\tremaining: 3.22ms\n",
      "2:\tlearn: 9160.0541290\ttotal: 3.15ms\tremaining: 2.1ms\n",
      "3:\tlearn: 8625.9112156\ttotal: 4.17ms\tremaining: 1.04ms\n",
      "4:\tlearn: 7913.3827098\ttotal: 5.15ms\tremaining: 0us\n",
      "0:\tlearn: 15215.3899460\ttotal: 1.15ms\tremaining: 4.6ms\n",
      "1:\tlearn: 14165.5369608\ttotal: 2.14ms\tremaining: 3.21ms\n",
      "2:\tlearn: 13229.8781337\ttotal: 3.15ms\tremaining: 2.1ms\n",
      "3:\tlearn: 11997.1411905\ttotal: 4.15ms\tremaining: 1.04ms\n",
      "4:\tlearn: 11223.9517343\ttotal: 5.15ms\tremaining: 0us\n",
      "0:\tlearn: 15249.2563788\ttotal: 1.35ms\tremaining: 5.41ms\n",
      "1:\tlearn: 14178.1737171\ttotal: 2.38ms\tremaining: 3.56ms\n",
      "2:\tlearn: 13224.9849916\ttotal: 3.41ms\tremaining: 2.28ms\n",
      "3:\tlearn: 12376.3664360\ttotal: 4.42ms\tremaining: 1.11ms\n",
      "4:\tlearn: 11195.6629975\ttotal: 5.41ms\tremaining: 0us\n",
      "0:\tlearn: 12848.0374599\ttotal: 1.34ms\tremaining: 5.37ms\n",
      "1:\tlearn: 11824.1722047\ttotal: 2.34ms\tremaining: 3.51ms\n",
      "2:\tlearn: 11262.1710688\ttotal: 3.37ms\tremaining: 2.25ms\n",
      "3:\tlearn: 10755.1373018\ttotal: 4.41ms\tremaining: 1.1ms\n",
      "4:\tlearn: 10294.0924524\ttotal: 5.44ms\tremaining: 0us\n",
      "0:\tlearn: 15904.3661176\ttotal: 1.19ms\tremaining: 4.77ms\n",
      "1:\tlearn: 14315.8790078\ttotal: 2.22ms\tremaining: 3.33ms\n",
      "2:\tlearn: 13345.9173467\ttotal: 3.24ms\tremaining: 2.16ms\n",
      "3:\tlearn: 12485.4066995\ttotal: 4.32ms\tremaining: 1.08ms\n",
      "4:\tlearn: 11721.7525254\ttotal: 5.33ms\tremaining: 0us\n",
      "0:\tlearn: 10172.9697494\ttotal: 1.14ms\tremaining: 4.56ms\n",
      "1:\tlearn: 9237.6947193\ttotal: 2.16ms\tremaining: 3.25ms\n",
      "2:\tlearn: 8058.0979516\ttotal: 3.17ms\tremaining: 2.11ms\n",
      "3:\tlearn: 7387.9387756\ttotal: 4.26ms\tremaining: 1.06ms\n",
      "4:\tlearn: 6942.0603230\ttotal: 5.28ms\tremaining: 0us\n",
      "0:\tlearn: 14635.8879937\ttotal: 1.16ms\tremaining: 4.66ms\n",
      "1:\tlearn: 13165.8826185\ttotal: 2.24ms\tremaining: 3.36ms\n",
      "2:\tlearn: 11349.2849401\ttotal: 3.28ms\tremaining: 2.19ms\n",
      "3:\tlearn: 10251.1822191\ttotal: 4.29ms\tremaining: 1.07ms\n",
      "4:\tlearn: 9321.7318281\ttotal: 5.35ms\tremaining: 0us\n",
      "0:\tlearn: 14657.1549834\ttotal: 1.17ms\tremaining: 4.7ms\n",
      "1:\tlearn: 13158.8627401\ttotal: 2.2ms\tremaining: 3.31ms\n",
      "2:\tlearn: 11906.8331510\ttotal: 3.23ms\tremaining: 2.15ms\n",
      "3:\tlearn: 10210.9814922\ttotal: 4.28ms\tremaining: 1.07ms\n",
      "4:\tlearn: 9280.2972898\ttotal: 5.3ms\tremaining: 0us\n",
      "0:\tlearn: 12249.6349733\ttotal: 1.38ms\tremaining: 5.54ms\n",
      "1:\tlearn: 11380.7648036\ttotal: 2.44ms\tremaining: 3.65ms\n",
      "2:\tlearn: 10643.4778050\ttotal: 3.47ms\tremaining: 2.31ms\n",
      "3:\tlearn: 10005.4699549\ttotal: 4.48ms\tremaining: 1.12ms\n",
      "4:\tlearn: 9445.9880222\ttotal: 5.49ms\tremaining: 0us\n",
      "0:\tlearn: 15314.5289020\ttotal: 1.13ms\tremaining: 4.52ms\n",
      "1:\tlearn: 13039.3500528\ttotal: 2.22ms\tremaining: 3.33ms\n",
      "2:\tlearn: 11748.0580441\ttotal: 3.28ms\tremaining: 2.18ms\n",
      "3:\tlearn: 10667.5680062\ttotal: 4.27ms\tremaining: 1.07ms\n",
      "4:\tlearn: 9764.6788821\ttotal: 5.28ms\tremaining: 0us\n",
      "0:\tlearn: 9627.0659640\ttotal: 1.19ms\tremaining: 4.76ms\n",
      "1:\tlearn: 8458.5394388\ttotal: 2.25ms\tremaining: 3.38ms\n",
      "2:\tlearn: 7553.6217149\ttotal: 3.28ms\tremaining: 2.19ms\n",
      "3:\tlearn: 6374.7807565\ttotal: 4.31ms\tremaining: 1.08ms\n",
      "4:\tlearn: 5861.6179163\ttotal: 5.32ms\tremaining: 0us\n",
      "0:\tlearn: 14064.2072631\ttotal: 1.29ms\tremaining: 5.15ms\n",
      "1:\tlearn: 11552.6158485\ttotal: 2.25ms\tremaining: 3.38ms\n",
      "2:\tlearn: 9997.0105570\ttotal: 3.25ms\tremaining: 2.16ms\n",
      "3:\tlearn: 8749.6863745\ttotal: 4.23ms\tremaining: 1.06ms\n",
      "4:\tlearn: 7756.9623340\ttotal: 5.21ms\tremaining: 0us\n",
      "0:\tlearn: 14073.1293120\ttotal: 1.25ms\tremaining: 5ms\n",
      "1:\tlearn: 12218.3460561\ttotal: 2.23ms\tremaining: 3.35ms\n",
      "2:\tlearn: 9947.5569397\ttotal: 3.19ms\tremaining: 2.13ms\n",
      "3:\tlearn: 8709.0132362\ttotal: 4.18ms\tremaining: 1.04ms\n",
      "4:\tlearn: 7725.2190017\ttotal: 5.21ms\tremaining: 0us\n",
      "0:\tlearn: 11672.1533263\ttotal: 1.36ms\tremaining: 5.43ms\n",
      "1:\tlearn: 10581.6368988\ttotal: 2.35ms\tremaining: 3.53ms\n",
      "2:\tlearn: 9690.3610568\ttotal: 3.34ms\tremaining: 2.23ms\n",
      "3:\tlearn: 8940.6243502\ttotal: 4.34ms\tremaining: 1.08ms\n",
      "4:\tlearn: 8300.6031345\ttotal: 5.32ms\tremaining: 0us\n",
      "0:\tlearn: 14735.6492595\ttotal: 1.27ms\tremaining: 5.09ms\n",
      "1:\tlearn: 11843.0826428\ttotal: 2.39ms\tremaining: 3.58ms\n",
      "2:\tlearn: 10318.3864771\ttotal: 3.41ms\tremaining: 2.27ms\n",
      "3:\tlearn: 9116.2434554\ttotal: 4.44ms\tremaining: 1.11ms\n",
      "4:\tlearn: 8174.4886846\ttotal: 5.45ms\tremaining: 0us\n",
      "0:\tlearn: 11423.5395821\ttotal: 1.4ms\tremaining: 0us\n",
      "0:\tlearn: 15726.6044139\ttotal: 1.49ms\tremaining: 0us\n",
      "0:\tlearn: 15779.0554672\ttotal: 1.42ms\tremaining: 0us\n",
      "0:\tlearn: 13570.2252671\ttotal: 1.61ms\tremaining: 0us\n",
      "0:\tlearn: 16376.7845091\ttotal: 1.39ms\tremaining: 0us\n",
      "0:\tlearn: 10970.1869674\ttotal: 1.4ms\tremaining: 0us\n",
      "0:\tlearn: 15061.0823653\ttotal: 1.53ms\tremaining: 0us\n",
      "0:\tlearn: 15106.2542737\ttotal: 1.41ms\tremaining: 0us\n",
      "0:\tlearn: 13048.1367732\ttotal: 1.54ms\tremaining: 0us\n",
      "0:\tlearn: 15644.7900949\ttotal: 1.46ms\tremaining: 0us\n",
      "0:\tlearn: 10519.5334437\ttotal: 1.46ms\tremaining: 0us\n",
      "0:\tlearn: 14398.2957871\ttotal: 1.4ms\tremaining: 0us\n",
      "0:\tlearn: 14436.1094960\ttotal: 1.59ms\tremaining: 0us\n",
      "0:\tlearn: 12531.1612479\ttotal: 1.62ms\tremaining: 0us\n",
      "0:\tlearn: 14916.9041516\ttotal: 3.05ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 10071.9414225\ttotal: 2.85ms\tremaining: 0us\n",
      "0:\tlearn: 13738.6407379\ttotal: 1.34ms\tremaining: 0us\n",
      "0:\tlearn: 13769.0091637\ttotal: 1.38ms\tremaining: 0us\n",
      "0:\tlearn: 12019.9585516\ttotal: 1.4ms\tremaining: 0us\n",
      "0:\tlearn: 14193.7589367\ttotal: 1.4ms\tremaining: 0us\n",
      "0:\tlearn: 11423.5395821\ttotal: 1.44ms\tremaining: 1.44ms\n",
      "1:\tlearn: 10989.6887600\ttotal: 2.65ms\tremaining: 0us\n",
      "0:\tlearn: 15726.6044139\ttotal: 1.35ms\tremaining: 1.35ms\n",
      "1:\tlearn: 15090.1972939\ttotal: 2.55ms\tremaining: 0us\n",
      "0:\tlearn: 15779.0554672\ttotal: 1.36ms\tremaining: 1.36ms\n",
      "1:\tlearn: 15135.7894122\ttotal: 2.58ms\tremaining: 0us\n",
      "0:\tlearn: 13570.2252671\ttotal: 1.51ms\tremaining: 1.51ms\n",
      "1:\tlearn: 13071.5518006\ttotal: 2.82ms\tremaining: 0us\n",
      "0:\tlearn: 16376.7845091\ttotal: 1.44ms\tremaining: 1.44ms\n",
      "1:\tlearn: 15679.1341135\ttotal: 2.65ms\tremaining: 0us\n",
      "0:\tlearn: 10970.1869674\ttotal: 1.35ms\tremaining: 1.35ms\n",
      "1:\tlearn: 10148.6780508\ttotal: 2.54ms\tremaining: 0us\n",
      "0:\tlearn: 15061.0823653\ttotal: 1.48ms\tremaining: 1.48ms\n",
      "1:\tlearn: 13902.0309480\ttotal: 2.67ms\tremaining: 0us\n",
      "0:\tlearn: 15106.2542737\ttotal: 2.54ms\tremaining: 2.54ms\n",
      "1:\tlearn: 13885.7137424\ttotal: 3.81ms\tremaining: 0us\n",
      "0:\tlearn: 13048.1367732\ttotal: 1.43ms\tremaining: 1.43ms\n",
      "1:\tlearn: 12111.2190401\ttotal: 2.64ms\tremaining: 0us\n",
      "0:\tlearn: 15644.7900949\ttotal: 1.34ms\tremaining: 1.34ms\n",
      "1:\tlearn: 14328.6338047\ttotal: 2.55ms\tremaining: 0us\n",
      "0:\tlearn: 10519.5334437\ttotal: 1.41ms\tremaining: 1.41ms\n",
      "1:\tlearn: 9357.0882245\ttotal: 2.69ms\tremaining: 0us\n",
      "0:\tlearn: 14398.2957871\ttotal: 1.54ms\tremaining: 1.54ms\n",
      "1:\tlearn: 12770.2267681\ttotal: 2.85ms\tremaining: 0us\n",
      "0:\tlearn: 14436.1094960\ttotal: 1.51ms\tremaining: 1.51ms\n",
      "1:\tlearn: 12704.4747196\ttotal: 2.84ms\tremaining: 0us\n",
      "0:\tlearn: 12531.1612479\ttotal: 1.53ms\tremaining: 1.53ms\n",
      "1:\tlearn: 11216.9426056\ttotal: 2.77ms\tremaining: 0us\n",
      "0:\tlearn: 14916.9041516\ttotal: 1.35ms\tremaining: 1.35ms\n",
      "1:\tlearn: 13061.3125277\ttotal: 2.52ms\tremaining: 0us\n",
      "0:\tlearn: 10071.9414225\ttotal: 2.45ms\tremaining: 2.45ms\n",
      "1:\tlearn: 8615.8661208\ttotal: 3.9ms\tremaining: 0us\n",
      "0:\tlearn: 13738.6407379\ttotal: 2.86ms\tremaining: 2.86ms\n",
      "1:\tlearn: 11680.3592251\ttotal: 4.05ms\tremaining: 0us\n",
      "0:\tlearn: 13769.0091637\ttotal: 1.41ms\tremaining: 1.41ms\n",
      "1:\tlearn: 11592.6811970\ttotal: 2.62ms\tremaining: 0us\n",
      "0:\tlearn: 12019.9585516\ttotal: 1.38ms\tremaining: 1.38ms\n",
      "1:\tlearn: 10389.8162858\ttotal: 2.58ms\tremaining: 0us\n",
      "0:\tlearn: 14193.7589367\ttotal: 2.8ms\tremaining: 2.8ms\n",
      "1:\tlearn: 11877.6659340\ttotal: 4ms\tremaining: 0us\n",
      "0:\tlearn: 11423.5395821\ttotal: 2.99ms\tremaining: 5.97ms\n",
      "1:\tlearn: 10989.6887600\ttotal: 4.23ms\tremaining: 2.12ms\n",
      "2:\tlearn: 10571.7521675\ttotal: 5.38ms\tremaining: 0us\n",
      "0:\tlearn: 15726.6044139\ttotal: 2.85ms\tremaining: 5.69ms\n",
      "1:\tlearn: 15090.1972939\ttotal: 4.09ms\tremaining: 2.05ms\n",
      "2:\tlearn: 14521.8905302\ttotal: 5.25ms\tremaining: 0us\n",
      "0:\tlearn: 15779.0554672\ttotal: 1.39ms\tremaining: 2.79ms\n",
      "1:\tlearn: 15135.7894122\ttotal: 2.57ms\tremaining: 1.28ms\n",
      "2:\tlearn: 14522.8980052\ttotal: 3.75ms\tremaining: 0us\n",
      "0:\tlearn: 13570.2252671\ttotal: 1.54ms\tremaining: 3.08ms\n",
      "1:\tlearn: 13071.5518006\ttotal: 2.83ms\tremaining: 1.42ms\n",
      "2:\tlearn: 12618.2934614\ttotal: 4.01ms\tremaining: 0us\n",
      "0:\tlearn: 16376.7845091\ttotal: 1.38ms\tremaining: 2.75ms\n",
      "1:\tlearn: 15679.1341135\ttotal: 2.52ms\tremaining: 1.26ms\n",
      "2:\tlearn: 15017.4041151\ttotal: 3.64ms\tremaining: 0us\n",
      "0:\tlearn: 10970.1869674\ttotal: 2.84ms\tremaining: 5.68ms\n",
      "1:\tlearn: 10148.6780508\ttotal: 4.14ms\tremaining: 2.07ms\n",
      "2:\tlearn: 9395.3470306\ttotal: 5.35ms\tremaining: 0us\n",
      "0:\tlearn: 15061.0823653\ttotal: 1.41ms\tremaining: 2.81ms\n",
      "1:\tlearn: 13902.0309480\ttotal: 2.65ms\tremaining: 1.33ms\n",
      "2:\tlearn: 12800.3172607\ttotal: 3.92ms\tremaining: 0us\n",
      "0:\tlearn: 15106.2542737\ttotal: 1.54ms\tremaining: 3.09ms\n",
      "1:\tlearn: 13885.7137424\ttotal: 2.81ms\tremaining: 1.4ms\n",
      "2:\tlearn: 12780.6227137\ttotal: 4.16ms\tremaining: 0us\n",
      "0:\tlearn: 13048.1367732\ttotal: 1.52ms\tremaining: 3.04ms\n",
      "1:\tlearn: 12111.2190401\ttotal: 2.75ms\tremaining: 1.37ms\n",
      "2:\tlearn: 11502.2564301\ttotal: 3.96ms\tremaining: 0us\n",
      "0:\tlearn: 15644.7900949\ttotal: 1.44ms\tremaining: 2.88ms\n",
      "1:\tlearn: 14328.6338047\ttotal: 2.64ms\tremaining: 1.32ms\n",
      "2:\tlearn: 13147.7868310\ttotal: 3.88ms\tremaining: 0us\n",
      "0:\tlearn: 10519.5334437\ttotal: 1.34ms\tremaining: 2.68ms\n",
      "1:\tlearn: 9357.0882245\ttotal: 2.53ms\tremaining: 1.26ms\n",
      "2:\tlearn: 8345.8407158\ttotal: 3.69ms\tremaining: 0us\n",
      "0:\tlearn: 14398.2957871\ttotal: 1.41ms\tremaining: 2.82ms\n",
      "1:\tlearn: 12770.2267681\ttotal: 2.69ms\tremaining: 1.35ms\n",
      "2:\tlearn: 11267.6545072\ttotal: 3.91ms\tremaining: 0us\n",
      "0:\tlearn: 14436.1094960\ttotal: 1.36ms\tremaining: 2.72ms\n",
      "1:\tlearn: 12704.4747196\ttotal: 2.56ms\tremaining: 1.28ms\n",
      "2:\tlearn: 11219.1846161\ttotal: 3.75ms\tremaining: 0us\n",
      "0:\tlearn: 12531.1612479\ttotal: 1.47ms\tremaining: 2.93ms\n",
      "1:\tlearn: 11216.9426056\ttotal: 2.8ms\tremaining: 1.4ms\n",
      "2:\tlearn: 10377.7877519\ttotal: 4.02ms\tremaining: 0us\n",
      "0:\tlearn: 14916.9041516\ttotal: 1.48ms\tremaining: 2.96ms\n",
      "1:\tlearn: 13061.3125277\ttotal: 2.68ms\tremaining: 1.34ms\n",
      "2:\tlearn: 11491.5709441\ttotal: 3.87ms\tremaining: 0us\n",
      "0:\tlearn: 10071.9414225\ttotal: 1.9ms\tremaining: 3.79ms\n",
      "1:\tlearn: 8615.8661208\ttotal: 3.19ms\tremaining: 1.59ms\n",
      "2:\tlearn: 7419.1236167\ttotal: 4.43ms\tremaining: 0us\n",
      "0:\tlearn: 13738.6407379\ttotal: 2.91ms\tremaining: 5.82ms\n",
      "1:\tlearn: 11680.3592251\ttotal: 4.21ms\tremaining: 2.11ms\n",
      "2:\tlearn: 9882.5504780\ttotal: 5.58ms\tremaining: 0us\n",
      "0:\tlearn: 13769.0091637\ttotal: 1.33ms\tremaining: 2.66ms\n",
      "1:\tlearn: 11592.6811970\ttotal: 2.55ms\tremaining: 1.27ms\n",
      "2:\tlearn: 9682.4058626\ttotal: 3.76ms\tremaining: 0us\n",
      "0:\tlearn: 12019.9585516\ttotal: 1.38ms\tremaining: 2.75ms\n",
      "1:\tlearn: 10389.8162858\ttotal: 2.65ms\tremaining: 1.32ms\n",
      "2:\tlearn: 9374.4951457\ttotal: 3.86ms\tremaining: 0us\n",
      "0:\tlearn: 14193.7589367\ttotal: 1.62ms\tremaining: 3.24ms\n",
      "1:\tlearn: 11877.6659340\ttotal: 2.96ms\tremaining: 1.48ms\n",
      "2:\tlearn: 9883.1619234\ttotal: 4.17ms\tremaining: 0us\n",
      "0:\tlearn: 11423.5395821\ttotal: 1.49ms\tremaining: 4.46ms\n",
      "1:\tlearn: 10989.6887600\ttotal: 2.77ms\tremaining: 2.77ms\n",
      "2:\tlearn: 10571.7521675\ttotal: 4ms\tremaining: 1.33ms\n",
      "3:\tlearn: 10173.5235458\ttotal: 5.2ms\tremaining: 0us\n",
      "0:\tlearn: 15726.6044139\ttotal: 1.45ms\tremaining: 4.35ms\n",
      "1:\tlearn: 15090.1972939\ttotal: 2.72ms\tremaining: 2.72ms\n",
      "2:\tlearn: 14521.8905302\ttotal: 4.02ms\tremaining: 1.34ms\n",
      "3:\tlearn: 13940.9268869\ttotal: 5.21ms\tremaining: 0us\n",
      "0:\tlearn: 15779.0554672\ttotal: 1.39ms\tremaining: 4.18ms\n",
      "1:\tlearn: 15135.7894122\ttotal: 2.64ms\tremaining: 2.64ms\n",
      "2:\tlearn: 14522.8980052\ttotal: 3.82ms\tremaining: 1.27ms\n",
      "3:\tlearn: 13906.4470073\ttotal: 5ms\tremaining: 0us\n",
      "0:\tlearn: 13570.2252671\ttotal: 1.57ms\tremaining: 4.7ms\n",
      "1:\tlearn: 13071.5518006\ttotal: 2.81ms\tremaining: 2.81ms\n",
      "2:\tlearn: 12618.2934614\ttotal: 4.03ms\tremaining: 1.34ms\n",
      "3:\tlearn: 12201.6873189\ttotal: 5.26ms\tremaining: 0us\n",
      "0:\tlearn: 16376.7845091\ttotal: 3.09ms\tremaining: 9.26ms\n",
      "1:\tlearn: 15679.1341135\ttotal: 4.28ms\tremaining: 4.28ms\n",
      "2:\tlearn: 15017.4041151\ttotal: 5.55ms\tremaining: 1.85ms\n",
      "3:\tlearn: 14389.6789079\ttotal: 6.78ms\tremaining: 0us\n",
      "0:\tlearn: 10970.1869674\ttotal: 1.37ms\tremaining: 4.11ms\n",
      "1:\tlearn: 10148.6780508\ttotal: 2.55ms\tremaining: 2.55ms\n",
      "2:\tlearn: 9395.3470306\ttotal: 3.72ms\tremaining: 1.24ms\n",
      "3:\tlearn: 8714.1858438\ttotal: 4.88ms\tremaining: 0us\n",
      "0:\tlearn: 15061.0823653\ttotal: 1.5ms\tremaining: 4.5ms\n",
      "1:\tlearn: 13902.0309480\ttotal: 2.72ms\tremaining: 2.72ms\n",
      "2:\tlearn: 12800.3172607\ttotal: 3.92ms\tremaining: 1.31ms\n",
      "3:\tlearn: 11803.2416796\ttotal: 5.19ms\tremaining: 0us\n",
      "0:\tlearn: 15106.2542737\ttotal: 2.87ms\tremaining: 8.62ms\n",
      "1:\tlearn: 13885.7137424\ttotal: 4.14ms\tremaining: 4.14ms\n",
      "2:\tlearn: 12780.6227137\ttotal: 5.35ms\tremaining: 1.78ms\n",
      "3:\tlearn: 11709.4494709\ttotal: 6.58ms\tremaining: 0us\n",
      "0:\tlearn: 13048.1367732\ttotal: 1.4ms\tremaining: 4.19ms\n",
      "1:\tlearn: 12111.2190401\ttotal: 2.68ms\tremaining: 2.68ms\n",
      "2:\tlearn: 11502.2564301\ttotal: 3.88ms\tremaining: 1.29ms\n",
      "3:\tlearn: 10766.5164376\ttotal: 5.11ms\tremaining: 0us\n",
      "0:\tlearn: 15644.7900949\ttotal: 1.4ms\tremaining: 4.21ms\n",
      "1:\tlearn: 14328.6338047\ttotal: 2.62ms\tremaining: 2.62ms\n",
      "2:\tlearn: 13147.7868310\ttotal: 3.83ms\tremaining: 1.28ms\n",
      "3:\tlearn: 12015.3881031\ttotal: 5.03ms\tremaining: 0us\n",
      "0:\tlearn: 10519.5334437\ttotal: 3.06ms\tremaining: 9.2ms\n",
      "1:\tlearn: 9357.0882245\ttotal: 4.25ms\tremaining: 4.25ms\n",
      "2:\tlearn: 8345.8407158\ttotal: 5.43ms\tremaining: 1.81ms\n",
      "3:\tlearn: 7482.7571774\ttotal: 6.59ms\tremaining: 0us\n",
      "0:\tlearn: 14398.2957871\ttotal: 1.48ms\tremaining: 4.45ms\n",
      "1:\tlearn: 12770.2267681\ttotal: 2.77ms\tremaining: 2.77ms\n",
      "2:\tlearn: 11267.6545072\ttotal: 3.95ms\tremaining: 1.32ms\n",
      "3:\tlearn: 9980.6544708\ttotal: 5.09ms\tremaining: 0us\n",
      "0:\tlearn: 14436.1094960\ttotal: 1.46ms\tremaining: 4.37ms\n",
      "1:\tlearn: 12704.4747196\ttotal: 2.67ms\tremaining: 2.67ms\n",
      "2:\tlearn: 11219.1846161\ttotal: 3.84ms\tremaining: 1.28ms\n",
      "3:\tlearn: 9832.7435899\ttotal: 5.01ms\tremaining: 0us\n",
      "0:\tlearn: 12531.1612479\ttotal: 2.5ms\tremaining: 7.51ms\n",
      "1:\tlearn: 11216.9426056\ttotal: 3.67ms\tremaining: 3.67ms\n",
      "2:\tlearn: 10377.7877519\ttotal: 4.81ms\tremaining: 1.6ms\n",
      "3:\tlearn: 9627.4541794\ttotal: 5.99ms\tremaining: 0us\n",
      "0:\tlearn: 14916.9041516\ttotal: 2.87ms\tremaining: 8.61ms\n",
      "1:\tlearn: 13061.3125277\ttotal: 4.01ms\tremaining: 4.01ms\n",
      "2:\tlearn: 11491.5709441\ttotal: 5.16ms\tremaining: 1.72ms\n",
      "3:\tlearn: 10044.8968041\ttotal: 6.3ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 10071.9414225\ttotal: 3ms\tremaining: 9.02ms\n",
      "1:\tlearn: 8615.8661208\ttotal: 4.29ms\tremaining: 4.29ms\n",
      "2:\tlearn: 7419.1236167\ttotal: 5.62ms\tremaining: 1.87ms\n",
      "3:\tlearn: 6531.3944006\ttotal: 6.82ms\tremaining: 0us\n",
      "0:\tlearn: 13738.6407379\ttotal: 1.41ms\tremaining: 4.22ms\n",
      "1:\tlearn: 11680.3592251\ttotal: 2.61ms\tremaining: 2.61ms\n",
      "2:\tlearn: 9882.5504780\ttotal: 3.79ms\tremaining: 1.26ms\n",
      "3:\tlearn: 8555.4684587\ttotal: 4.98ms\tremaining: 0us\n",
      "0:\tlearn: 13769.0091637\ttotal: 1.42ms\tremaining: 4.26ms\n",
      "1:\tlearn: 11592.6811970\ttotal: 2.67ms\tremaining: 2.67ms\n",
      "2:\tlearn: 9682.4058626\ttotal: 3.89ms\tremaining: 1.29ms\n",
      "3:\tlearn: 8323.8309753\ttotal: 5.06ms\tremaining: 0us\n",
      "0:\tlearn: 12019.9585516\ttotal: 1.4ms\tremaining: 4.19ms\n",
      "1:\tlearn: 10389.8162858\ttotal: 2.59ms\tremaining: 2.59ms\n",
      "2:\tlearn: 9374.4951457\ttotal: 3.8ms\tremaining: 1.27ms\n",
      "3:\tlearn: 8495.7733885\ttotal: 4.99ms\tremaining: 0us\n",
      "0:\tlearn: 14193.7589367\ttotal: 1.43ms\tremaining: 4.29ms\n",
      "1:\tlearn: 11877.6659340\ttotal: 2.76ms\tremaining: 2.76ms\n",
      "2:\tlearn: 9883.1619234\ttotal: 3.97ms\tremaining: 1.32ms\n",
      "3:\tlearn: 8516.4222235\ttotal: 5.25ms\tremaining: 0us\n",
      "0:\tlearn: 11423.5395821\ttotal: 1.52ms\tremaining: 6.08ms\n",
      "1:\tlearn: 10989.6887600\ttotal: 2.77ms\tremaining: 4.15ms\n",
      "2:\tlearn: 10571.7521675\ttotal: 3.98ms\tremaining: 2.66ms\n",
      "3:\tlearn: 10173.5235458\ttotal: 5.17ms\tremaining: 1.29ms\n",
      "4:\tlearn: 9794.1750775\ttotal: 6.35ms\tremaining: 0us\n",
      "0:\tlearn: 15726.6044139\ttotal: 1.44ms\tremaining: 5.74ms\n",
      "1:\tlearn: 15090.1972939\ttotal: 2.67ms\tremaining: 4.01ms\n",
      "2:\tlearn: 14521.8905302\ttotal: 3.94ms\tremaining: 2.63ms\n",
      "3:\tlearn: 13940.9268869\ttotal: 5.14ms\tremaining: 1.28ms\n",
      "4:\tlearn: 13387.4632187\ttotal: 6.34ms\tremaining: 0us\n",
      "0:\tlearn: 15779.0554672\ttotal: 1.5ms\tremaining: 6.01ms\n",
      "1:\tlearn: 15135.7894122\ttotal: 2.84ms\tremaining: 4.26ms\n",
      "2:\tlearn: 14522.8980052\ttotal: 4.03ms\tremaining: 2.69ms\n",
      "3:\tlearn: 13906.4470073\ttotal: 5.19ms\tremaining: 1.3ms\n",
      "4:\tlearn: 13400.4883297\ttotal: 6.36ms\tremaining: 0us\n",
      "0:\tlearn: 13570.2252671\ttotal: 1.56ms\tremaining: 6.26ms\n",
      "1:\tlearn: 13071.5518006\ttotal: 2.72ms\tremaining: 4.08ms\n",
      "2:\tlearn: 12618.2934614\ttotal: 3.91ms\tremaining: 2.6ms\n",
      "3:\tlearn: 12201.6873189\ttotal: 5.09ms\tremaining: 1.27ms\n",
      "4:\tlearn: 11806.7993541\ttotal: 6.25ms\tremaining: 0us\n",
      "0:\tlearn: 16376.7845091\ttotal: 2.49ms\tremaining: 9.98ms\n",
      "1:\tlearn: 15679.1341135\ttotal: 3.78ms\tremaining: 5.67ms\n",
      "2:\tlearn: 15017.4041151\ttotal: 4.99ms\tremaining: 3.33ms\n",
      "3:\tlearn: 14389.6789079\ttotal: 6.2ms\tremaining: 1.55ms\n",
      "4:\tlearn: 13794.1842318\ttotal: 7.42ms\tremaining: 0us\n",
      "0:\tlearn: 10970.1869674\ttotal: 1.38ms\tremaining: 5.53ms\n",
      "1:\tlearn: 10148.6780508\ttotal: 2.58ms\tremaining: 3.87ms\n",
      "2:\tlearn: 9395.3470306\ttotal: 3.75ms\tremaining: 2.5ms\n",
      "3:\tlearn: 8714.1858438\ttotal: 4.92ms\tremaining: 1.23ms\n",
      "4:\tlearn: 8099.1773866\ttotal: 6.07ms\tremaining: 0us\n",
      "0:\tlearn: 15061.0823653\ttotal: 1.37ms\tremaining: 5.49ms\n",
      "1:\tlearn: 13902.0309480\ttotal: 2.55ms\tremaining: 3.82ms\n",
      "2:\tlearn: 12800.3172607\ttotal: 3.72ms\tremaining: 2.48ms\n",
      "3:\tlearn: 11803.2416796\ttotal: 4.89ms\tremaining: 1.22ms\n",
      "4:\tlearn: 10901.3260083\ttotal: 6.06ms\tremaining: 0us\n",
      "0:\tlearn: 15106.2542737\ttotal: 1.54ms\tremaining: 6.17ms\n",
      "1:\tlearn: 13885.7137424\ttotal: 2.82ms\tremaining: 4.23ms\n",
      "2:\tlearn: 12780.6227137\ttotal: 4.05ms\tremaining: 2.7ms\n",
      "3:\tlearn: 11709.4494709\ttotal: 5.23ms\tremaining: 1.31ms\n",
      "4:\tlearn: 10800.5858330\ttotal: 6.46ms\tremaining: 0us\n",
      "0:\tlearn: 13048.1367732\ttotal: 1.41ms\tremaining: 5.64ms\n",
      "1:\tlearn: 12111.2190401\ttotal: 2.61ms\tremaining: 3.92ms\n",
      "2:\tlearn: 11502.2564301\ttotal: 3.77ms\tremaining: 2.51ms\n",
      "3:\tlearn: 10766.5164376\ttotal: 4.94ms\tremaining: 1.24ms\n",
      "4:\tlearn: 10169.5201826\ttotal: 6.1ms\tremaining: 0us\n",
      "0:\tlearn: 15644.7900949\ttotal: 1.61ms\tremaining: 6.45ms\n",
      "1:\tlearn: 14328.6338047\ttotal: 2.89ms\tremaining: 4.34ms\n",
      "2:\tlearn: 13147.7868310\ttotal: 4.11ms\tremaining: 2.74ms\n",
      "3:\tlearn: 12015.3881031\ttotal: 5.27ms\tremaining: 1.32ms\n",
      "4:\tlearn: 11059.4153948\ttotal: 6.43ms\tremaining: 0us\n",
      "0:\tlearn: 10519.5334437\ttotal: 1.36ms\tremaining: 5.44ms\n",
      "1:\tlearn: 9357.0882245\ttotal: 2.56ms\tremaining: 3.85ms\n",
      "2:\tlearn: 8345.8407158\ttotal: 3.76ms\tremaining: 2.51ms\n",
      "3:\tlearn: 7482.7571774\ttotal: 4.93ms\tremaining: 1.23ms\n",
      "4:\tlearn: 6863.7419976\ttotal: 6.15ms\tremaining: 0us\n",
      "0:\tlearn: 14398.2957871\ttotal: 2.51ms\tremaining: 10.1ms\n",
      "1:\tlearn: 12770.2267681\ttotal: 3.8ms\tremaining: 5.71ms\n",
      "2:\tlearn: 11267.6545072\ttotal: 5.23ms\tremaining: 3.48ms\n",
      "3:\tlearn: 9980.6544708\ttotal: 6.42ms\tremaining: 1.6ms\n",
      "4:\tlearn: 8779.1137594\ttotal: 7.61ms\tremaining: 0us\n",
      "0:\tlearn: 14436.1094960\ttotal: 1.6ms\tremaining: 6.4ms\n",
      "1:\tlearn: 12704.4747196\ttotal: 2.86ms\tremaining: 4.29ms\n",
      "2:\tlearn: 11219.1846161\ttotal: 4.18ms\tremaining: 2.79ms\n",
      "3:\tlearn: 9832.7435899\ttotal: 5.35ms\tremaining: 1.34ms\n",
      "4:\tlearn: 8657.3475449\ttotal: 6.54ms\tremaining: 0us\n",
      "0:\tlearn: 12531.1612479\ttotal: 1.45ms\tremaining: 5.8ms\n",
      "1:\tlearn: 11216.9426056\ttotal: 2.73ms\tremaining: 4.1ms\n",
      "2:\tlearn: 10377.7877519\ttotal: 3.96ms\tremaining: 2.64ms\n",
      "3:\tlearn: 9627.4541794\ttotal: 5.16ms\tremaining: 1.29ms\n",
      "4:\tlearn: 8848.5352654\ttotal: 6.37ms\tremaining: 0us\n",
      "0:\tlearn: 14916.9041516\ttotal: 1.45ms\tremaining: 5.82ms\n",
      "1:\tlearn: 13061.3125277\ttotal: 2.65ms\tremaining: 3.97ms\n",
      "2:\tlearn: 11491.5709441\ttotal: 3.83ms\tremaining: 2.55ms\n",
      "3:\tlearn: 10044.8968041\ttotal: 4.99ms\tremaining: 1.25ms\n",
      "4:\tlearn: 8994.3624057\ttotal: 6.17ms\tremaining: 0us\n",
      "0:\tlearn: 10071.9414225\ttotal: 1.36ms\tremaining: 5.45ms\n",
      "1:\tlearn: 8615.8661208\ttotal: 2.53ms\tremaining: 3.8ms\n",
      "2:\tlearn: 7419.1236167\ttotal: 3.69ms\tremaining: 2.46ms\n",
      "3:\tlearn: 6531.3944006\ttotal: 4.87ms\tremaining: 1.22ms\n",
      "4:\tlearn: 5894.7035703\ttotal: 6.06ms\tremaining: 0us\n",
      "0:\tlearn: 13738.6407379\ttotal: 1.36ms\tremaining: 5.43ms\n",
      "1:\tlearn: 11680.3592251\ttotal: 2.54ms\tremaining: 3.81ms\n",
      "2:\tlearn: 9882.5504780\ttotal: 3.69ms\tremaining: 2.46ms\n",
      "3:\tlearn: 8555.4684587\ttotal: 4.82ms\tremaining: 1.21ms\n",
      "4:\tlearn: 7806.0290275\ttotal: 6.01ms\tremaining: 0us\n",
      "0:\tlearn: 13769.0091637\ttotal: 1.53ms\tremaining: 6.11ms\n",
      "1:\tlearn: 11592.6811970\ttotal: 2.71ms\tremaining: 4.06ms\n",
      "2:\tlearn: 9682.4058626\ttotal: 3.88ms\tremaining: 2.58ms\n",
      "3:\tlearn: 8323.8309753\ttotal: 5.01ms\tremaining: 1.25ms\n",
      "4:\tlearn: 7036.3345222\ttotal: 6.18ms\tremaining: 0us\n",
      "0:\tlearn: 12019.9585516\ttotal: 1.38ms\tremaining: 5.53ms\n",
      "1:\tlearn: 10389.8162858\ttotal: 2.59ms\tremaining: 3.89ms\n",
      "2:\tlearn: 9374.4951457\ttotal: 3.79ms\tremaining: 2.52ms\n",
      "3:\tlearn: 8495.7733885\ttotal: 4.97ms\tremaining: 1.24ms\n",
      "4:\tlearn: 7737.5361220\ttotal: 6.16ms\tremaining: 0us\n",
      "0:\tlearn: 14193.7589367\ttotal: 1.57ms\tremaining: 6.3ms\n",
      "1:\tlearn: 11877.6659340\ttotal: 2.89ms\tremaining: 4.34ms\n",
      "2:\tlearn: 9883.1619234\ttotal: 4.2ms\tremaining: 2.8ms\n",
      "3:\tlearn: 8516.4222235\ttotal: 5.4ms\tremaining: 1.35ms\n",
      "4:\tlearn: 7193.9880576\ttotal: 6.61ms\tremaining: 0us\n",
      "0:\tlearn: 11564.6245031\ttotal: 1.77ms\tremaining: 0us\n",
      "0:\tlearn: 15767.4785202\ttotal: 1.63ms\tremaining: 0us\n",
      "0:\tlearn: 15821.9715017\ttotal: 1.59ms\tremaining: 0us\n",
      "0:\tlearn: 13710.5606396\ttotal: 1.58ms\tremaining: 0us\n",
      "0:\tlearn: 16437.4830737\ttotal: 2.89ms\tremaining: 0us\n",
      "0:\tlearn: 11250.6246112\ttotal: 1.62ms\tremaining: 0us\n",
      "0:\tlearn: 15141.9291748\ttotal: 1.6ms\tremaining: 0us\n",
      "0:\tlearn: 15191.1411682\ttotal: 1.67ms\tremaining: 0us\n",
      "0:\tlearn: 13325.1858721\ttotal: 1.75ms\tremaining: 0us\n",
      "0:\tlearn: 15764.2656977\ttotal: 2.8ms\tremaining: 0us\n",
      "0:\tlearn: 10937.3392676\ttotal: 1.64ms\tremaining: 0us\n",
      "0:\tlearn: 14518.0747873\ttotal: 1.62ms\tremaining: 0us\n",
      "0:\tlearn: 14561.8762732\ttotal: 3.26ms\tremaining: 0us\n",
      "0:\tlearn: 12940.8168405\ttotal: 1.78ms\tremaining: 0us\n",
      "0:\tlearn: 15092.9301452\ttotal: 1.91ms\tremaining: 0us\n",
      "0:\tlearn: 10624.8317523\ttotal: 1.86ms\tremaining: 0us\n",
      "0:\tlearn: 13896.1437857\ttotal: 3.29ms\tremaining: 0us\n",
      "0:\tlearn: 13934.3890468\ttotal: 3.25ms\tremaining: 0us\n",
      "0:\tlearn: 12557.5459861\ttotal: 1.68ms\tremaining: 0us\n",
      "0:\tlearn: 14423.7393369\ttotal: 1.68ms\tremaining: 0us\n",
      "0:\tlearn: 11564.6245031\ttotal: 3.27ms\tremaining: 3.27ms\n",
      "1:\tlearn: 11253.5351927\ttotal: 4.77ms\tremaining: 0us\n",
      "0:\tlearn: 15767.4785202\ttotal: 2.73ms\tremaining: 2.73ms\n",
      "1:\tlearn: 15166.5338813\ttotal: 4.17ms\tremaining: 0us\n",
      "0:\tlearn: 15821.9715017\ttotal: 1.75ms\tremaining: 1.75ms\n",
      "1:\tlearn: 15164.0984359\ttotal: 3.16ms\tremaining: 0us\n",
      "0:\tlearn: 13710.5606396\ttotal: 1.64ms\tremaining: 1.64ms\n",
      "1:\tlearn: 13361.0579781\ttotal: 3.12ms\tremaining: 0us\n",
      "0:\tlearn: 16437.4830737\ttotal: 2.98ms\tremaining: 2.98ms\n",
      "1:\tlearn: 15792.5941467\ttotal: 4.45ms\tremaining: 0us\n",
      "0:\tlearn: 11250.6246112\ttotal: 1.81ms\tremaining: 1.81ms\n",
      "1:\tlearn: 10646.9844132\ttotal: 3.31ms\tremaining: 0us\n",
      "0:\tlearn: 15141.9291748\ttotal: 2.69ms\tremaining: 2.69ms\n",
      "1:\tlearn: 13995.2546045\ttotal: 4.11ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 15191.1411682\ttotal: 1.87ms\tremaining: 1.87ms\n",
      "1:\tlearn: 13932.7075820\ttotal: 3.49ms\tremaining: 0us\n",
      "0:\tlearn: 13325.1858721\ttotal: 1.67ms\tremaining: 1.67ms\n",
      "1:\tlearn: 12648.4608205\ttotal: 3.22ms\tremaining: 0us\n",
      "0:\tlearn: 15764.2656977\ttotal: 1.85ms\tremaining: 1.85ms\n",
      "1:\tlearn: 14535.5603651\ttotal: 3.41ms\tremaining: 0us\n",
      "0:\tlearn: 10937.3392676\ttotal: 2.58ms\tremaining: 2.58ms\n",
      "1:\tlearn: 10059.5788896\ttotal: 4.07ms\tremaining: 0us\n",
      "0:\tlearn: 14518.0747873\ttotal: 1.7ms\tremaining: 1.7ms\n",
      "1:\tlearn: 12881.2630159\ttotal: 3.22ms\tremaining: 0us\n",
      "0:\tlearn: 14561.8762732\ttotal: 1.8ms\tremaining: 1.8ms\n",
      "1:\tlearn: 12760.3574482\ttotal: 3.24ms\tremaining: 0us\n",
      "0:\tlearn: 12940.8168405\ttotal: 3.13ms\tremaining: 3.13ms\n",
      "1:\tlearn: 11958.9530629\ttotal: 4.65ms\tremaining: 0us\n",
      "0:\tlearn: 15092.9301452\ttotal: 1.78ms\tremaining: 1.78ms\n",
      "1:\tlearn: 13341.8309696\ttotal: 3.29ms\tremaining: 0us\n",
      "0:\tlearn: 10624.8317523\ttotal: 2.85ms\tremaining: 2.85ms\n",
      "1:\tlearn: 9491.2732276\ttotal: 4.34ms\tremaining: 0us\n",
      "0:\tlearn: 13896.1437857\ttotal: 1.78ms\tremaining: 1.78ms\n",
      "1:\tlearn: 11825.2480326\ttotal: 3.24ms\tremaining: 0us\n",
      "0:\tlearn: 13934.3890468\ttotal: 2.86ms\tremaining: 2.86ms\n",
      "1:\tlearn: 11647.4811709\ttotal: 4.37ms\tremaining: 0us\n",
      "0:\tlearn: 12557.5459861\ttotal: 1.61ms\tremaining: 1.61ms\n",
      "1:\tlearn: 11292.4172719\ttotal: 3.04ms\tremaining: 0us\n",
      "0:\tlearn: 14423.7393369\ttotal: 1.76ms\tremaining: 1.76ms\n",
      "1:\tlearn: 12212.0967873\ttotal: 3.23ms\tremaining: 0us\n",
      "0:\tlearn: 11564.6245031\ttotal: 1.64ms\tremaining: 3.28ms\n",
      "1:\tlearn: 11253.5351927\ttotal: 3.05ms\tremaining: 1.53ms\n",
      "2:\tlearn: 10957.4819207\ttotal: 4.48ms\tremaining: 0us\n",
      "0:\tlearn: 15767.4785202\ttotal: 1.75ms\tremaining: 3.51ms\n",
      "1:\tlearn: 15166.5338813\ttotal: 3.23ms\tremaining: 1.62ms\n",
      "2:\tlearn: 14591.3515214\ttotal: 4.7ms\tremaining: 0us\n",
      "0:\tlearn: 15821.9715017\ttotal: 1.86ms\tremaining: 3.73ms\n",
      "1:\tlearn: 15164.0984359\ttotal: 3.37ms\tremaining: 1.68ms\n",
      "2:\tlearn: 14578.2288471\ttotal: 4.97ms\tremaining: 0us\n",
      "0:\tlearn: 13710.5606396\ttotal: 1.8ms\tremaining: 3.61ms\n",
      "1:\tlearn: 13361.0579781\ttotal: 3.31ms\tremaining: 1.66ms\n",
      "2:\tlearn: 12996.9528743\ttotal: 4.73ms\tremaining: 0us\n",
      "0:\tlearn: 16437.4830737\ttotal: 1.65ms\tremaining: 3.31ms\n",
      "1:\tlearn: 15792.5941467\ttotal: 3.07ms\tremaining: 1.53ms\n",
      "2:\tlearn: 15175.3311647\ttotal: 4.47ms\tremaining: 0us\n",
      "0:\tlearn: 11250.6246112\ttotal: 2.62ms\tremaining: 5.24ms\n",
      "1:\tlearn: 10646.9844132\ttotal: 4.07ms\tremaining: 2.04ms\n",
      "2:\tlearn: 10090.7089703\ttotal: 5.49ms\tremaining: 0us\n",
      "0:\tlearn: 15141.9291748\ttotal: 1.67ms\tremaining: 3.33ms\n",
      "1:\tlearn: 13995.2546045\ttotal: 3.12ms\tremaining: 1.56ms\n",
      "2:\tlearn: 12947.6279147\ttotal: 4.61ms\tremaining: 0us\n",
      "0:\tlearn: 15191.1411682\ttotal: 1.68ms\tremaining: 3.35ms\n",
      "1:\tlearn: 13932.7075820\ttotal: 3.12ms\tremaining: 1.56ms\n",
      "2:\tlearn: 12867.1187722\ttotal: 4.56ms\tremaining: 0us\n",
      "0:\tlearn: 13325.1858721\ttotal: 2.59ms\tremaining: 5.19ms\n",
      "1:\tlearn: 12648.4608205\ttotal: 3.97ms\tremaining: 1.98ms\n",
      "2:\tlearn: 11964.7028978\ttotal: 5.32ms\tremaining: 0us\n",
      "0:\tlearn: 15764.2656977\ttotal: 1.76ms\tremaining: 3.52ms\n",
      "1:\tlearn: 14535.5603651\ttotal: 3.19ms\tremaining: 1.59ms\n",
      "2:\tlearn: 13414.5755367\ttotal: 4.62ms\tremaining: 0us\n",
      "0:\tlearn: 10937.3392676\ttotal: 2.71ms\tremaining: 5.43ms\n",
      "1:\tlearn: 10059.5788896\ttotal: 4.16ms\tremaining: 2.08ms\n",
      "2:\tlearn: 9276.9274774\ttotal: 5.58ms\tremaining: 0us\n",
      "0:\tlearn: 14518.0747873\ttotal: 3.02ms\tremaining: 6.04ms\n",
      "1:\tlearn: 12881.2630159\ttotal: 4.5ms\tremaining: 2.25ms\n",
      "2:\tlearn: 11457.4143080\ttotal: 5.99ms\tremaining: 0us\n",
      "0:\tlearn: 14561.8762732\ttotal: 1.6ms\tremaining: 3.21ms\n",
      "1:\tlearn: 12760.3574482\ttotal: 3.02ms\tremaining: 1.51ms\n",
      "2:\tlearn: 11314.4381104\ttotal: 4.43ms\tremaining: 0us\n",
      "0:\tlearn: 12940.8168405\ttotal: 2.63ms\tremaining: 5.26ms\n",
      "1:\tlearn: 11958.9530629\ttotal: 4.03ms\tremaining: 2.01ms\n",
      "2:\tlearn: 10997.4389289\ttotal: 5.47ms\tremaining: 0us\n",
      "0:\tlearn: 15092.9301452\ttotal: 3.26ms\tremaining: 6.53ms\n",
      "1:\tlearn: 13341.8309696\ttotal: 4.71ms\tremaining: 2.35ms\n",
      "2:\tlearn: 11822.6939898\ttotal: 6.15ms\tremaining: 0us\n",
      "0:\tlearn: 10624.8317523\ttotal: 1.66ms\tremaining: 3.31ms\n",
      "1:\tlearn: 9491.2732276\ttotal: 3.23ms\tremaining: 1.61ms\n",
      "2:\tlearn: 8514.1656698\ttotal: 4.9ms\tremaining: 0us\n",
      "0:\tlearn: 13896.1437857\ttotal: 2.87ms\tremaining: 5.74ms\n",
      "1:\tlearn: 11825.2480326\ttotal: 4.32ms\tremaining: 2.16ms\n",
      "2:\tlearn: 10673.8630674\ttotal: 5.7ms\tremaining: 0us\n",
      "0:\tlearn: 13934.3890468\ttotal: 1.64ms\tremaining: 3.27ms\n",
      "1:\tlearn: 11647.4811709\ttotal: 3.14ms\tremaining: 1.57ms\n",
      "2:\tlearn: 9914.0401412\ttotal: 4.51ms\tremaining: 0us\n",
      "0:\tlearn: 12557.5459861\ttotal: 1.8ms\tremaining: 3.6ms\n",
      "1:\tlearn: 11292.4172719\ttotal: 3.23ms\tremaining: 1.62ms\n",
      "2:\tlearn: 10092.5865696\ttotal: 4.63ms\tremaining: 0us\n",
      "0:\tlearn: 14423.7393369\ttotal: 3.31ms\tremaining: 6.61ms\n",
      "1:\tlearn: 12212.0967873\ttotal: 4.87ms\tremaining: 2.43ms\n",
      "2:\tlearn: 10347.6102395\ttotal: 6.28ms\tremaining: 0us\n",
      "0:\tlearn: 11564.6245031\ttotal: 3.5ms\tremaining: 10.5ms\n",
      "1:\tlearn: 11253.5351927\ttotal: 4.97ms\tremaining: 4.97ms\n",
      "2:\tlearn: 10957.4819207\ttotal: 6.42ms\tremaining: 2.14ms\n",
      "3:\tlearn: 10666.9807683\ttotal: 7.84ms\tremaining: 0us\n",
      "0:\tlearn: 15767.4785202\ttotal: 3.26ms\tremaining: 9.79ms\n",
      "1:\tlearn: 15166.5338813\ttotal: 4.78ms\tremaining: 4.78ms\n",
      "2:\tlearn: 14591.3515214\ttotal: 6.17ms\tremaining: 2.06ms\n",
      "3:\tlearn: 14031.5980231\ttotal: 7.59ms\tremaining: 0us\n",
      "0:\tlearn: 15821.9715017\ttotal: 1.6ms\tremaining: 4.8ms\n",
      "1:\tlearn: 15164.0984359\ttotal: 3.02ms\tremaining: 3.02ms\n",
      "2:\tlearn: 14578.2288471\ttotal: 4.39ms\tremaining: 1.46ms\n",
      "3:\tlearn: 13978.5875259\ttotal: 5.77ms\tremaining: 0us\n",
      "0:\tlearn: 13710.5606396\ttotal: 1.65ms\tremaining: 4.96ms\n",
      "1:\tlearn: 13361.0579781\ttotal: 3.16ms\tremaining: 3.16ms\n",
      "2:\tlearn: 12996.9528743\ttotal: 4.73ms\tremaining: 1.57ms\n",
      "3:\tlearn: 12644.3945004\ttotal: 6.15ms\tremaining: 0us\n",
      "0:\tlearn: 16437.4830737\ttotal: 1.64ms\tremaining: 4.93ms\n",
      "1:\tlearn: 15792.5941467\ttotal: 3.05ms\tremaining: 3.05ms\n",
      "2:\tlearn: 15175.3311647\ttotal: 4.49ms\tremaining: 1.5ms\n",
      "3:\tlearn: 14577.5158821\ttotal: 5.98ms\tremaining: 0us\n",
      "0:\tlearn: 11250.6246112\ttotal: 1.65ms\tremaining: 4.95ms\n",
      "1:\tlearn: 10646.9844132\ttotal: 3.07ms\tremaining: 3.07ms\n",
      "2:\tlearn: 10090.7089703\ttotal: 4.48ms\tremaining: 1.49ms\n",
      "3:\tlearn: 9494.4205114\ttotal: 5.86ms\tremaining: 0us\n",
      "0:\tlearn: 15141.9291748\ttotal: 2.97ms\tremaining: 8.91ms\n",
      "1:\tlearn: 13995.2546045\ttotal: 4.39ms\tremaining: 4.39ms\n",
      "2:\tlearn: 12947.6279147\ttotal: 5.77ms\tremaining: 1.92ms\n",
      "3:\tlearn: 11921.8718672\ttotal: 7.15ms\tremaining: 0us\n",
      "0:\tlearn: 15191.1411682\ttotal: 1.78ms\tremaining: 5.33ms\n",
      "1:\tlearn: 13932.7075820\ttotal: 3.23ms\tremaining: 3.23ms\n",
      "2:\tlearn: 12867.1187722\ttotal: 4.63ms\tremaining: 1.54ms\n",
      "3:\tlearn: 11823.5908741\ttotal: 6.02ms\tremaining: 0us\n",
      "0:\tlearn: 13325.1858721\ttotal: 1.57ms\tremaining: 4.71ms\n",
      "1:\tlearn: 12648.4608205\ttotal: 3ms\tremaining: 3ms\n",
      "2:\tlearn: 11964.7028978\ttotal: 4.35ms\tremaining: 1.45ms\n",
      "3:\tlearn: 11323.8751709\ttotal: 5.72ms\tremaining: 0us\n",
      "0:\tlearn: 15764.2656977\ttotal: 1.71ms\tremaining: 5.13ms\n",
      "1:\tlearn: 14535.5603651\ttotal: 3.15ms\tremaining: 3.15ms\n",
      "2:\tlearn: 13414.5755367\ttotal: 4.53ms\tremaining: 1.51ms\n",
      "3:\tlearn: 12387.4090524\ttotal: 5.96ms\tremaining: 0us\n",
      "0:\tlearn: 10937.3392676\ttotal: 1.56ms\tremaining: 4.69ms\n",
      "1:\tlearn: 10059.5788896\ttotal: 3.06ms\tremaining: 3.06ms\n",
      "2:\tlearn: 9276.9274774\ttotal: 4.55ms\tremaining: 1.51ms\n",
      "3:\tlearn: 8465.5617025\ttotal: 5.99ms\tremaining: 0us\n",
      "0:\tlearn: 14518.0747873\ttotal: 3.17ms\tremaining: 9.51ms\n",
      "1:\tlearn: 12881.2630159\ttotal: 4.61ms\tremaining: 4.61ms\n",
      "2:\tlearn: 11457.4143080\ttotal: 6.05ms\tremaining: 2.02ms\n",
      "3:\tlearn: 10109.0858654\ttotal: 7.46ms\tremaining: 0us\n",
      "0:\tlearn: 14561.8762732\ttotal: 1.69ms\tremaining: 5.07ms\n",
      "1:\tlearn: 12760.3574482\ttotal: 3.16ms\tremaining: 3.16ms\n",
      "2:\tlearn: 11314.4381104\ttotal: 4.54ms\tremaining: 1.51ms\n",
      "3:\tlearn: 9962.9734233\ttotal: 5.93ms\tremaining: 0us\n",
      "0:\tlearn: 12940.8168405\ttotal: 1.62ms\tremaining: 4.87ms\n",
      "1:\tlearn: 11958.9530629\ttotal: 3.02ms\tremaining: 3.02ms\n",
      "2:\tlearn: 10997.4389289\ttotal: 4.38ms\tremaining: 1.46ms\n",
      "3:\tlearn: 10125.7483363\ttotal: 5.75ms\tremaining: 0us\n",
      "0:\tlearn: 15092.9301452\ttotal: 1.88ms\tremaining: 5.63ms\n",
      "1:\tlearn: 13341.8309696\ttotal: 3.29ms\tremaining: 3.29ms\n",
      "2:\tlearn: 11822.6939898\ttotal: 4.71ms\tremaining: 1.57ms\n",
      "3:\tlearn: 10496.3470932\ttotal: 6.11ms\tremaining: 0us\n",
      "0:\tlearn: 10624.8317523\ttotal: 1.64ms\tremaining: 4.91ms\n",
      "1:\tlearn: 9491.2732276\ttotal: 3.02ms\tremaining: 3.02ms\n",
      "2:\tlearn: 8514.1656698\ttotal: 4.42ms\tremaining: 1.47ms\n",
      "3:\tlearn: 7535.1584957\ttotal: 5.79ms\tremaining: 0us\n",
      "0:\tlearn: 13896.1437857\ttotal: 1.68ms\tremaining: 5.03ms\n",
      "1:\tlearn: 11825.2480326\ttotal: 3.12ms\tremaining: 3.12ms\n",
      "2:\tlearn: 10673.8630674\ttotal: 4.5ms\tremaining: 1.5ms\n",
      "3:\tlearn: 9658.4838869\ttotal: 5.87ms\tremaining: 0us\n",
      "0:\tlearn: 13934.3890468\ttotal: 1.65ms\tremaining: 4.95ms\n",
      "1:\tlearn: 11647.4811709\ttotal: 3.03ms\tremaining: 3.03ms\n",
      "2:\tlearn: 9914.0401412\ttotal: 4.39ms\tremaining: 1.46ms\n",
      "3:\tlearn: 8372.5503107\ttotal: 5.76ms\tremaining: 0us\n",
      "0:\tlearn: 12557.5459861\ttotal: 1.55ms\tremaining: 4.66ms\n",
      "1:\tlearn: 11292.4172719\ttotal: 2.96ms\tremaining: 2.96ms\n",
      "2:\tlearn: 10092.5865696\ttotal: 4.37ms\tremaining: 1.46ms\n",
      "3:\tlearn: 9041.2385731\ttotal: 5.76ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 14423.7393369\ttotal: 1.84ms\tremaining: 5.51ms\n",
      "1:\tlearn: 12212.0967873\ttotal: 3.38ms\tremaining: 3.38ms\n",
      "2:\tlearn: 10347.6102395\ttotal: 4.77ms\tremaining: 1.59ms\n",
      "3:\tlearn: 8836.5566700\ttotal: 6.21ms\tremaining: 0us\n",
      "0:\tlearn: 11564.6245031\ttotal: 1.93ms\tremaining: 7.72ms\n",
      "1:\tlearn: 11253.5351927\ttotal: 3.46ms\tremaining: 5.19ms\n",
      "2:\tlearn: 10957.4819207\ttotal: 4.91ms\tremaining: 3.27ms\n",
      "3:\tlearn: 10666.9807683\ttotal: 6.36ms\tremaining: 1.59ms\n",
      "4:\tlearn: 10383.4963169\ttotal: 7.8ms\tremaining: 0us\n",
      "0:\tlearn: 15767.4785202\ttotal: 2.01ms\tremaining: 8.03ms\n",
      "1:\tlearn: 15166.5338813\ttotal: 3.56ms\tremaining: 5.33ms\n",
      "2:\tlearn: 14591.3515214\ttotal: 5.03ms\tremaining: 3.35ms\n",
      "3:\tlearn: 14031.5980231\ttotal: 6.46ms\tremaining: 1.62ms\n",
      "4:\tlearn: 13501.0189916\ttotal: 7.94ms\tremaining: 0us\n",
      "0:\tlearn: 15821.9715017\ttotal: 3.54ms\tremaining: 14.2ms\n",
      "1:\tlearn: 15164.0984359\ttotal: 5ms\tremaining: 7.51ms\n",
      "2:\tlearn: 14578.2288471\ttotal: 6.41ms\tremaining: 4.27ms\n",
      "3:\tlearn: 13978.5875259\ttotal: 7.84ms\tremaining: 1.96ms\n",
      "4:\tlearn: 13404.8209729\ttotal: 9.22ms\tremaining: 0us\n",
      "0:\tlearn: 13710.5606396\ttotal: 1.64ms\tremaining: 6.54ms\n",
      "1:\tlearn: 13361.0579781\ttotal: 3.04ms\tremaining: 4.56ms\n",
      "2:\tlearn: 12996.9528743\ttotal: 4.43ms\tremaining: 2.96ms\n",
      "3:\tlearn: 12644.3945004\ttotal: 5.86ms\tremaining: 1.47ms\n",
      "4:\tlearn: 12302.9435380\ttotal: 7.34ms\tremaining: 0us\n",
      "0:\tlearn: 16437.4830737\ttotal: 1.66ms\tremaining: 6.66ms\n",
      "1:\tlearn: 15792.5941467\ttotal: 3.15ms\tremaining: 4.72ms\n",
      "2:\tlearn: 15175.3311647\ttotal: 4.7ms\tremaining: 3.13ms\n",
      "3:\tlearn: 14577.5158821\ttotal: 6.12ms\tremaining: 1.53ms\n",
      "4:\tlearn: 14003.6690302\ttotal: 7.54ms\tremaining: 0us\n",
      "0:\tlearn: 11250.6246112\ttotal: 1.72ms\tremaining: 6.89ms\n",
      "1:\tlearn: 10646.9844132\ttotal: 3.13ms\tremaining: 4.69ms\n",
      "2:\tlearn: 10090.7089703\ttotal: 4.52ms\tremaining: 3.01ms\n",
      "3:\tlearn: 9494.4205114\ttotal: 5.92ms\tremaining: 1.48ms\n",
      "4:\tlearn: 8995.9473941\ttotal: 7.32ms\tremaining: 0us\n",
      "0:\tlearn: 15141.9291748\ttotal: 3.54ms\tremaining: 14.2ms\n",
      "1:\tlearn: 13995.2546045\ttotal: 5ms\tremaining: 7.5ms\n",
      "2:\tlearn: 12947.6279147\ttotal: 6.46ms\tremaining: 4.3ms\n",
      "3:\tlearn: 11921.8718672\ttotal: 7.89ms\tremaining: 1.97ms\n",
      "4:\tlearn: 11334.4781998\ttotal: 9.31ms\tremaining: 0us\n",
      "0:\tlearn: 15191.1411682\ttotal: 1.78ms\tremaining: 7.12ms\n",
      "1:\tlearn: 13932.7075820\ttotal: 3.23ms\tremaining: 4.85ms\n",
      "2:\tlearn: 12867.1187722\ttotal: 4.62ms\tremaining: 3.08ms\n",
      "3:\tlearn: 11823.5908741\ttotal: 6ms\tremaining: 1.5ms\n",
      "4:\tlearn: 10873.7874189\ttotal: 7.39ms\tremaining: 0us\n",
      "0:\tlearn: 13325.1858721\ttotal: 1.66ms\tremaining: 6.63ms\n",
      "1:\tlearn: 12648.4608205\ttotal: 3.04ms\tremaining: 4.55ms\n",
      "2:\tlearn: 11964.7028978\ttotal: 4.41ms\tremaining: 2.94ms\n",
      "3:\tlearn: 11323.8751709\ttotal: 5.76ms\tremaining: 1.44ms\n",
      "4:\tlearn: 10716.9865522\ttotal: 7.13ms\tremaining: 0us\n",
      "0:\tlearn: 15764.2656977\ttotal: 1.68ms\tremaining: 6.73ms\n",
      "1:\tlearn: 14535.5603651\ttotal: 3.26ms\tremaining: 4.89ms\n",
      "2:\tlearn: 13414.5755367\ttotal: 4.72ms\tremaining: 3.15ms\n",
      "3:\tlearn: 12387.4090524\ttotal: 6.16ms\tremaining: 1.54ms\n",
      "4:\tlearn: 11437.9951177\ttotal: 7.6ms\tremaining: 0us\n",
      "0:\tlearn: 10937.3392676\ttotal: 1.73ms\tremaining: 6.92ms\n",
      "1:\tlearn: 10059.5788896\ttotal: 3.17ms\tremaining: 4.75ms\n",
      "2:\tlearn: 9276.9274774\ttotal: 4.6ms\tremaining: 3.07ms\n",
      "3:\tlearn: 8465.5617025\ttotal: 6.05ms\tremaining: 1.51ms\n",
      "4:\tlearn: 7806.2069405\ttotal: 7.51ms\tremaining: 0us\n",
      "0:\tlearn: 14518.0747873\ttotal: 3.11ms\tremaining: 12.4ms\n",
      "1:\tlearn: 12881.2630159\ttotal: 4.5ms\tremaining: 6.74ms\n",
      "2:\tlearn: 11457.4143080\ttotal: 5.87ms\tremaining: 3.91ms\n",
      "3:\tlearn: 10109.0858654\ttotal: 7.25ms\tremaining: 1.81ms\n",
      "4:\tlearn: 9374.4764825\ttotal: 8.61ms\tremaining: 0us\n",
      "0:\tlearn: 14561.8762732\ttotal: 2.9ms\tremaining: 11.6ms\n",
      "1:\tlearn: 12760.3574482\ttotal: 4.4ms\tremaining: 6.6ms\n",
      "2:\tlearn: 11314.4381104\ttotal: 5.99ms\tremaining: 4ms\n",
      "3:\tlearn: 9962.9734233\ttotal: 7.61ms\tremaining: 1.9ms\n",
      "4:\tlearn: 8806.4720229\ttotal: 9.11ms\tremaining: 0us\n",
      "0:\tlearn: 12940.8168405\ttotal: 1.81ms\tremaining: 7.26ms\n",
      "1:\tlearn: 11958.9530629\ttotal: 3.31ms\tremaining: 4.96ms\n",
      "2:\tlearn: 10997.4389289\ttotal: 4.74ms\tremaining: 3.16ms\n",
      "3:\tlearn: 10125.7483363\ttotal: 6.16ms\tremaining: 1.54ms\n",
      "4:\tlearn: 9335.3068970\ttotal: 7.68ms\tremaining: 0us\n",
      "0:\tlearn: 15092.9301452\ttotal: 1.67ms\tremaining: 6.67ms\n",
      "1:\tlearn: 13341.8309696\ttotal: 3.13ms\tremaining: 4.7ms\n",
      "2:\tlearn: 11822.6939898\ttotal: 4.55ms\tremaining: 3.03ms\n",
      "3:\tlearn: 10496.3470932\ttotal: 6.01ms\tremaining: 1.5ms\n",
      "4:\tlearn: 9254.8521212\ttotal: 7.45ms\tremaining: 0us\n",
      "0:\tlearn: 10624.8317523\ttotal: 1.8ms\tremaining: 7.21ms\n",
      "1:\tlearn: 9491.2732276\ttotal: 3.48ms\tremaining: 5.21ms\n",
      "2:\tlearn: 8514.1656698\ttotal: 5.06ms\tremaining: 3.37ms\n",
      "3:\tlearn: 7535.1584957\ttotal: 6.71ms\tremaining: 1.68ms\n",
      "4:\tlearn: 6807.9064291\ttotal: 8.32ms\tremaining: 0us\n",
      "0:\tlearn: 13896.1437857\ttotal: 1.73ms\tremaining: 6.93ms\n",
      "1:\tlearn: 11825.2480326\ttotal: 3.2ms\tremaining: 4.8ms\n",
      "2:\tlearn: 10673.8630674\ttotal: 4.66ms\tremaining: 3.1ms\n",
      "3:\tlearn: 9658.4838869\ttotal: 6.15ms\tremaining: 1.54ms\n",
      "4:\tlearn: 8738.7508994\ttotal: 7.59ms\tremaining: 0us\n",
      "0:\tlearn: 13934.3890468\ttotal: 2.65ms\tremaining: 10.6ms\n",
      "1:\tlearn: 11647.4811709\ttotal: 4.09ms\tremaining: 6.14ms\n",
      "2:\tlearn: 9914.0401412\ttotal: 5.6ms\tremaining: 3.73ms\n",
      "3:\tlearn: 8372.5503107\ttotal: 7.02ms\tremaining: 1.75ms\n",
      "4:\tlearn: 7023.8901432\ttotal: 8.46ms\tremaining: 0us\n",
      "0:\tlearn: 12557.5459861\ttotal: 1.63ms\tremaining: 6.53ms\n",
      "1:\tlearn: 11292.4172719\ttotal: 3.07ms\tremaining: 4.6ms\n",
      "2:\tlearn: 10092.5865696\ttotal: 4.46ms\tremaining: 2.97ms\n",
      "3:\tlearn: 9041.2385731\ttotal: 5.88ms\tremaining: 1.47ms\n",
      "4:\tlearn: 8193.2424920\ttotal: 7.31ms\tremaining: 0us\n",
      "0:\tlearn: 14423.7393369\ttotal: 3.03ms\tremaining: 12.1ms\n",
      "1:\tlearn: 12212.0967873\ttotal: 4.46ms\tremaining: 6.69ms\n",
      "2:\tlearn: 10347.6102395\ttotal: 5.9ms\tremaining: 3.93ms\n",
      "3:\tlearn: 8836.5566700\ttotal: 7.34ms\tremaining: 1.83ms\n",
      "4:\tlearn: 7492.1712634\ttotal: 8.78ms\tremaining: 0us\n",
      "0:\tlearn: 11586.2930280\ttotal: 3.86ms\tremaining: 0us\n",
      "0:\tlearn: 15757.6804051\ttotal: 2.01ms\tremaining: 0us\n",
      "0:\tlearn: 15812.6206658\ttotal: 3.19ms\tremaining: 0us\n",
      "0:\tlearn: 13747.9827805\ttotal: 5.56ms\tremaining: 0us\n",
      "0:\tlearn: 16428.5068709\ttotal: 1.94ms\tremaining: 0us\n",
      "0:\tlearn: 11293.6095624\ttotal: 1.96ms\tremaining: 0us\n",
      "0:\tlearn: 15121.8573801\ttotal: 3.27ms\tremaining: 0us\n",
      "0:\tlearn: 15171.8420703\ttotal: 2.14ms\tremaining: 0us\n",
      "0:\tlearn: 13399.4070336\ttotal: 3.21ms\tremaining: 0us\n",
      "0:\tlearn: 15745.7034228\ttotal: 3.51ms\tremaining: 0us\n",
      "0:\tlearn: 11001.2562921\ttotal: 1.9ms\tremaining: 0us\n",
      "0:\tlearn: 14487.1947382\ttotal: 3.82ms\tremaining: 0us\n",
      "0:\tlearn: 14531.9556720\ttotal: 1.93ms\tremaining: 0us\n",
      "0:\tlearn: 13051.1554699\ttotal: 1.96ms\tremaining: 0us\n",
      "0:\tlearn: 15064.0925911\ttotal: 1.87ms\tremaining: 0us\n",
      "0:\tlearn: 10709.2603264\ttotal: 1.89ms\tremaining: 0us\n",
      "0:\tlearn: 13853.8521042\ttotal: 3.73ms\tremaining: 0us\n",
      "0:\tlearn: 13893.0848992\ttotal: 3.13ms\tremaining: 0us\n",
      "0:\tlearn: 12703.2548313\ttotal: 1.88ms\tremaining: 0us\n",
      "0:\tlearn: 14383.8440805\ttotal: 3.96ms\tremaining: 0us\n",
      "0:\tlearn: 11586.2930280\ttotal: 2.14ms\tremaining: 2.14ms\n",
      "1:\tlearn: 11298.1882629\ttotal: 3.96ms\tremaining: 0us\n",
      "0:\tlearn: 15757.6804051\ttotal: 3.82ms\tremaining: 3.82ms\n",
      "1:\tlearn: 15133.6250270\ttotal: 5.56ms\tremaining: 0us\n",
      "0:\tlearn: 15812.6206658\ttotal: 2.93ms\tremaining: 2.93ms\n",
      "1:\tlearn: 15165.3080588\ttotal: 4.61ms\tremaining: 0us\n",
      "0:\tlearn: 13747.9827805\ttotal: 3.26ms\tremaining: 3.26ms\n",
      "1:\tlearn: 13370.5850468\ttotal: 4.99ms\tremaining: 0us\n",
      "0:\tlearn: 16428.5068709\ttotal: 1.92ms\tremaining: 1.92ms\n",
      "1:\tlearn: 15765.0706687\ttotal: 3.67ms\tremaining: 0us\n",
      "0:\tlearn: 11293.6095624\ttotal: 2.06ms\tremaining: 2.06ms\n",
      "1:\tlearn: 10732.6060871\ttotal: 3.83ms\tremaining: 0us\n",
      "0:\tlearn: 15121.8573801\ttotal: 3.16ms\tremaining: 3.16ms\n",
      "1:\tlearn: 13928.3848866\ttotal: 4.85ms\tremaining: 0us\n",
      "0:\tlearn: 15171.8420703\ttotal: 4.11ms\tremaining: 4.11ms\n",
      "1:\tlearn: 13935.2158041\ttotal: 5.91ms\tremaining: 0us\n",
      "0:\tlearn: 13399.4070336\ttotal: 1.91ms\tremaining: 1.91ms\n",
      "1:\tlearn: 12665.6135451\ttotal: 3.65ms\tremaining: 0us\n",
      "0:\tlearn: 15745.7034228\ttotal: 1.93ms\tremaining: 1.93ms\n",
      "1:\tlearn: 14478.8166357\ttotal: 3.64ms\tremaining: 0us\n",
      "0:\tlearn: 11001.2562921\ttotal: 3.66ms\tremaining: 3.66ms\n",
      "1:\tlearn: 10182.4986201\ttotal: 5.4ms\tremaining: 0us\n",
      "0:\tlearn: 14487.1947382\ttotal: 3.2ms\tremaining: 3.2ms\n",
      "1:\tlearn: 12779.2398962\ttotal: 4.9ms\tremaining: 0us\n",
      "0:\tlearn: 14531.9556720\ttotal: 3.04ms\tremaining: 3.04ms\n",
      "1:\tlearn: 12764.3141652\ttotal: 4.82ms\tremaining: 0us\n",
      "0:\tlearn: 13051.1554699\ttotal: 1.96ms\tremaining: 1.96ms\n",
      "1:\tlearn: 11981.9269382\ttotal: 3.72ms\tremaining: 0us\n",
      "0:\tlearn: 15064.0925911\ttotal: 3.18ms\tremaining: 3.18ms\n",
      "1:\tlearn: 13254.0336860\ttotal: 5.01ms\tremaining: 0us\n",
      "0:\tlearn: 10709.2603264\ttotal: 1.94ms\tremaining: 1.94ms\n",
      "1:\tlearn: 9647.8344822\ttotal: 3.67ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 13853.8521042\ttotal: 1.97ms\tremaining: 1.97ms\n",
      "1:\tlearn: 11686.7204466\ttotal: 3.93ms\tremaining: 0us\n",
      "0:\tlearn: 13893.0848992\ttotal: 1.92ms\tremaining: 1.92ms\n",
      "1:\tlearn: 11653.0954517\ttotal: 3.71ms\tremaining: 0us\n",
      "0:\tlearn: 12703.2548313\ttotal: 2.08ms\tremaining: 2.08ms\n",
      "1:\tlearn: 11319.5133904\ttotal: 3.71ms\tremaining: 0us\n",
      "0:\tlearn: 14383.8440805\ttotal: 2ms\tremaining: 2ms\n",
      "1:\tlearn: 12315.5090652\ttotal: 3.94ms\tremaining: 0us\n",
      "0:\tlearn: 11586.2930280\ttotal: 3.1ms\tremaining: 6.21ms\n",
      "1:\tlearn: 11298.1882629\ttotal: 4.82ms\tremaining: 2.41ms\n",
      "2:\tlearn: 10995.4142884\ttotal: 6.56ms\tremaining: 0us\n",
      "0:\tlearn: 15757.6804051\ttotal: 3.3ms\tremaining: 6.61ms\n",
      "1:\tlearn: 15133.6250270\ttotal: 4.99ms\tremaining: 2.5ms\n",
      "2:\tlearn: 14758.8362531\ttotal: 6.66ms\tremaining: 0us\n",
      "0:\tlearn: 15812.6206658\ttotal: 2.06ms\tremaining: 4.13ms\n",
      "1:\tlearn: 15165.3080588\ttotal: 3.84ms\tremaining: 1.92ms\n",
      "2:\tlearn: 14586.1427055\ttotal: 5.68ms\tremaining: 0us\n",
      "0:\tlearn: 13747.9827805\ttotal: 2.01ms\tremaining: 4.03ms\n",
      "1:\tlearn: 13370.5850468\ttotal: 3.82ms\tremaining: 1.91ms\n",
      "2:\tlearn: 13040.2778285\ttotal: 5.45ms\tremaining: 0us\n",
      "0:\tlearn: 16428.5068709\ttotal: 1.97ms\tremaining: 3.93ms\n",
      "1:\tlearn: 15765.0706687\ttotal: 3.82ms\tremaining: 1.91ms\n",
      "2:\tlearn: 15164.7942467\ttotal: 5.5ms\tremaining: 0us\n",
      "0:\tlearn: 11293.6095624\ttotal: 2.2ms\tremaining: 4.39ms\n",
      "1:\tlearn: 10732.6060871\ttotal: 3.97ms\tremaining: 1.99ms\n",
      "2:\tlearn: 10158.1519784\ttotal: 5.8ms\tremaining: 0us\n",
      "0:\tlearn: 15121.8573801\ttotal: 3.03ms\tremaining: 6.05ms\n",
      "1:\tlearn: 13928.3848866\ttotal: 4.81ms\tremaining: 2.4ms\n",
      "2:\tlearn: 13239.7342414\ttotal: 6.56ms\tremaining: 0us\n",
      "0:\tlearn: 15171.8420703\ttotal: 3.39ms\tremaining: 6.79ms\n",
      "1:\tlearn: 13935.2158041\ttotal: 5.13ms\tremaining: 2.57ms\n",
      "2:\tlearn: 12880.5750757\ttotal: 6.85ms\tremaining: 0us\n",
      "0:\tlearn: 13399.4070336\ttotal: 3.68ms\tremaining: 7.36ms\n",
      "1:\tlearn: 12665.6135451\ttotal: 5.36ms\tremaining: 2.68ms\n",
      "2:\tlearn: 12041.8523765\ttotal: 7.05ms\tremaining: 0us\n",
      "0:\tlearn: 15745.7034228\ttotal: 3.23ms\tremaining: 6.45ms\n",
      "1:\tlearn: 14478.8166357\ttotal: 5.02ms\tremaining: 2.51ms\n",
      "2:\tlearn: 13383.3863739\ttotal: 6.75ms\tremaining: 0us\n",
      "0:\tlearn: 11001.2562921\ttotal: 1.94ms\tremaining: 3.87ms\n",
      "1:\tlearn: 10182.4986201\ttotal: 3.65ms\tremaining: 1.82ms\n",
      "2:\tlearn: 9420.9843446\ttotal: 5.3ms\tremaining: 0us\n",
      "0:\tlearn: 14487.1947382\ttotal: 2.22ms\tremaining: 4.45ms\n",
      "1:\tlearn: 12779.2398962\ttotal: 3.96ms\tremaining: 1.98ms\n",
      "2:\tlearn: 11833.3262247\ttotal: 5.66ms\tremaining: 0us\n",
      "0:\tlearn: 14531.9556720\ttotal: 2.98ms\tremaining: 5.97ms\n",
      "1:\tlearn: 12764.3141652\ttotal: 4.68ms\tremaining: 2.34ms\n",
      "2:\tlearn: 11211.5994620\ttotal: 6.34ms\tremaining: 0us\n",
      "0:\tlearn: 13051.1554699\ttotal: 1.9ms\tremaining: 3.8ms\n",
      "1:\tlearn: 11981.9269382\ttotal: 3.56ms\tremaining: 1.78ms\n",
      "2:\tlearn: 11099.7665419\ttotal: 5.22ms\tremaining: 0us\n",
      "0:\tlearn: 15064.0925911\ttotal: 1.96ms\tremaining: 3.93ms\n",
      "1:\tlearn: 13254.0336860\ttotal: 3.7ms\tremaining: 1.85ms\n",
      "2:\tlearn: 11762.3480922\ttotal: 5.41ms\tremaining: 0us\n",
      "0:\tlearn: 10709.2603264\ttotal: 3.71ms\tremaining: 7.43ms\n",
      "1:\tlearn: 9647.8344822\ttotal: 5.43ms\tremaining: 2.71ms\n",
      "2:\tlearn: 8686.4939882\ttotal: 7.08ms\tremaining: 0us\n",
      "0:\tlearn: 13853.8521042\ttotal: 2.02ms\tremaining: 4.05ms\n",
      "1:\tlearn: 11686.7204466\ttotal: 3.8ms\tremaining: 1.9ms\n",
      "2:\tlearn: 10535.6093271\ttotal: 5.55ms\tremaining: 0us\n",
      "0:\tlearn: 13893.0848992\ttotal: 3.02ms\tremaining: 6.04ms\n",
      "1:\tlearn: 11653.0954517\ttotal: 4.8ms\tremaining: 2.4ms\n",
      "2:\tlearn: 10503.0862959\ttotal: 6.67ms\tremaining: 0us\n",
      "0:\tlearn: 12703.2548313\ttotal: 3.82ms\tremaining: 7.64ms\n",
      "1:\tlearn: 11319.5133904\ttotal: 5.54ms\tremaining: 2.77ms\n",
      "2:\tlearn: 10212.2944267\ttotal: 7.25ms\tremaining: 0us\n",
      "0:\tlearn: 14383.8440805\ttotal: 3.44ms\tremaining: 6.88ms\n",
      "1:\tlearn: 12315.5090652\ttotal: 5.27ms\tremaining: 2.64ms\n",
      "2:\tlearn: 10491.5696668\ttotal: 7.08ms\tremaining: 0us\n",
      "0:\tlearn: 11586.2930280\ttotal: 1.9ms\tremaining: 5.7ms\n",
      "1:\tlearn: 11298.1882629\ttotal: 3.61ms\tremaining: 3.61ms\n",
      "2:\tlearn: 10995.4142884\ttotal: 5.32ms\tremaining: 1.77ms\n",
      "3:\tlearn: 10720.9489478\ttotal: 7.03ms\tremaining: 0us\n",
      "0:\tlearn: 15757.6804051\ttotal: 1.94ms\tremaining: 5.82ms\n",
      "1:\tlearn: 15133.6250270\ttotal: 3.75ms\tremaining: 3.75ms\n",
      "2:\tlearn: 14758.8362531\ttotal: 5.77ms\tremaining: 1.92ms\n",
      "3:\tlearn: 14197.8135078\ttotal: 7.63ms\tremaining: 0us\n",
      "0:\tlearn: 15812.6206658\ttotal: 2.2ms\tremaining: 6.61ms\n",
      "1:\tlearn: 15165.3080588\ttotal: 4.03ms\tremaining: 4.03ms\n",
      "2:\tlearn: 14586.1427055\ttotal: 5.8ms\tremaining: 1.93ms\n",
      "3:\tlearn: 14021.4256215\ttotal: 7.5ms\tremaining: 0us\n",
      "0:\tlearn: 13747.9827805\ttotal: 2.12ms\tremaining: 6.37ms\n",
      "1:\tlearn: 13370.5850468\ttotal: 3.8ms\tremaining: 3.8ms\n",
      "2:\tlearn: 13040.2778285\ttotal: 5.49ms\tremaining: 1.83ms\n",
      "3:\tlearn: 12708.1381495\ttotal: 7.15ms\tremaining: 0us\n",
      "0:\tlearn: 16428.5068709\ttotal: 2.04ms\tremaining: 6.12ms\n",
      "1:\tlearn: 15765.0706687\ttotal: 3.71ms\tremaining: 3.71ms\n",
      "2:\tlearn: 15164.7942467\ttotal: 5.44ms\tremaining: 1.81ms\n",
      "3:\tlearn: 14595.7315937\ttotal: 7.11ms\tremaining: 0us\n",
      "0:\tlearn: 11293.6095624\ttotal: 3.4ms\tremaining: 10.2ms\n",
      "1:\tlearn: 10732.6060871\ttotal: 5.32ms\tremaining: 5.32ms\n",
      "2:\tlearn: 10158.1519784\ttotal: 7.13ms\tremaining: 2.38ms\n",
      "3:\tlearn: 9651.5546999\ttotal: 8.86ms\tremaining: 0us\n",
      "0:\tlearn: 15121.8573801\ttotal: 2.17ms\tremaining: 6.5ms\n",
      "1:\tlearn: 13928.3848866\ttotal: 3.95ms\tremaining: 3.95ms\n",
      "2:\tlearn: 13239.7342414\ttotal: 5.7ms\tremaining: 1.9ms\n",
      "3:\tlearn: 12229.5606393\ttotal: 7.38ms\tremaining: 0us\n",
      "0:\tlearn: 15171.8420703\ttotal: 3.13ms\tremaining: 9.4ms\n",
      "1:\tlearn: 13935.2158041\ttotal: 4.87ms\tremaining: 4.87ms\n",
      "2:\tlearn: 12880.5750757\ttotal: 6.52ms\tremaining: 2.17ms\n",
      "3:\tlearn: 12241.9209771\ttotal: 8.19ms\tremaining: 0us\n",
      "0:\tlearn: 13399.4070336\ttotal: 3.21ms\tremaining: 9.62ms\n",
      "1:\tlearn: 12665.6135451\ttotal: 4.91ms\tremaining: 4.91ms\n",
      "2:\tlearn: 12041.8523765\ttotal: 6.67ms\tremaining: 2.23ms\n",
      "3:\tlearn: 11432.7336422\ttotal: 8.33ms\tremaining: 0us\n",
      "0:\tlearn: 15745.7034228\ttotal: 3.76ms\tremaining: 11.3ms\n",
      "1:\tlearn: 14478.8166357\ttotal: 5.6ms\tremaining: 5.6ms\n",
      "2:\tlearn: 13383.3863739\ttotal: 7.26ms\tremaining: 2.42ms\n",
      "3:\tlearn: 12390.9150748\ttotal: 8.96ms\tremaining: 0us\n",
      "0:\tlearn: 11001.2562921\ttotal: 1.96ms\tremaining: 5.88ms\n",
      "1:\tlearn: 10182.4986201\ttotal: 3.66ms\tremaining: 3.66ms\n",
      "2:\tlearn: 9420.9843446\ttotal: 5.34ms\tremaining: 1.78ms\n",
      "3:\tlearn: 8716.9333000\ttotal: 7.02ms\tremaining: 0us\n",
      "0:\tlearn: 14487.1947382\ttotal: 2ms\tremaining: 6.01ms\n",
      "1:\tlearn: 12779.2398962\ttotal: 3.75ms\tremaining: 3.75ms\n",
      "2:\tlearn: 11833.3262247\ttotal: 5.51ms\tremaining: 1.84ms\n",
      "3:\tlearn: 10442.4957986\ttotal: 7.24ms\tremaining: 0us\n",
      "0:\tlearn: 14531.9556720\ttotal: 3.11ms\tremaining: 9.32ms\n",
      "1:\tlearn: 12764.3141652\ttotal: 4.93ms\tremaining: 4.93ms\n",
      "2:\tlearn: 11211.5994620\ttotal: 6.67ms\tremaining: 2.22ms\n",
      "3:\tlearn: 9976.5580347\ttotal: 8.41ms\tremaining: 0us\n",
      "0:\tlearn: 13051.1554699\ttotal: 3.53ms\tremaining: 10.6ms\n",
      "1:\tlearn: 11981.9269382\ttotal: 5.2ms\tremaining: 5.2ms\n",
      "2:\tlearn: 11099.7665419\ttotal: 6.89ms\tremaining: 2.3ms\n",
      "3:\tlearn: 10263.7828233\ttotal: 8.54ms\tremaining: 0us\n",
      "0:\tlearn: 15064.0925911\ttotal: 2.02ms\tremaining: 6.07ms\n",
      "1:\tlearn: 13254.0336860\ttotal: 3.8ms\tremaining: 3.8ms\n",
      "2:\tlearn: 11762.3480922\ttotal: 5.51ms\tremaining: 1.84ms\n",
      "3:\tlearn: 10474.5747991\ttotal: 7.21ms\tremaining: 0us\n",
      "0:\tlearn: 10709.2603264\ttotal: 2ms\tremaining: 5.99ms\n",
      "1:\tlearn: 9647.8344822\ttotal: 3.76ms\tremaining: 3.76ms\n",
      "2:\tlearn: 8686.4939882\ttotal: 5.42ms\tremaining: 1.8ms\n",
      "3:\tlearn: 7821.8309953\ttotal: 7.17ms\tremaining: 0us\n",
      "0:\tlearn: 13853.8521042\ttotal: 3.79ms\tremaining: 11.4ms\n",
      "1:\tlearn: 11686.7204466\ttotal: 5.51ms\tremaining: 5.51ms\n",
      "2:\tlearn: 10535.6093271\ttotal: 7.2ms\tremaining: 2.4ms\n",
      "3:\tlearn: 9505.0015717\ttotal: 8.85ms\tremaining: 0us\n",
      "0:\tlearn: 13893.0848992\ttotal: 2ms\tremaining: 6ms\n",
      "1:\tlearn: 11653.0954517\ttotal: 3.81ms\tremaining: 3.81ms\n",
      "2:\tlearn: 10503.0862959\ttotal: 5.52ms\tremaining: 1.84ms\n",
      "3:\tlearn: 8929.9856601\ttotal: 7.21ms\tremaining: 0us\n",
      "0:\tlearn: 12703.2548313\ttotal: 1.87ms\tremaining: 5.6ms\n",
      "1:\tlearn: 11319.5133904\ttotal: 3.52ms\tremaining: 3.52ms\n",
      "2:\tlearn: 10212.2944267\ttotal: 5.16ms\tremaining: 1.72ms\n",
      "3:\tlearn: 9194.9815095\ttotal: 6.84ms\tremaining: 0us\n",
      "0:\tlearn: 14383.8440805\ttotal: 2.05ms\tremaining: 6.15ms\n",
      "1:\tlearn: 12315.5090652\ttotal: 3.74ms\tremaining: 3.74ms\n",
      "2:\tlearn: 10491.5696668\ttotal: 5.4ms\tremaining: 1.8ms\n",
      "3:\tlearn: 9425.7200733\ttotal: 7.04ms\tremaining: 0us\n",
      "0:\tlearn: 11586.2930280\ttotal: 2.03ms\tremaining: 8.11ms\n",
      "1:\tlearn: 11298.1882629\ttotal: 3.8ms\tremaining: 5.7ms\n",
      "2:\tlearn: 10995.4142884\ttotal: 5.55ms\tremaining: 3.7ms\n",
      "3:\tlearn: 10720.9489478\ttotal: 7.25ms\tremaining: 1.81ms\n",
      "4:\tlearn: 10453.4140932\ttotal: 9.04ms\tremaining: 0us\n",
      "0:\tlearn: 15757.6804051\ttotal: 3.06ms\tremaining: 12.2ms\n",
      "1:\tlearn: 15133.6250270\ttotal: 4.72ms\tremaining: 7.09ms\n",
      "2:\tlearn: 14758.8362531\ttotal: 6.39ms\tremaining: 4.26ms\n",
      "3:\tlearn: 14197.8135078\ttotal: 8.03ms\tremaining: 2.01ms\n",
      "4:\tlearn: 13631.1797132\ttotal: 9.7ms\tremaining: 0us\n",
      "0:\tlearn: 15812.6206658\ttotal: 1.97ms\tremaining: 7.88ms\n",
      "1:\tlearn: 15165.3080588\ttotal: 3.67ms\tremaining: 5.5ms\n",
      "2:\tlearn: 14586.1427055\ttotal: 5.3ms\tremaining: 3.53ms\n",
      "3:\tlearn: 14021.4256215\ttotal: 6.94ms\tremaining: 1.74ms\n",
      "4:\tlearn: 13478.0196558\ttotal: 8.6ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 13747.9827805\ttotal: 3.13ms\tremaining: 12.5ms\n",
      "1:\tlearn: 13370.5850468\ttotal: 4.81ms\tremaining: 7.22ms\n",
      "2:\tlearn: 13040.2778285\ttotal: 6.51ms\tremaining: 4.34ms\n",
      "3:\tlearn: 12708.1381495\ttotal: 8.19ms\tremaining: 2.05ms\n",
      "4:\tlearn: 12398.9763344\ttotal: 9.84ms\tremaining: 0us\n",
      "0:\tlearn: 16428.5068709\ttotal: 3.33ms\tremaining: 13.3ms\n",
      "1:\tlearn: 15765.0706687\ttotal: 5ms\tremaining: 7.5ms\n",
      "2:\tlearn: 15164.7942467\ttotal: 6.77ms\tremaining: 4.51ms\n",
      "3:\tlearn: 14595.7315937\ttotal: 8.45ms\tremaining: 2.11ms\n",
      "4:\tlearn: 14218.2200416\ttotal: 10.1ms\tremaining: 0us\n",
      "0:\tlearn: 11293.6095624\ttotal: 2.02ms\tremaining: 8.06ms\n",
      "1:\tlearn: 10732.6060871\ttotal: 3.76ms\tremaining: 5.63ms\n",
      "2:\tlearn: 10158.1519784\ttotal: 5.5ms\tremaining: 3.67ms\n",
      "3:\tlearn: 9651.5546999\ttotal: 7.41ms\tremaining: 1.85ms\n",
      "4:\tlearn: 9170.4441627\ttotal: 9.13ms\tremaining: 0us\n",
      "0:\tlearn: 15121.8573801\ttotal: 3.07ms\tremaining: 12.3ms\n",
      "1:\tlearn: 13928.3848866\ttotal: 4.81ms\tremaining: 7.22ms\n",
      "2:\tlearn: 13239.7342414\ttotal: 6.67ms\tremaining: 4.45ms\n",
      "3:\tlearn: 12229.5606393\ttotal: 8.44ms\tremaining: 2.11ms\n",
      "4:\tlearn: 11262.2894958\ttotal: 10.2ms\tremaining: 0us\n",
      "0:\tlearn: 15171.8420703\ttotal: 4.03ms\tremaining: 16.1ms\n",
      "1:\tlearn: 13935.2158041\ttotal: 5.79ms\tremaining: 8.69ms\n",
      "2:\tlearn: 12880.5750757\ttotal: 7.44ms\tremaining: 4.96ms\n",
      "3:\tlearn: 12241.9209771\ttotal: 9.11ms\tremaining: 2.28ms\n",
      "4:\tlearn: 11306.5333236\ttotal: 10.8ms\tremaining: 0us\n",
      "0:\tlearn: 13399.4070336\ttotal: 2ms\tremaining: 7.99ms\n",
      "1:\tlearn: 12665.6135451\ttotal: 3.68ms\tremaining: 5.53ms\n",
      "2:\tlearn: 12041.8523765\ttotal: 5.4ms\tremaining: 3.6ms\n",
      "3:\tlearn: 11432.7336422\ttotal: 7.11ms\tremaining: 1.78ms\n",
      "4:\tlearn: 10880.8255041\ttotal: 8.79ms\tremaining: 0us\n",
      "0:\tlearn: 15745.7034228\ttotal: 1.99ms\tremaining: 7.96ms\n",
      "1:\tlearn: 14478.8166357\ttotal: 3.69ms\tremaining: 5.54ms\n",
      "2:\tlearn: 13383.3863739\ttotal: 5.36ms\tremaining: 3.57ms\n",
      "3:\tlearn: 12390.9150748\ttotal: 7.05ms\tremaining: 1.76ms\n",
      "4:\tlearn: 11757.6006329\ttotal: 8.71ms\tremaining: 0us\n",
      "0:\tlearn: 11001.2562921\ttotal: 3.29ms\tremaining: 13.2ms\n",
      "1:\tlearn: 10182.4986201\ttotal: 4.99ms\tremaining: 7.48ms\n",
      "2:\tlearn: 9420.9843446\ttotal: 6.68ms\tremaining: 4.45ms\n",
      "3:\tlearn: 8716.9333000\ttotal: 8.31ms\tremaining: 2.08ms\n",
      "4:\tlearn: 8065.8892076\ttotal: 9.97ms\tremaining: 0us\n",
      "0:\tlearn: 14487.1947382\ttotal: 3.49ms\tremaining: 14ms\n",
      "1:\tlearn: 12779.2398962\ttotal: 5.17ms\tremaining: 7.75ms\n",
      "2:\tlearn: 11833.3262247\ttotal: 6.86ms\tremaining: 4.57ms\n",
      "3:\tlearn: 10442.4957986\ttotal: 8.49ms\tremaining: 2.12ms\n",
      "4:\tlearn: 9226.8794168\ttotal: 10.2ms\tremaining: 0us\n",
      "0:\tlearn: 14531.9556720\ttotal: 1.97ms\tremaining: 7.87ms\n",
      "1:\tlearn: 12764.3141652\ttotal: 3.67ms\tremaining: 5.5ms\n",
      "2:\tlearn: 11211.5994620\ttotal: 5.3ms\tremaining: 3.54ms\n",
      "3:\tlearn: 9976.5580347\ttotal: 6.95ms\tremaining: 1.74ms\n",
      "4:\tlearn: 8863.9261021\ttotal: 8.62ms\tremaining: 0us\n",
      "0:\tlearn: 13051.1554699\ttotal: 2.01ms\tremaining: 8.03ms\n",
      "1:\tlearn: 11981.9269382\ttotal: 3.77ms\tremaining: 5.65ms\n",
      "2:\tlearn: 11099.7665419\ttotal: 5.49ms\tremaining: 3.66ms\n",
      "3:\tlearn: 10263.7828233\ttotal: 7.17ms\tremaining: 1.79ms\n",
      "4:\tlearn: 9526.7759250\ttotal: 8.83ms\tremaining: 0us\n",
      "0:\tlearn: 15064.0925911\ttotal: 3.33ms\tremaining: 13.3ms\n",
      "1:\tlearn: 13254.0336860\ttotal: 5.02ms\tremaining: 7.53ms\n",
      "2:\tlearn: 11762.3480922\ttotal: 6.7ms\tremaining: 4.46ms\n",
      "3:\tlearn: 10474.5747991\ttotal: 8.38ms\tremaining: 2.09ms\n",
      "4:\tlearn: 9694.3846823\ttotal: 10.2ms\tremaining: 0us\n",
      "0:\tlearn: 10709.2603264\ttotal: 2.98ms\tremaining: 11.9ms\n",
      "1:\tlearn: 9647.8344822\ttotal: 4.68ms\tremaining: 7.03ms\n",
      "2:\tlearn: 8686.4939882\ttotal: 6.34ms\tremaining: 4.23ms\n",
      "3:\tlearn: 7821.8309953\ttotal: 8ms\tremaining: 2ms\n",
      "4:\tlearn: 7043.8769023\ttotal: 9.66ms\tremaining: 0us\n",
      "0:\tlearn: 13853.8521042\ttotal: 3.14ms\tremaining: 12.6ms\n",
      "1:\tlearn: 11686.7204466\ttotal: 4.92ms\tremaining: 7.38ms\n",
      "2:\tlearn: 10535.6093271\ttotal: 6.86ms\tremaining: 4.57ms\n",
      "3:\tlearn: 9505.0015717\ttotal: 8.56ms\tremaining: 2.14ms\n",
      "4:\tlearn: 8024.5172523\ttotal: 10.3ms\tremaining: 0us\n",
      "0:\tlearn: 13893.0848992\ttotal: 1.91ms\tremaining: 7.62ms\n",
      "1:\tlearn: 11653.0954517\ttotal: 3.61ms\tremaining: 5.41ms\n",
      "2:\tlearn: 10503.0862959\ttotal: 5.33ms\tremaining: 3.55ms\n",
      "3:\tlearn: 8929.9856601\ttotal: 7.07ms\tremaining: 1.77ms\n",
      "4:\tlearn: 8070.9327392\ttotal: 8.75ms\tremaining: 0us\n",
      "0:\tlearn: 12703.2548313\ttotal: 3.4ms\tremaining: 13.6ms\n",
      "1:\tlearn: 11319.5133904\ttotal: 4.99ms\tremaining: 7.48ms\n",
      "2:\tlearn: 10212.2944267\ttotal: 6.6ms\tremaining: 4.4ms\n",
      "3:\tlearn: 9194.9815095\ttotal: 8.19ms\tremaining: 2.05ms\n",
      "4:\tlearn: 8322.9637081\ttotal: 9.76ms\tremaining: 0us\n",
      "0:\tlearn: 14383.8440805\ttotal: 2.14ms\tremaining: 8.55ms\n",
      "1:\tlearn: 12315.5090652\ttotal: 4.02ms\tremaining: 6.03ms\n",
      "2:\tlearn: 10491.5696668\ttotal: 5.75ms\tremaining: 3.84ms\n",
      "3:\tlearn: 9425.7200733\ttotal: 7.48ms\tremaining: 1.87ms\n",
      "4:\tlearn: 8515.8507753\ttotal: 9.27ms\tremaining: 0us\n",
      "0:\tlearn: 12702.4811552\ttotal: 1.46ms\tremaining: 5.86ms\n",
      "1:\tlearn: 10632.2562062\ttotal: 2.79ms\tremaining: 4.18ms\n",
      "2:\tlearn: 9098.0869745\ttotal: 4ms\tremaining: 2.66ms\n",
      "3:\tlearn: 7889.5556044\ttotal: 5.24ms\tremaining: 1.31ms\n",
      "4:\tlearn: 6586.0250663\ttotal: 6.47ms\tremaining: 0us\n",
      "Best GridSearchCV Parameter :  {'depth': 3, 'iterations': 5, 'learning_rate': 0.4}\n",
      "Best GridSearchCV Accuracy :  0.406\n",
      "Test Set Accuracy :  0.019\n"
     ]
    }
   ],
   "source": [
    "model = model_CB\n",
    "parameters = {'depth':[2,3,4,5],\n",
    "              'learning_rate':[0.1,0.2,0.3,0.4],\n",
    "              'iterations':[1,2,3,4,5]}\n",
    "\n",
    "grid_Tree = GridSearchCV(model,param_grid=parameters,cv=5,\n",
    "                         refit=True)\n",
    "\n",
    "grid_Tree.fit(X_train,Y_train.values.ravel())\n",
    "estimator = grid_Tree.best_estimator_\n",
    "pred = estimator.predict(X_test)\n",
    "print(\"Best GridSearchCV Parameter : \",grid_Tree.best_params_)\n",
    "print(\"Best GridSearchCV Accuracy : \", (grid_Tree.best_score_).round(3))\n",
    "print('Test Set Accuracy : ', (r2_score(Y_test,pred).round(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance\n",
      "Backers  :  15.452\n",
      "Pledge  :  12.018\n",
      "Goal  :  71.022\n",
      "Fiends  :  0.444\n",
      "Comments Creator  :  1.065\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature Importance\")\n",
    "importance_list = []\n",
    "value_list = []\n",
    "for name,value in zip(X.columns,estimator.feature_importances_):\n",
    "    if value >=0.05:\n",
    "        print(name ,\" : \", value.round(3))\n",
    "        importance_list.append(name)\n",
    "        value_list.append(value)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x258b3dcb388>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[15,5])\n",
    "sns.barplot(y=value_list, x=importance_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Backers</th>\n",
       "      <th>Pledge</th>\n",
       "      <th>VideoCount</th>\n",
       "      <th>ImageCount</th>\n",
       "      <th>Goal</th>\n",
       "      <th>Period</th>\n",
       "      <th>SNS</th>\n",
       "      <th>Fiends</th>\n",
       "      <th>Created</th>\n",
       "      <th>Created Success</th>\n",
       "      <th>Backed</th>\n",
       "      <th>Backed Success</th>\n",
       "      <th>Total Rewards</th>\n",
       "      <th>Comments Creator</th>\n",
       "      <th>Comments User</th>\n",
       "      <th>Total Updates</th>\n",
       "      <th>Updates Likes</th>\n",
       "      <th>Updates Comments</th>\n",
       "      <th>Tag_3D Printing</th>\n",
       "      <th>Tag_Academic</th>\n",
       "      <th>Tag_Accessories</th>\n",
       "      <th>Tag_Action</th>\n",
       "      <th>Tag_Animals</th>\n",
       "      <th>Tag_Animation</th>\n",
       "      <th>Tag_Anthologies</th>\n",
       "      <th>Tag_Apparel</th>\n",
       "      <th>Tag_Apps</th>\n",
       "      <th>Tag_Architecture</th>\n",
       "      <th>Tag_Art</th>\n",
       "      <th>Tag_Art Books</th>\n",
       "      <th>Tag_Audio</th>\n",
       "      <th>Tag_Bacon</th>\n",
       "      <th>Tag_Blues</th>\n",
       "      <th>Tag_Calendars</th>\n",
       "      <th>Tag_Camera Equipment</th>\n",
       "      <th>Tag_Candles</th>\n",
       "      <th>Tag_Ceramics</th>\n",
       "      <th>Tag_Children's Books</th>\n",
       "      <th>Tag_Childrenswear</th>\n",
       "      <th>Tag_Chiptune</th>\n",
       "      <th>Tag_Civic Design</th>\n",
       "      <th>Tag_Classical Music</th>\n",
       "      <th>Tag_Comedy</th>\n",
       "      <th>Tag_Comic Books</th>\n",
       "      <th>Tag_Comics</th>\n",
       "      <th>Tag_Community Gardens</th>\n",
       "      <th>Tag_Conceptual Art</th>\n",
       "      <th>Tag_Cookbooks</th>\n",
       "      <th>Tag_Country &amp; Folk</th>\n",
       "      <th>Tag_Couture</th>\n",
       "      <th>...</th>\n",
       "      <th>Tag_Pop</th>\n",
       "      <th>Tag_Pottery</th>\n",
       "      <th>Tag_Print</th>\n",
       "      <th>Tag_Printing</th>\n",
       "      <th>Tag_Product Design</th>\n",
       "      <th>Tag_Public Art</th>\n",
       "      <th>Tag_Publishing</th>\n",
       "      <th>Tag_Punk</th>\n",
       "      <th>Tag_Puzzles</th>\n",
       "      <th>Tag_Quilts</th>\n",
       "      <th>Tag_R&amp;B;</th>\n",
       "      <th>Tag_Radio &amp; Podcasts</th>\n",
       "      <th>Tag_Ready-to-wear</th>\n",
       "      <th>Tag_Residencies</th>\n",
       "      <th>Tag_Restaurants</th>\n",
       "      <th>Tag_Robots</th>\n",
       "      <th>Tag_Rock</th>\n",
       "      <th>Tag_Romance</th>\n",
       "      <th>Tag_Science Fiction</th>\n",
       "      <th>Tag_Sculpture</th>\n",
       "      <th>Tag_Shorts</th>\n",
       "      <th>Tag_Small Batch</th>\n",
       "      <th>Tag_Software</th>\n",
       "      <th>Tag_Sound</th>\n",
       "      <th>Tag_Space Exploration</th>\n",
       "      <th>Tag_Spaces</th>\n",
       "      <th>Tag_Stationery</th>\n",
       "      <th>Tag_Tabletop Games</th>\n",
       "      <th>Tag_Taxidermy</th>\n",
       "      <th>Tag_Technology</th>\n",
       "      <th>Tag_Television</th>\n",
       "      <th>Tag_Textiles</th>\n",
       "      <th>Tag_Theater</th>\n",
       "      <th>Tag_Thrillers</th>\n",
       "      <th>Tag_Translations</th>\n",
       "      <th>Tag_Typography</th>\n",
       "      <th>Tag_Vegan</th>\n",
       "      <th>Tag_Video</th>\n",
       "      <th>Tag_Video Art</th>\n",
       "      <th>Tag_Video Games</th>\n",
       "      <th>Tag_Wearables</th>\n",
       "      <th>Tag_Weaving</th>\n",
       "      <th>Tag_Web</th>\n",
       "      <th>Tag_Webcomics</th>\n",
       "      <th>Tag_Webseries</th>\n",
       "      <th>Tag_Woodworking</th>\n",
       "      <th>Tag_Workshops</th>\n",
       "      <th>Tag_World Music</th>\n",
       "      <th>Tag_Young Adult</th>\n",
       "      <th>Tag_Zines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4800.00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1140.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2873.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5361.53</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>583.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>34513.70</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4675.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1510.0</td>\n",
       "      <td>52471.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20483</td>\n",
       "      <td>9.0</td>\n",
       "      <td>200.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20484</td>\n",
       "      <td>9.0</td>\n",
       "      <td>160.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20488</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1992.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20492</td>\n",
       "      <td>12.0</td>\n",
       "      <td>636.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>99.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15780 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Backers    Pledge  VideoCount  ImageCount      Goal  Period  SNS  \\\n",
       "0          0.0      0.00         0.0         0.0   4800.00    19.0  1.0   \n",
       "1          4.0   1140.00         0.0         0.0  10000.00    30.0  1.0   \n",
       "2          0.0      0.00         0.0         0.0   5361.53    30.0  1.0   \n",
       "3          1.0     34.51         0.0         3.0  34513.70    30.0  1.0   \n",
       "4       1510.0  52471.00         0.0        39.0   5000.00    59.0  0.0   \n",
       "...        ...       ...         ...         ...       ...     ...  ...   \n",
       "20483      9.0    200.00         0.0         0.0    200.00    10.0  0.0   \n",
       "20484      9.0    160.00         0.0         0.0    120.00     8.0  0.0   \n",
       "20488     52.0   1992.00         0.0        10.0   1000.00     7.0  0.0   \n",
       "20492     12.0    636.00         0.0        14.0     99.00     8.0  0.0   \n",
       "20500      0.0      0.00         0.0         0.0    150.00     4.0  0.0   \n",
       "\n",
       "       Fiends  Created  Created Success  Backed  Backed Success  \\\n",
       "0        26.0      1.0              0.0     0.0             0.0   \n",
       "1      2873.0     11.0              0.0     0.0             0.0   \n",
       "2       583.0      1.0              0.0     0.0             0.0   \n",
       "3      4675.0      1.0              0.0     0.0             0.0   \n",
       "4         0.0      1.0              0.0     0.0             4.0   \n",
       "...       ...      ...              ...     ...             ...   \n",
       "20483     0.0      7.0              0.0     0.0             0.0   \n",
       "20484     0.0      1.0              0.0     1.0             0.0   \n",
       "20488     0.0      6.0              3.0     5.0             9.0   \n",
       "20492     0.0      7.0              4.0     0.0             0.0   \n",
       "20500     0.0      1.0              0.0     0.0             0.0   \n",
       "\n",
       "       Total Rewards  Comments Creator  Comments User  Total Updates  \\\n",
       "0                1.0               0.0            0.0            0.0   \n",
       "1                9.0               0.0            0.0            0.0   \n",
       "2                2.0               0.0            0.0            0.0   \n",
       "3                4.0               0.0            0.0            7.0   \n",
       "4                8.0              18.0           31.0           13.0   \n",
       "...              ...               ...            ...            ...   \n",
       "20483            4.0               0.0            0.0            0.0   \n",
       "20484            5.0               0.0            0.0            0.0   \n",
       "20488            6.0               0.0            5.0            1.0   \n",
       "20492            6.0               0.0            0.0            0.0   \n",
       "20500            3.0               0.0            0.0            0.0   \n",
       "\n",
       "       Updates Likes  Updates Comments  Tag_3D Printing  Tag_Academic  \\\n",
       "0                0.0               0.0                0             0   \n",
       "1                0.0               0.0                0             0   \n",
       "2                0.0               0.0                1             0   \n",
       "3                2.0               0.0                0             0   \n",
       "4               88.0              13.0                0             0   \n",
       "...              ...               ...              ...           ...   \n",
       "20483            0.0               0.0                0             0   \n",
       "20484            0.0               0.0                0             0   \n",
       "20488            0.0               1.0                0             0   \n",
       "20492            0.0               0.0                0             0   \n",
       "20500            0.0               0.0                0             0   \n",
       "\n",
       "       Tag_Accessories  Tag_Action  Tag_Animals  Tag_Animation  \\\n",
       "0                    0           0            0              0   \n",
       "1                    0           0            0              0   \n",
       "2                    0           0            0              0   \n",
       "3                    0           0            0              0   \n",
       "4                    0           0            0              0   \n",
       "...                ...         ...          ...            ...   \n",
       "20483                0           0            0              0   \n",
       "20484                0           0            0              0   \n",
       "20488                0           0            0              0   \n",
       "20492                0           0            0              0   \n",
       "20500                0           0            0              0   \n",
       "\n",
       "       Tag_Anthologies  Tag_Apparel  Tag_Apps  Tag_Architecture  Tag_Art  \\\n",
       "0                    0            0         0                 0        0   \n",
       "1                    0            0         0                 0        0   \n",
       "2                    0            0         0                 0        0   \n",
       "3                    0            0         0                 0        0   \n",
       "4                    0            0         0                 0        0   \n",
       "...                ...          ...       ...               ...      ...   \n",
       "20483                0            0         0                 0        0   \n",
       "20484                0            0         0                 0        0   \n",
       "20488                0            0         0                 0        0   \n",
       "20492                0            0         0                 0        0   \n",
       "20500                0            0         0                 0        0   \n",
       "\n",
       "       Tag_Art Books  Tag_Audio  Tag_Bacon  Tag_Blues  Tag_Calendars  \\\n",
       "0                  0          0          0          0              0   \n",
       "1                  0          0          0          0              0   \n",
       "2                  0          0          0          0              0   \n",
       "3                  0          0          0          0              0   \n",
       "4                  0          0          0          0              0   \n",
       "...              ...        ...        ...        ...            ...   \n",
       "20483              0          0          0          0              0   \n",
       "20484              0          0          0          0              0   \n",
       "20488              0          0          0          0              0   \n",
       "20492              0          0          0          0              0   \n",
       "20500              0          0          0          0              0   \n",
       "\n",
       "       Tag_Camera Equipment  Tag_Candles  Tag_Ceramics  Tag_Children's Books  \\\n",
       "0                         0            0             0                     0   \n",
       "1                         0            0             0                     0   \n",
       "2                         0            0             0                     0   \n",
       "3                         0            0             0                     0   \n",
       "4                         0            0             0                     0   \n",
       "...                     ...          ...           ...                   ...   \n",
       "20483                     0            0             0                     0   \n",
       "20484                     0            0             0                     0   \n",
       "20488                     0            0             0                     0   \n",
       "20492                     0            0             0                     0   \n",
       "20500                     0            0             0                     0   \n",
       "\n",
       "       Tag_Childrenswear  Tag_Chiptune  Tag_Civic Design  Tag_Classical Music  \\\n",
       "0                      0             0                 0                    0   \n",
       "1                      0             0                 0                    0   \n",
       "2                      0             0                 0                    0   \n",
       "3                      0             0                 0                    0   \n",
       "4                      0             0                 0                    0   \n",
       "...                  ...           ...               ...                  ...   \n",
       "20483                  0             0                 0                    0   \n",
       "20484                  0             0                 0                    0   \n",
       "20488                  0             0                 0                    0   \n",
       "20492                  0             0                 0                    0   \n",
       "20500                  0             0                 0                    0   \n",
       "\n",
       "       Tag_Comedy  Tag_Comic Books  Tag_Comics  Tag_Community Gardens  \\\n",
       "0               0                0           0                      0   \n",
       "1               0                0           0                      0   \n",
       "2               0                0           0                      0   \n",
       "3               0                0           0                      0   \n",
       "4               0                0           0                      0   \n",
       "...           ...              ...         ...                    ...   \n",
       "20483           0                0           0                      0   \n",
       "20484           0                0           0                      0   \n",
       "20488           0                0           0                      0   \n",
       "20492           0                0           0                      0   \n",
       "20500           0                0           0                      0   \n",
       "\n",
       "       Tag_Conceptual Art  Tag_Cookbooks  Tag_Country & Folk  Tag_Couture  \\\n",
       "0                       0              0                   0            0   \n",
       "1                       0              0                   0            0   \n",
       "2                       0              0                   0            0   \n",
       "3                       0              0                   0            0   \n",
       "4                       0              0                   0            0   \n",
       "...                   ...            ...                 ...          ...   \n",
       "20483                   0              0                   0            0   \n",
       "20484                   0              0                   0            0   \n",
       "20488                   0              0                   0            0   \n",
       "20492                   0              0                   0            0   \n",
       "20500                   0              0                   0            0   \n",
       "\n",
       "       ...  Tag_Pop  Tag_Pottery  Tag_Print  Tag_Printing  Tag_Product Design  \\\n",
       "0      ...        0            0          0             0                   0   \n",
       "1      ...        0            0          0             0                   0   \n",
       "2      ...        0            0          0             0                   0   \n",
       "3      ...        0            0          0             0                   0   \n",
       "4      ...        0            0          0             0                   1   \n",
       "...    ...      ...          ...        ...           ...                 ...   \n",
       "20483  ...        0            0          0             0                   0   \n",
       "20484  ...        0            0          0             0                   0   \n",
       "20488  ...        0            0          0             0                   0   \n",
       "20492  ...        0            0          0             0                   0   \n",
       "20500  ...        0            0          0             0                   0   \n",
       "\n",
       "       Tag_Public Art  Tag_Publishing  Tag_Punk  Tag_Puzzles  Tag_Quilts  \\\n",
       "0                   0               0         0            0           0   \n",
       "1                   0               1         0            0           0   \n",
       "2                   0               0         0            0           0   \n",
       "3                   0               0         0            0           0   \n",
       "4                   0               0         0            0           0   \n",
       "...               ...             ...       ...          ...         ...   \n",
       "20483               0               0         0            0           0   \n",
       "20484               0               0         0            0           0   \n",
       "20488               0               0         0            0           0   \n",
       "20492               0               0         0            0           0   \n",
       "20500               0               0         0            0           0   \n",
       "\n",
       "       Tag_R&B;  Tag_Radio & Podcasts  Tag_Ready-to-wear  Tag_Residencies  \\\n",
       "0             0                     0                  0                0   \n",
       "1             0                     0                  0                0   \n",
       "2             0                     0                  0                0   \n",
       "3             0                     0                  0                0   \n",
       "4             0                     0                  0                0   \n",
       "...         ...                   ...                ...              ...   \n",
       "20483         0                     0                  0                0   \n",
       "20484         0                     0                  0                0   \n",
       "20488         0                     0                  0                0   \n",
       "20492         0                     0                  0                0   \n",
       "20500         0                     0                  0                0   \n",
       "\n",
       "       Tag_Restaurants  Tag_Robots  Tag_Rock  Tag_Romance  \\\n",
       "0                    0           0         0            0   \n",
       "1                    0           0         0            0   \n",
       "2                    0           0         0            0   \n",
       "3                    0           0         0            0   \n",
       "4                    0           0         0            0   \n",
       "...                ...         ...       ...          ...   \n",
       "20483                0           0         0            0   \n",
       "20484                0           0         0            0   \n",
       "20488                0           0         0            0   \n",
       "20492                0           0         0            0   \n",
       "20500                0           0         0            0   \n",
       "\n",
       "       Tag_Science Fiction  Tag_Sculpture  Tag_Shorts  Tag_Small Batch  \\\n",
       "0                        0              0           0                0   \n",
       "1                        0              0           0                0   \n",
       "2                        0              0           0                0   \n",
       "3                        0              0           0                0   \n",
       "4                        0              0           0                0   \n",
       "...                    ...            ...         ...              ...   \n",
       "20483                    0              0           0                0   \n",
       "20484                    0              0           1                0   \n",
       "20488                    0              0           0                0   \n",
       "20492                    0              0           0                0   \n",
       "20500                    0              0           0                0   \n",
       "\n",
       "       Tag_Software  Tag_Sound  Tag_Space Exploration  Tag_Spaces  \\\n",
       "0                 0          0                      0           0   \n",
       "1                 0          0                      0           0   \n",
       "2                 0          0                      0           0   \n",
       "3                 0          0                      0           0   \n",
       "4                 0          0                      0           0   \n",
       "...             ...        ...                    ...         ...   \n",
       "20483             0          0                      0           0   \n",
       "20484             0          0                      0           0   \n",
       "20488             0          0                      0           0   \n",
       "20492             0          0                      0           0   \n",
       "20500             0          0                      0           0   \n",
       "\n",
       "       Tag_Stationery  Tag_Tabletop Games  Tag_Taxidermy  Tag_Technology  \\\n",
       "0                   0                   0              0               0   \n",
       "1                   0                   0              0               0   \n",
       "2                   0                   0              0               0   \n",
       "3                   0                   0              0               0   \n",
       "4                   0                   0              0               0   \n",
       "...               ...                 ...            ...             ...   \n",
       "20483               0                   0              0               0   \n",
       "20484               0                   0              0               0   \n",
       "20488               0                   0              0               0   \n",
       "20492               0                   0              0               0   \n",
       "20500               0                   0              0               0   \n",
       "\n",
       "       Tag_Television  Tag_Textiles  Tag_Theater  Tag_Thrillers  \\\n",
       "0                   0             0            0              0   \n",
       "1                   0             0            0              0   \n",
       "2                   0             0            0              0   \n",
       "3                   0             0            0              0   \n",
       "4                   0             0            0              0   \n",
       "...               ...           ...          ...            ...   \n",
       "20483               0             0            0              0   \n",
       "20484               0             0            0              0   \n",
       "20488               0             0            0              0   \n",
       "20492               0             0            0              0   \n",
       "20500               0             0            0              0   \n",
       "\n",
       "       Tag_Translations  Tag_Typography  Tag_Vegan  Tag_Video  Tag_Video Art  \\\n",
       "0                     0               0          0          0              0   \n",
       "1                     0               0          0          0              0   \n",
       "2                     0               0          0          0              0   \n",
       "3                     0               0          0          0              0   \n",
       "4                     0               0          0          0              0   \n",
       "...                 ...             ...        ...        ...            ...   \n",
       "20483                 0               0          0          0              0   \n",
       "20484                 0               0          0          0              0   \n",
       "20488                 0               0          0          0              0   \n",
       "20492                 0               0          0          0              0   \n",
       "20500                 0               0          0          0              0   \n",
       "\n",
       "       Tag_Video Games  Tag_Wearables  Tag_Weaving  Tag_Web  Tag_Webcomics  \\\n",
       "0                    0              0            0        0              0   \n",
       "1                    0              0            0        0              0   \n",
       "2                    0              0            0        0              0   \n",
       "3                    0              0            0        0              0   \n",
       "4                    0              0            0        0              0   \n",
       "...                ...            ...          ...      ...            ...   \n",
       "20483                0              0            0        0              0   \n",
       "20484                0              0            0        0              0   \n",
       "20488                0              0            0        0              0   \n",
       "20492                0              0            0        0              0   \n",
       "20500                0              0            0        0              0   \n",
       "\n",
       "       Tag_Webseries  Tag_Woodworking  Tag_Workshops  Tag_World Music  \\\n",
       "0                  0                0              0                0   \n",
       "1                  0                0              0                0   \n",
       "2                  0                0              0                0   \n",
       "3                  0                0              0                0   \n",
       "4                  0                0              0                0   \n",
       "...              ...              ...            ...              ...   \n",
       "20483              0                0              0                0   \n",
       "20484              0                0              0                0   \n",
       "20488              0                0              0                0   \n",
       "20492              0                0              0                0   \n",
       "20500              0                0              0                0   \n",
       "\n",
       "       Tag_Young Adult  Tag_Zines  \n",
       "0                    0          0  \n",
       "1                    0          0  \n",
       "2                    0          0  \n",
       "3                    0          0  \n",
       "4                    0          0  \n",
       "...                ...        ...  \n",
       "20483                0          0  \n",
       "20484                0          0  \n",
       "20488                0          0  \n",
       "20492                0          0  \n",
       "20500                0          0  \n",
       "\n",
       "[15780 rows x 176 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X.values\n",
    "y = Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0.,    0.,    0., ...,    0.,    0.,    0.],\n",
       "       [   4., 1140.,    0., ...,    0.,    0.,    0.],\n",
       "       [   0.,    0.,    0., ...,    0.,    0.,    0.],\n",
       "       ...,\n",
       "       [  52., 1992.,    0., ...,    0.,    0.,    0.],\n",
       "       [  12.,  636.,    0., ...,    0.,    0.,    0.],\n",
       "       [   0.,    0.,    0., ...,    0.,    0.,    0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12624 samples, validate on 3156 samples\n",
      "Epoch 1/50\n",
      "12624/12624 [==============================] - 3s 199us/step - loss: 246629237.1063 - mse: 246629104.0000 - val_loss: 3235120.0475 - val_mse: 3235120.2500\n",
      "Epoch 2/50\n",
      "12624/12624 [==============================] - 2s 141us/step - loss: 251881152.7743 - mse: 251881120.0000 - val_loss: 1504214.0511 - val_mse: 1504214.0000\n",
      "Epoch 3/50\n",
      "12624/12624 [==============================] - 2s 191us/step - loss: 237785297.3939 - mse: 237785360.0000 - val_loss: 1782398.8786 - val_mse: 1782399.8750\n",
      "Epoch 4/50\n",
      "12624/12624 [==============================] - 2s 152us/step - loss: 235362624.7287 - mse: 235362640.0000 - val_loss: 1481711.6974 - val_mse: 1481711.7500\n",
      "Epoch 5/50\n",
      "12624/12624 [==============================] - 2s 169us/step - loss: 256919141.5687 - mse: 256919088.0000 - val_loss: 3203098.6239 - val_mse: 3203098.0000\n",
      "Epoch 6/50\n",
      "12624/12624 [==============================] - 2s 146us/step - loss: 235129928.7875 - mse: 235129872.0000 - val_loss: 1478541.3141 - val_mse: 1478541.1250\n",
      "Epoch 7/50\n",
      "12624/12624 [==============================] - 2s 186us/step - loss: 235589126.3026 - mse: 235589136.0000 - val_loss: 1459058.2208 - val_mse: 1459058.2500\n",
      "Epoch 8/50\n",
      "12624/12624 [==============================] - 2s 190us/step - loss: 234702531.1113 - mse: 234702496.0000 - val_loss: 1862032.2641 - val_mse: 1862032.0000\n",
      "Epoch 9/50\n",
      "12624/12624 [==============================] - 3s 223us/step - loss: 235977145.7945 - mse: 235977088.0000 - val_loss: 1451227.8907 - val_mse: 1451228.0000\n",
      "Epoch 10/50\n",
      "12624/12624 [==============================] - 2s 187us/step - loss: 234352371.0757 - mse: 234352288.0000 - val_loss: 1866943.8033 - val_mse: 1866943.8750\n",
      "Epoch 11/50\n",
      "12624/12624 [==============================] - 2s 183us/step - loss: 234561851.8204 - mse: 234561840.0000 - val_loss: 1446171.7124 - val_mse: 1446172.2500: 276934386.2453 - mse: 276934432.00 - ETA: 0s - loss: 264523013.8555 - mse: 2645230\n",
      "Epoch 12/50\n",
      "12624/12624 [==============================] - 3s 266us/step - loss: 234920000.2164 - mse: 234920080.0000 - val_loss: 1710355.9916 - val_mse: 1710356.2500\n",
      "Epoch 13/50\n",
      "12624/12624 [==============================] - 3s 205us/step - loss: 236015615.6295 - mse: 236015520.0000 - val_loss: 1442620.4849 - val_mse: 1442620.3750\n",
      "Epoch 14/50\n",
      "12624/12624 [==============================] - 3s 249us/step - loss: 235398572.3068 - mse: 235398576.0000 - val_loss: 1408729.3946 - val_mse: 1408729.1250\n",
      "Epoch 15/50\n",
      "12624/12624 [==============================] - 3s 218us/step - loss: 235051940.9773 - mse: 235051984.0000 - val_loss: 2980786.7701 - val_mse: 2980787.0000\n",
      "Epoch 16/50\n",
      "12624/12624 [==============================] - 2s 136us/step - loss: 238861510.6121 - mse: 238861424.0000 - val_loss: 1390927.3705 - val_mse: 1390927.3750\n",
      "Epoch 17/50\n",
      "12624/12624 [==============================] - 2s 166us/step - loss: 235399533.7559 - mse: 235399504.0000 - val_loss: 1375994.9774 - val_mse: 1375995.1250\n",
      "Epoch 18/50\n",
      "12624/12624 [==============================] - 6s 445us/step - loss: 240244198.3551 - mse: 240244080.0000 - val_loss: 1378996.7128 - val_mse: 1378996.8750\n",
      "Epoch 19/50\n",
      "12624/12624 [==============================] - 3s 267us/step - loss: 235204673.8210 - mse: 235204672.0000 - val_loss: 1617518.6419 - val_mse: 1617518.0000\n",
      "Epoch 20/50\n",
      "12624/12624 [==============================] - 4s 343us/step - loss: 236881507.1043 - mse: 236881456.0000 - val_loss: 1392184.7639 - val_mse: 1392184.6250\n",
      "Epoch 21/50\n",
      "12624/12624 [==============================] - 3s 201us/step - loss: 233935147.6079 - mse: 233935120.0000 - val_loss: 1371924.5978 - val_mse: 1371924.5000\n",
      "Epoch 22/50\n",
      "12624/12624 [==============================] - 3s 224us/step - loss: 237436935.9685 - mse: 237436912.0000 - val_loss: 1367312.8114 - val_mse: 1367312.5000\n",
      "Epoch 23/50\n",
      "12624/12624 [==============================] - 2s 186us/step - loss: 236976859.3113 - mse: 236976848.0000 - val_loss: 1330678.1647 - val_mse: 1330678.2500\n",
      "Epoch 24/50\n",
      "12624/12624 [==============================] - 2s 152us/step - loss: 236112124.8851 - mse: 236111920.0000 - val_loss: 1317521.8316 - val_mse: 1317521.7500\n",
      "Epoch 25/50\n",
      "12624/12624 [==============================] - 2s 136us/step - loss: 242526998.8591 - mse: 242526928.0000 - val_loss: 1316615.9294 - val_mse: 1316615.7500\n",
      "Epoch 26/50\n",
      "12624/12624 [==============================] - 2s 167us/step - loss: 237088760.6716 - mse: 237088688.0000 - val_loss: 1359797.2943 - val_mse: 1359797.5000\n",
      "Epoch 27/50\n",
      "12624/12624 [==============================] - 2s 129us/step - loss: 237865268.1738 - mse: 237865152.0000 - val_loss: 1378201.6709 - val_mse: 1378201.5000\n",
      "Epoch 28/50\n",
      "12624/12624 [==============================] - 2s 143us/step - loss: 232912933.3843 - mse: 232912800.0000 - val_loss: 1261532.8292 - val_mse: 1261532.7500\n",
      "Epoch 29/50\n",
      "12624/12624 [==============================] - 2s 136us/step - loss: 241591624.7100 - mse: 241591568.0000 - val_loss: 3134323.4735 - val_mse: 3134322.7500\n",
      "Epoch 30/50\n",
      "12624/12624 [==============================] - 2s 132us/step - loss: 245332969.8818 - mse: 245332960.0000 - val_loss: 1341375.7976 - val_mse: 1341375.6250\n",
      "Epoch 31/50\n",
      "12624/12624 [==============================] - 2s 150us/step - loss: 289314368.2212 - mse: 289314272.0000 - val_loss: 1477991.1684 - val_mse: 1477990.8750\n",
      "Epoch 32/50\n",
      "12624/12624 [==============================] - 2s 139us/step - loss: 247713703.0947 - mse: 247713520.0000 - val_loss: 1580937.9938 - val_mse: 1580938.5000\n",
      "Epoch 33/50\n",
      "12624/12624 [==============================] - 2s 147us/step - loss: 249295839.9266 - mse: 249295792.0000 - val_loss: 1792106.2152 - val_mse: 1792105.8750\n",
      "Epoch 34/50\n",
      "12624/12624 [==============================] - 1s 102us/step - loss: 261135368.3333 - mse: 261135328.0000 - val_loss: 1229925.0202 - val_mse: 1229925.1250\n",
      "Epoch 35/50\n",
      "12624/12624 [==============================] - 1s 99us/step - loss: 246263372.6212 - mse: 246263376.0000 - val_loss: 1547743.4297 - val_mse: 1547743.1250\n",
      "Epoch 36/50\n",
      "12624/12624 [==============================] - 1s 105us/step - loss: 242458211.9732 - mse: 242458080.0000 - val_loss: 1320566.8715 - val_mse: 1320566.8750\n",
      "Epoch 37/50\n",
      "12624/12624 [==============================] - 3s 242us/step - loss: 250951716.1766 - mse: 250951632.0000 - val_loss: 1263840.4960 - val_mse: 1263840.6250\n",
      "Epoch 38/50\n",
      "12624/12624 [==============================] - 3s 251us/step - loss: 253603812.7811 - mse: 253603872.0000 - val_loss: 1263284.4223 - val_mse: 1263284.7500\n",
      "Epoch 39/50\n",
      "12624/12624 [==============================] - 3s 241us/step - loss: 286670268.9502 - mse: 286670336.0000 - val_loss: 1203069.0415 - val_mse: 1203069.0000\n",
      "Epoch 40/50\n",
      "12624/12624 [==============================] - 2s 197us/step - loss: 327937466.5073 - mse: 327937408.0000 - val_loss: 2669601.6225 - val_mse: 2669601.5000\n",
      "Epoch 41/50\n",
      "12624/12624 [==============================] - 2s 154us/step - loss: 292220775.1442 - mse: 292220672.0000 - val_loss: 1192478.1663 - val_mse: 1192477.8750\n",
      "Epoch 42/50\n",
      "12624/12624 [==============================] - 2s 126us/step - loss: 267754533.3832 - mse: 267754528.0000 - val_loss: 1214984.3524 - val_mse: 1214984.3750\n",
      "Epoch 43/50\n",
      "12624/12624 [==============================] - 2s 150us/step - loss: 277187144.7871 - mse: 277187168.0000 - val_loss: 1181663.9046 - val_mse: 1181663.8750\n",
      "Epoch 44/50\n",
      "12624/12624 [==============================] - 2s 127us/step - loss: 276428249.9026 - mse: 276428224.0000 - val_loss: 2967914.9648 - val_mse: 2967914.5000\n",
      "Epoch 45/50\n",
      "12624/12624 [==============================] - 2s 124us/step - loss: 305120582.3563 - mse: 305120544.0000 - val_loss: 1165914.7183 - val_mse: 1165914.6250\n",
      "Epoch 46/50\n",
      "12624/12624 [==============================] - 2s 127us/step - loss: 302219052.2639 - mse: 302219136.0000 - val_loss: 1207348.6431 - val_mse: 1207349.0000\n",
      "Epoch 47/50\n",
      "12624/12624 [==============================] - 2s 119us/step - loss: 260143926.3329 - mse: 260143840.0000 - val_loss: 1208029.5834 - val_mse: 1208029.6250\n",
      "Epoch 48/50\n",
      "12624/12624 [==============================] - 1s 108us/step - loss: 273554625.7642 - mse: 273554624.0000 - val_loss: 1189465.5675 - val_mse: 1189465.5000\n",
      "Epoch 49/50\n",
      "12624/12624 [==============================] - 1s 60us/step - loss: 261364688.2875 - mse: 261364592.0000 - val_loss: 1150573.6239 - val_mse: 1150573.3750\n",
      "Epoch 50/50\n",
      "12624/12624 [==============================] - 1s 57us/step - loss: 260946250.3808 - mse: 260946208.0000 - val_loss: 1695236.3892 - val_mse: 1695236.3750\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32,activation= 'relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='rmsprop', loss='mse', metrics = ['mse'])\n",
    "history = model.fit(x, y,epochs=50,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, 51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mse = history.history['mse']\n",
    "val_mse = history.history['val_mse']\n",
    "plt.plot(epochs, mse, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_mse, 'b', label='Validation loss')\n",
    "plt.title('Training and validation MSE')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
